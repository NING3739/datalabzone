[
  {
    "objectID": "chalkboard/Introduction_to_Shiny.html#code",
    "href": "chalkboard/Introduction_to_Shiny.html#code",
    "title": "Introduction to Shiny",
    "section": "Code",
    "text": "Code\n\n# load shiny package\nlibrary(\"shiny\")\n\n# Define UI\nui &lt;- fluidPage(\n  titlePanel(\"My first Shiny App\"),\n  sidebarLayout(\n    sidebarPanel(\n      sliderInput(\"obs\", \"Number of observations:\", min = 0, max = 1000, value = 500)\n    ),\n    mainPanel(plotOutput(\"distPlot\"))\n  )\n)"
  },
  {
    "objectID": "chalkboard/Introduction_to_Shiny.html#outline",
    "href": "chalkboard/Introduction_to_Shiny.html#outline",
    "title": "Introduction to Shiny",
    "section": "Outline",
    "text": "Outline\n\nfluidPage(): creates a new page that automatically adjusts its layout to the browser’s dimensions.\ntitlePanel(): sets the title.\nsidebarLayout(), sidebarPanel(): create a sidebar.\nsliderInput(): creates an interactive slider."
  },
  {
    "objectID": "chalkboard/Introduction_to_Shiny.html#code-1",
    "href": "chalkboard/Introduction_to_Shiny.html#code-1",
    "title": "Introduction to Shiny",
    "section": "Code",
    "text": "Code\n\n# Define server logic \nserver &lt;- function(input, output) {\n  output$distPlot &lt;- renderPlot({\n    hist(rnorm(input$obs))\n  })\n}"
  },
  {
    "objectID": "chalkboard/Introduction_to_Shiny.html#outline-1",
    "href": "chalkboard/Introduction_to_Shiny.html#outline-1",
    "title": "Introduction to Shiny",
    "section": "Outline",
    "text": "Outline\n\nserver: This function contains the processing logic of the app.\noutput$distPlot: The output object is modified to include a plot named distPlot.\nrenderPlot(): This function is used to render the plot.\nhist(rnorm(input$obs)): Generate a histogram based on the input value from the slider."
  },
  {
    "objectID": "faq.html",
    "href": "faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Who are you?\nWhy did you start Data Lab Zone?\nCan I use the content on your website for my own purposes?\nHow can I reach out to you when I encounter problems?\nDo you accept guest posts or contributions?\nHow can I support your website or contribute to your work?\nAre there any other software or resources you recommend for data science?"
  },
  {
    "objectID": "faq.html#sec-who-are-you-",
    "href": "faq.html#sec-who-are-you-",
    "title": "FAQ",
    "section": "Who are you?",
    "text": "Who are you?\nI’m an ordinary person who is down-to-earth. If you’d like to learn more about me, feel free to visit my About page."
  },
  {
    "objectID": "faq.html#sec-why-did-you-start-data-lab-zone--",
    "href": "faq.html#sec-why-did-you-start-data-lab-zone--",
    "title": "FAQ",
    "section": "Why did you start Data Lab Zone ?",
    "text": "Why did you start Data Lab Zone ?\nThe reason why i want to start Data Lab Zone is to motivate myself to continuously learn new knowledge, as well as to showcasing my achievements for those interested in R language and data science to read, offer feedback and engage in mutual exchange."
  },
  {
    "objectID": "faq.html#sec-can-i-use-the-content-on-your-website-for-my-own-purposes",
    "href": "faq.html#sec-can-i-use-the-content-on-your-website-for-my-own-purposes",
    "title": "FAQ",
    "section": "Can I use the content on your website for my own purposes?",
    "text": "Can I use the content on your website for my own purposes?\nFeel free to utilize the content on my website for your own use, but please adhere to the following guidelines:\n\nCommercial use of my content is prohibited.\nProper credit must be given in your works.\nI am not liable for any issues related to the code or results in the content.\n\nIf you incorporate my code or material into your project, kindly reference the following details:\n\nAuthor’s name: “NING LI”\nTitle of the article or tutorial\nWebsite name: “Data Lab Zone”\nURL of the article or tutorial\nDate of access or code reproduction\n\nFor example:\nNING LI, R Basic, Data Lab Zone. Retrieved from:\nhttps://datalabzone.com/series/R/2022/ 11/27/rbasic.html, accessed on March 6th, 2023."
  },
  {
    "objectID": "faq.html#sec-how-can-i-reach-out-to-you-when-i-encounter-problems",
    "href": "faq.html#sec-how-can-i-reach-out-to-you-when-i-encounter-problems",
    "title": "FAQ",
    "section": "How can I reach out to you when I encounter problems?",
    "text": "How can I reach out to you when I encounter problems?\nThank you for considering reaching out to me. To ensure prompt response, please use the following methods for best communication:\n\nPost questions as comments on the relevant article to benefit other readers and avoid duplication.\nEmail inquiries will not be addressed, but redirected to the comments section.\nReport mistakes, bugs, or inaccuracies by creating an issue on GitHub. For those familiar with GitHub, feel free to edit the file and submit a pull request for speedy incorporation of your changes.\nBefore contacting me, please check the comments section for a possible answer to your question. Thank you!"
  },
  {
    "objectID": "faq.html#sec-do-you-accept-guest-posts-or-contributions",
    "href": "faq.html#sec-do-you-accept-guest-posts-or-contributions",
    "title": "FAQ",
    "section": "Do you accept guest posts or contributions?",
    "text": "Do you accept guest posts or contributions?\nOf course. I warmly welcome you to publish posts and make valuable contributions on my website.\nIf you are interested in publishing a post on my website, please contact me through Twitter or github. Once your submission has been reviewed and approved, I will publish it on my website, and the copyright will belong to you. Additionally, if you have any suggestions or feedback regarding my content, please contact me through the contact form. I will respond to your message promptly."
  },
  {
    "objectID": "faq.html#sec-how-can-i-support-your-website-or-contribute-to-your-work",
    "href": "faq.html#sec-how-can-i-support-your-website-or-contribute-to-your-work",
    "title": "FAQ",
    "section": "How can I support your website or contribute to your work?",
    "text": "How can I support your website or contribute to your work?\nIf you find my content helpful, please consider supporting me by buying me a coffee.\nOr, You are also welcome to buy me by Wechat and Alipay:"
  },
  {
    "objectID": "faq.html#sec-are-there-any-other-software-or-resources-you-recommend-for-data-science",
    "href": "faq.html#sec-are-there-any-other-software-or-resources-you-recommend-for-data-science",
    "title": "FAQ",
    "section": "Are there any other software or resources you recommend for data science?",
    "text": "Are there any other software or resources you recommend for data science?\nAs a science researcher, I deal with various scientific tools every day. Here, I have listed some of the software I use. If anyone knows better software, please leave a comment in the section below.\n\nStatistical software\nStatistical software is the most commonly used, and I mainly focus on R language, for no other reason than it being free and powerful!!!\n\nR (free and open source)\nRstudio (the most popular R IDE)\nIBM SPSS\nOriginLab\njamovi\n\n\n\nReference management software\nGood reference management software will greatly improve your efficiency in selecting and citing literature.\n\nEndnote\nZotero\nMendeley\n\n\n\nFlowchart software\n\nDiagrams.net"
  },
  {
    "objectID": "resources/livedemo/livedemo.html#introduction",
    "href": "resources/livedemo/livedemo.html#introduction",
    "title": "Data Lab Zone",
    "section": "Introduction",
    "text": "Introduction\nThis is a web-enabled code cell, powered by quarto-webr extension, where you have the freedom to play around and write any R code you desire.\nBy default, the quarto-webr extension avoids loading or requesting additional packages. You can add extra packages when opening the document or on a per-code cell basis. To see available packages, execute the following R code (using WebR or just R):\n\navailable.packages(repos=\"https://repo.r-wasm.org/\", type=\"source\")\n\nPackages may also be installed inside of a code cell through the built-in webr::install() function. For example, to install ggplot2, you would need to use:\n\nwebr::install(\"ggplot2\")"
  },
  {
    "objectID": "resources/livedemo/livedemo.html#playground",
    "href": "resources/livedemo/livedemo.html#playground",
    "title": "Data Lab Zone",
    "section": "Playground",
    "text": "Playground\nWrite your code here.\nLoading\n  webR..."
  },
  {
    "objectID": "posts/blogsforr/2023/02/07/math.html",
    "href": "posts/blogsforr/2023/02/07/math.html",
    "title": "Mathematics in R Markdown",
    "section": "",
    "text": "The ability to beautifully and accurately write mathematical expressions is crucial to many fields, particularly in scientific research. Luckily, R Markdown provides an excellent platform for doing this, thanks to its compatibility with LaTeX, a popular typesetting system renowned for high-quality typesetting of mathematical and scientific content."
  },
  {
    "objectID": "posts/blogsforr/2023/02/07/math.html#inline-mathematical",
    "href": "posts/blogsforr/2023/02/07/math.html#inline-mathematical",
    "title": "Mathematics in R Markdown",
    "section": "Inline mathematical",
    "text": "Inline mathematical\nThe formula for the area of a circle is $A = \\pi r^2$.\nAnd it will render as:\n\n\\[A = \\pi r^2\\]"
  },
  {
    "objectID": "posts/blogsforr/2023/02/07/math.html#display-formula",
    "href": "posts/blogsforr/2023/02/07/math.html#display-formula",
    "title": "Mathematics in R Markdown",
    "section": "Display Formula",
    "text": "Display Formula\nThe formula for the area of a circle is:\n$$\nA = \\pi r^2\n$$\nWhich will render as:\n\n\\[A = \\pi r^2\\]"
  },
  {
    "objectID": "posts/blogsforr/2023/02/07/math.html#examples",
    "href": "posts/blogsforr/2023/02/07/math.html#examples",
    "title": "Mathematics in R Markdown",
    "section": "Examples",
    "text": "Examples\n\nFraction:\n\n$$\n\\begin{align*}\n\\frac{a}{b}\n\\end{align*}\n$$\nrenders as:\n\n\\[\n\\begin{align*}\n\\frac{a}{b}\n\\end{align*}\n\\]\n\n\nExponents and Subscripts:\n\nwe use ^ for superscripts (exponents) and _for subscripts.\n$$\n\\begin{align*}\na^{b}\\\\\nc_{d}\n\\end{align*}\n$$\nrenders as:\n\n\\[\n\\begin{align*}\na^{b}\\\\\nc_{d}\n\\end{align*}\n\\]\n\n\nRoots and Logarithms:\n\n$$\n\\begin{align*}\nSquare\\ root: \\sqrt{a}\\\\\nnth\\ root: \\sqrt[n]{b}\\\\\nnatural\\ log: \\ln{c}\\\\\nlog\\ base\\ n: \\log_{n}{d}\n\\end{align*}\n$$\nrenders as:\n\n\\[\n\\begin{align*}\nSquare\\ root: \\sqrt{a}\\\\\nnth\\ root: \\sqrt[n]{b}\\\\\nnatural\\ log: \\ln{c}\\\\\nlog\\ base\\ n: \\log_{n}{d}\n\\end{align*}\n\\]\n\n\nQuadratic equation:\n\n$$\n\\begin{align*}\nx = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\n\\end{align*}\n$$\nrenders as:\n\n\\[\n\\begin{align*}\nx = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\n\\end{align*}\n\\]\n\n\nSummation:\n\n$$\n\\begin{align*}\n\\sum_{i=1}^{n} i = \\frac{n*(n + 1)}{2}\n\\end{align*}\n$$\nrenders as:\n\n\\[\n\\begin{align*}\n\\sum_{i=1}^{n} i = \\frac{n*(n + 1)}{2}\n\\end{align*}\n\\]\n\n\nIntegral:\n\n$$\n\\begin{align*}\n\\int_{0}^{\\infty} e^{-x} dx = 1\\\\\n\\int_{a}^{b} f(x) \\, dx\n\\end{align*}\n$$\nrenders as:\n\n\\[\n\\begin{align*}\n\\int_{0}^{\\infty} e^{-x} dx = 1\\\\\n\\int_{a}^{b} f(x) \\, dx\n\\end{align*}\n\\]\n\n\nMatrix representation:\n\n$$\n\\begin{align*}\n\\begin{bmatrix}\na & b \\\\\nc & d \n\\end{bmatrix}\n\\end{align*}\n$$\n\n$$\n\\begin{pmatrix}\na & b \\\\\nc & d \n\\end{pmatrix}\n$$\nRenders as:\n\n\\[\n\\begin{align*}\n\\begin{bmatrix}\na & b \\\\\nc & d\n\\end{bmatrix}\n\\end{align*}\n\\] \\[\n\\begin{align*}\n\\begin{pmatrix}\na & b \\\\\nc & d\n\\end{pmatrix}\n\\end{align*}\n\\]\n\n\nTrigonometric functions:\n\n$$\n\\begin{align*}\nSine: \\sin(x)\\\\ \nCosine: \\cos(x)\\\\ \nTangent: \\tan(x)\\\\ \nCotangent: \\cot(x)\\\\ \nSecant: \\sec(x)\\\\ \nCosecant: \\csc(x) \\\\ \nDegree: 30^\\circ\n\\end{align*}\n$$\nrenders as:\n\n\\[\n\\begin{align*}\nSine: \\sin(x)\\\\\nCosine: \\cos(x)\\\\\nTangent: \\tan(x)\\\\\nCotangent: \\cot(x)\\\\\nSecant: \\sec(x)\\\\\nCosecant: \\csc(x) \\\\\nDegree: 30^\\circ\n\\end{align*}\n\\]\n\n\nInverse trigonometric functions:\n\n$$\n\\\\begin{flalign}\nInverse\\ sine (arcsine): \\arcsin(x) &\\\\\nInverse\\ cosine (arccosine): \\arccos(x) &\\\\\nInverse\\ tangent (arctangent): \\arctan(x) &\n\\end{flalign}\n$$\nrender as:\n\n\\[\n\\small\n\\begin{flalign*}\n\\text{Inverse sine (arcsine):} \\quad & \\arcsin(x) &\\\\\n\\text{Inverse cosine (arccosine):} \\quad & \\arccos(x) &\\\\\n\\text{Inverse tangent (arctangent):} \\quad & \\arctan(x) &\n\\end{flalign*}\n\\small\n\\]"
  },
  {
    "objectID": "posts/blogsforr/2023/02/07/math.html#footnotes",
    "href": "posts/blogsforr/2023/02/07/math.html#footnotes",
    "title": "Mathematics in R Markdown",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://www.cnblogs.com/nowgood/p/latexstart.html#_nav_4↩︎"
  },
  {
    "objectID": "posts/blogsforr/2022/11/25/welcome.html",
    "href": "posts/blogsforr/2022/11/25/welcome.html",
    "title": "A Big Welcome!!!",
    "section": "",
    "text": "Welcome, readers!\nIf you’re interested in data science and the R programming language, you’re in the right place! My name is NING and I’m thrilled to have you here on my personal website. The goal of this website is to create a space for exchanging ideas, learning new knowledge, and exploring the exciting world of data science.\nAs you may know, R is a powerful language for data analysis, visualization, and modeling. It’s used by many data scientists, statisticians, and researchers around the world. Through this website, I hope to share my knowledge and experiences with R and data science, and also learn from your feedback and comments.\nMy website will cover a wide range of topics related to data science, including data wrangling, statistical modeling, machine learning, data visualization, and more. I’ll also share tips and tricks for working with R, as well as my thoughts on the latest trends and developments in the field.\nBut this website is not just about me talking at you – it’s about us having a conversation. I encourage you to leave comments and questions on my posts, share your own experiences and insights, and engage with other readers. Let’s build a community of data enthusiasts who can learn from each other and grow together.\nTo quote the famous statistician George Box, “All models are wrong, but some are useful.” Let’s work together to build useful models and insights that can help us understand the world around us.\nIf you have any feedback, suggestions, or ideas for future posts, please don’t hesitate to contact me. I’m always open to new ideas and collaborations.\nThanks for stopping by, and I hope you’ll join me on this journey of learning and discovery in the exciting world of data science and R programming.\n\n\n\n    \n    Social share button\n    \n    \n\n\n\n    \n        \n        \n\n        \n        \n\n        \n        \n\n        \n        \n\n        \n        \n\n        \n        \n\n        \n        \n    \n\n    \n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International",
    "section": "",
    "text": "Creative Commons Corporation (“Creative Commons”) is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an “as-is” basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.\nUsing Creative Commons Public Licenses\nCreative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.\n\nConsiderations for licensors: Our public licenses are intended for use by those authorized to give the public permission to use material in ways otherwise restricted by copyright and certain other rights. Our licenses are irrevocable. Licensors should read and understand the terms and conditions of the license they choose before applying it. Licensors should also secure all rights necessary before applying our licenses so that the public can reuse the material as expected. Licensors should clearly mark any material not subject to the license. This includes other CC-licensed material, or material used under an exception or limitation to copyright. More considerations for licensors.\nConsiderations for the public: By using one of our public licenses, a licensor grants the public permission to use the licensed material under specified terms and conditions. If the licensor’s permission is not necessary for any reason–for example, because of any applicable exception or limitation to copyright–then that use is not regulated by the license. Our licenses grant only permissions under copyright and certain other rights that a licensor has authority to grant. Use of the licensed material may still be restricted for other reasons, including because others have copyright or other rights in the material. A licensor may make special requests, such as asking that all changes be marked or described. Although not required by our licenses, you are encouraged to respect those requests where reasonable. More considerations for the public.\n\n\n\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\n\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nNonCommercial means not primarily intended for or directed towards commercial advantage or monetary compensation. For purposes of this Public License, the exchange of the Licensed Material for other material subject to Copyright and Similar Rights by digital file-sharing or similar means is NonCommercial provided there is no payment of monetary compensation in connection with the exchange.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\n\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part, for NonCommercial purposes only; and\nB. produce and reproduce, but not Share, Adapted Material for NonCommercial purposes only.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties, including when the Licensed Material is used other than for NonCommercial purposes.\n\n\n\n\n\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material, You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nFor the avoidance of doubt, You do not have permission under this Public License to Share Adapted Material.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\n\n\n\n\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database for NonCommercial purposes only and provided You do not Share Adapted Material;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material; and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\n\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\n\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\n\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\n\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org."
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-noncommercial-noderivatives-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-noncommercial-noderivatives-4.0-international-public-license",
    "title": "Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International",
    "section": "",
    "text": "By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\n\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nNonCommercial means not primarily intended for or directed towards commercial advantage or monetary compensation. For purposes of this Public License, the exchange of the Licensed Material for other material subject to Copyright and Similar Rights by digital file-sharing or similar means is NonCommercial provided there is no payment of monetary compensation in connection with the exchange.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\n\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part, for NonCommercial purposes only; and\nB. produce and reproduce, but not Share, Adapted Material for NonCommercial purposes only.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties, including when the Licensed Material is used other than for NonCommercial purposes.\n\n\n\n\n\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material, You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nFor the avoidance of doubt, You do not have permission under this Public License to Share Adapted Material.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\n\n\n\n\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database for NonCommercial purposes only and provided You do not Share Adapted Material;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material; and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\n\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\n\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\n\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\n\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org."
  },
  {
    "objectID": "series/R/2022/12/01/datavisualization_distributions.html",
    "href": "series/R/2022/12/01/datavisualization_distributions.html",
    "title": "Data Visualization and Distributions",
    "section": "",
    "text": "Data visualization is the graphical representation of information and data. By using visual elements like charts, graphs, and maps, data visualization tools provide an accessible way to see and understand trends, outliers, and patterns in data. Additionally, it provides an excellent way for employees or business owners to present data to non-technical audiences without confusion.\nIn the world of Big Data, data visualization tools and technologies are essential to analyze massive amounts of information and make data-driven decisions."
  },
  {
    "objectID": "series/R/2022/12/01/datavisualization_distributions.html#what-is-data-visualization",
    "href": "series/R/2022/12/01/datavisualization_distributions.html#what-is-data-visualization",
    "title": "Data Visualization and Distributions",
    "section": "",
    "text": "Data visualization is the graphical representation of information and data. By using visual elements like charts, graphs, and maps, data visualization tools provide an accessible way to see and understand trends, outliers, and patterns in data. Additionally, it provides an excellent way for employees or business owners to present data to non-technical audiences without confusion.\nIn the world of Big Data, data visualization tools and technologies are essential to analyze massive amounts of information and make data-driven decisions."
  },
  {
    "objectID": "series/R/2022/12/01/datavisualization_distributions.html#overview",
    "href": "series/R/2022/12/01/datavisualization_distributions.html#overview",
    "title": "Data Visualization and Distributions",
    "section": "Overview",
    "text": "Overview\nAfter completing this section, we will:\n\nunderstand the importance of data visualization for communicating data-driven findings.\nbe able to use distributions to summarize data.\nbe able to use the average and the standard deviation to understand the normal distribution\nbe able to access how well a normal distribution fit the data using a quantile-quantile plot.\nbe able to interpret data from a box plot"
  },
  {
    "objectID": "series/R/2022/12/01/datavisualization_distributions.html#introduction-to-data-visualization",
    "href": "series/R/2022/12/01/datavisualization_distributions.html#introduction-to-data-visualization",
    "title": "Data Visualization and Distributions",
    "section": "Introduction to Data Visualization",
    "text": "Introduction to Data Visualization\nKey Point:\n\nPlots of data easily communicate information that is difficult to extract from table of raw values.\nData visualization is a key component of exploratory data analysis (EDA), in which the properties of data are explored through visualization and summarization techniques.\nData visualization can help discover biases, systematic errors, mistakes and other unexpected problems in data before those data are incorporated into potentially flawed analysis.\nBasics of data visualization and EDA will be covered in R by using the ggplot2 package and motivating examples from world health, economics and infections disease.\nCode:\n\nlibrary(dslabs)\ndata(murders)\nhead(murders)\n\n       state abb region population total\n1    Alabama  AL  South    4779736   135\n2     Alaska  AK   West     710231    19\n3    Arizona  AZ   West    6392017   232\n4   Arkansas  AR  South    2915918    93\n5 California  CA   West   37253956  1257\n6   Colorado  CO   West    5029196    65"
  },
  {
    "objectID": "series/R/2022/12/01/datavisualization_distributions.html#introduction-to-distributions",
    "href": "series/R/2022/12/01/datavisualization_distributions.html#introduction-to-distributions",
    "title": "Data Visualization and Distributions",
    "section": "Introduction to Distributions",
    "text": "Introduction to Distributions\nKey Points:\n(Variance/Deviation Var)方差: 方差越大，数据的波动越大；方差越小，数据的波动就越小。\n(Standard Deviation)标准差: 方差开根号。\n\nThe most basic statistical summary of a list of object is its distribution.\nWe will learn ways to visualize and analyze distributions in the upcoming videos.\nIn some cases, data can be summarized by two-number summary: the average and standard deviation.I will learn to use data visualization to determine when that is appropriate.\nData Types\nIn R, there are 6 basic data types:\n\nlogical\nnumeric\ninteger\ncomplex\ncharacter\nraw\n\n\n\n\n\n\n\nImportant\n\n\n\nCategorical data are variables that are defined by a small number of groups.\n\nOrdinal categorical data have an inherent order to the categories (mild/medium/hot, for example).\nNon-ordinal categorical data have no order to the categories.\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nNumerical data take a variety of numeric values.\n\nContinuous variables can take any value.\nDiscrete variables are limited to sets of specific values.\n\n\n\n\n\n\n\nflowchart LR\n  A[Main variable types] --&gt; B{Catrgorical}\n  A[Main variable types] --&gt; C{Numeric}\n  B{Catrgorical} --&gt; D[ordinal]\n  B{Catrgorical} --&gt; E[non-ordinal]\n  C{Numeric} --&gt; F[continuous]\n  C{Numeric} --&gt; G[discrete]\n  \nlinkStyle default stroke:red\nlinkStyle 0 stroke:green\nlinkStyle 3 stroke:blue\nlinkStyle 4 stroke:black\n\n\n\n\n\nExercise\n\n# extract the variable names from a dataset\nnames(x)\n# explore how many unique values are used in dataset\nunique(x)\n# determine how many variable were reported\nlength(x)\n# determine how many unique variable were reported\nlength(unique(x))\n# to compute the frequencies of each unique value\ntable(x)"
  },
  {
    "objectID": "series/R/2022/12/01/datavisualization_distributions.html#describe-heights-to-et",
    "href": "series/R/2022/12/01/datavisualization_distributions.html#describe-heights-to-et",
    "title": "Data Visualization and Distributions",
    "section": "Describe Heights to ET",
    "text": "Describe Heights to ET\nkey point:\n\nA distribution is a function or description that shows the possible values of a variable and how often those values occur.\nFor categorical variables, the distribution describes the proportions of each category.\nA frequency table is the simplest way to show a categorical distribution. Use prop.table() to convert a table of counts to a frequency table. Barplots display the distribution of categorical variables and are a way to visualize the information in frequency tables.\nFor continuous numerical data, reporting the frequency of each unique entry is not an effective summary as many or most values are unique. Instead, a distribution function is required.\nThe cumulative distribution function (CDF) is a function that reports the proportion of data below a value \\(a\\) for all values of \\(a\\) :\\(F(a)=Pr(x≤a)\\).\nThe proportion of observations between any two values \\(a\\) and \\(b\\) can be computed from the CDF as \\(F(b)-F(a)\\).\nA histogram divides data into non-overlapping bins of the same size and plots the counts of number of values that fall in that interval.\nCode:\nR 语言学习 - table() 结果提取.\n\n# load the dataset\nlibrary(dslabs)\ndata(heights)\n# make a table of category proportions\nprop.table(table(heights$sex))"
  },
  {
    "objectID": "series/R/2022/12/01/datavisualization_distributions.html#cumulative-distribution-function",
    "href": "series/R/2022/12/01/datavisualization_distributions.html#cumulative-distribution-function",
    "title": "Data Visualization and Distributions",
    "section": "Cumulative Distribution Function",
    "text": "Cumulative Distribution Function\nEvery continuous distribution has cumulative distribution function (CDF). The CDF defines the proportion of the data below a given value for all values of \\(a\\) :\n\n\nCumulative Distribution Function (CDF)\n\nAs defined above, this plot of the CDF for male heights has height value a on the x-axis and the proportion of student with heights of that value or lower(F(a)) on the y-axis.\nThe CDF is essential for calculating probabilities related to continuous data. In a continuous dataset, the probability of a specific exact value is not informative because most entries are unique. For example, in the student heights data, only one individual reported a height of 68.8976377952726 inches, but many students rounded similar heights to 69 inches. If we computed exact value probabilities, we would find that being exactly 69 inches is much more likely than being a non-integer exact height, which does not match our understanding that height is continuous. We can instead use the CDF to obtain a useful summary, such as the probability that a student is between 68.5 and 69.5 inches.\nFor datasets that are not normal, the CDF can be calculated manually by defining a function to compute the probability above. This function can then be applied to a range of values across the range of the dataset to calculate a CDF. Given a datasetmy_data, the CDF can be calculated and plotted like this:\nR语言中的[apply()]，[lapply()]，[sapply()]，tapply()函数以及示例\nCode for CDF:\n\n# Cumulative Distribution Function \na &lt;- seq(min(x), max(x), length) # define range of the values\ncdf_function &lt;- function(x) {\n    mean(my_data &lt;= x)\n}\ncdf_values &lt;- sapply(a, cdf_function)\nplot(a, cdf_values)\n\nCode for student height:\n\n# example for student heights\na &lt;- seq(min(heights$height), max(heights$height), length = 100)\ncdf_function &lt;- function(x){\n  mean(heights$height &lt;= x)\n}\ncdf_value &lt;- sapply(a, cdf_function)\nplot(a, cdf_value)\n\n\n\n\n\n\n\nThe CDF defines that proportion of data below a cut-off \\(a\\). To define the proportion of values above \\(a\\), we compute: \\(1-F(a)\\)\nTo define the proportion of values between \\(a\\) and \\(b\\), we compute: \\(F(b)-F(a)\\)\nNote that the CDF can help compute probabilities. The probability of observing a randomly chosen value between \\(a\\) and \\(b\\) is equal to the proportion of values between \\(a\\) and \\(b\\), which we compute with the CDF."
  },
  {
    "objectID": "series/R/2022/12/01/datavisualization_distributions.html#smooth-density-plots",
    "href": "series/R/2022/12/01/datavisualization_distributions.html#smooth-density-plots",
    "title": "Data Visualization and Distributions",
    "section": "Smooth Density Plots",
    "text": "Smooth Density Plots\nKey Point:\n\n\n\n\n\n\nA further note on histograms\n\n\n\nThe choice of binwidth has a determinative effect on sharp. There is no “correct” choice for binwidth, and you can sometimes gain insights into the data by experimenting with binwidths.\n\n\n\nSmooth density plots can be thought of as histograms where the binwidth is extremely or infinitely small. The smoothing function makes estimates of the true continuous trend of the data given the available sample of data points.\nThe degree of smoothness can be controlled by an argument in the plotting function.\nWhile the histogram is an assumption-free summary, the smooth density plot is shaped by assumptions and choices you make as a data analyst.\nThe y-axis is scaled so that the area under the density curve sums to 1. This means that interpreting value on the y-axis is not straightforward. To determine the proportion of data in between two values, compute the area under the smooth density curve in the region between those values.\nAn advantage of smooth densities over histograms is that densities are easier to compare visually."
  },
  {
    "objectID": "series/R/2022/12/01/datavisualization_distributions.html#normal-distribution",
    "href": "series/R/2022/12/01/datavisualization_distributions.html#normal-distribution",
    "title": "Data Visualization and Distributions",
    "section": "Normal Distribution",
    "text": "Normal Distribution\nKey Points:\n\n\nThe normal distribution:\n\nis centered around one value, the mean\n\nis symmetric(对称) around the mean.\nis defined completely by its mean(\\(\\mu\\)) and standard deviation(\\(\\sigma\\))\n\n\nAlways has the same proportion of observations within a given distance of the mean (for example, 95% with 2\\(\\sigma\\))\n\n\nThe standard deviation is the average distance between a value and the mean value.\nCalculate the mean using the mean() function.\nCalculate the standard deviation using the sd() function or manually.\n\nStandard units describe how many standard deviations a value is away from the mean. The z-score, or number of standard deviation an observation is away from the mean \\(\\mu\\):\n\\[\n  z = (x-\\mu)/\\sigma\n  \\]\n\nComputer standard units with the scale() function.\nImportant: to calculate the proportion of value that meet a certain condition, use the mean function on a logical vector. Because TRUE is converted to 1 and FALSE is converted to 0, taking the mean of this vector yields the proportion of TURE."
  },
  {
    "objectID": "series/R/2022/12/01/datavisualization_distributions.html#equation-for-the-normal-distribution",
    "href": "series/R/2022/12/01/datavisualization_distributions.html#equation-for-the-normal-distribution",
    "title": "Data Visualization and Distributions",
    "section": "Equation for the normal distribution",
    "text": "Equation for the normal distribution\nThe normal distribution is mathematically defined by the following formula for any mean \\(\\mu\\) and standard deviation \\(\\sigma\\):\n\\[\nPr(a &lt; x &lt; b) = \\int_{a}^b\\frac{1}{\\sqrt{2\\pi\\mu}}{e}^{-\\frac{1}{2}(\\frac{x-\\mu^2}{\\sigma})}dx\n\\]\nWhen standard unites \\(z=0\\), the normal distribution is at a maximum, the mean \\(\\mu\\). The function is defined to be symmetric around \\(z=0\\).\nThe normal distribution of z-score is called the standard normal distribution and is defined by \\(\\mu=0\\) and \\(\\sigma=1\\).\nZ-score are useful to quickly evalute whether an observation is average or extreme. Z-scores near 0 are average. Z-score above 2 or below -2 are significantly above or blew the mean, and z-scores above 3 or below -3 are extrmely rate.\nCode:\n\n# define x as vector of male heights\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(heights)\nindex &lt;- heights$sex==\"Male\"\nx &lt;- heights$height[index]\n\n# calculate the mean and standard deviation manually\naverage &lt;- sum(x)/length(x)\nSD &lt;- sqrt(sum((x-average)^2)/length(x))\n\n# built-in mean and sd functions - note that the audio and printed value disagree\naverage &lt;- mean(x)\nSD &lt;- sd(x)\nc(average = average, SD = SD)\n\n# calculate standard units\nz &lt;- scale(x)\n\n# calculate proportion of value within 2 SD of mean\nmean(abs(z) &lt; 2)\n\nfunction sd():The built-in R function sd() calculates the standard deviation, but it divides by length(x)-1 instead of length(x). When the length of the list is large, this difference is negligible and you can use the built-in sd() function. Otherwise, you should compute σ by hand. For this course series, assume that you should use the sd() function unless you are told not to do so.\nHere we will learn more about benchmark z-score value and their corresponding probabilities.\nThe 68-95-99.7 Rule\nThe normal distribution is associated with the 68-95-99.7 rule. This rule describes the probability of observing events within a ceration number of standard deviations of the mean.\n\n\nNormal Distribution Probabilities\n\nThe probability distribution function for the normal distribution is defined such that:\n\nAbout 68% of observations will be within one standard deviation of the mean(\\(\\mu\\pm\\sigma\\)). In standard units, this is equivalent to a z-score of \\(|z|\\leq2\\)\n\n\n\n\nProbability of an observation within 1 SD of mean\n\n\nAbout 95% of observations will be within two standard seviations of the mean(\\(\\mu\\pm2\\sigma\\)). In standard units, this is equivalent to a z-sore of \\(|z|\\leq2\\).\n\n\n\nProbability of an ovservation within 2 SD of mean\n\n\nAbout 99.7% of observations will be within three standard deviations of the mean(\\(\\mu\\pm3\\sigma\\)). In standard units, this is equivalent to a z-score of \\(|z|\\leq3\\).\n\n\n\nProbability of an observation within 3 SD of mean"
  },
  {
    "objectID": "series/R/2022/12/01/datavisualization_distributions.html#the-normal-cdf-and-pnorm",
    "href": "series/R/2022/12/01/datavisualization_distributions.html#the-normal-cdf-and-pnorm",
    "title": "Data Visualization and Distributions",
    "section": "The Normal CDF and pnorm",
    "text": "The Normal CDF and pnorm\nKey points:\n\nThe normal distribution has a mathematically defined CDF which can be computed in R with the function pnorm.\npnom(a, avg, s) gives the value of the cumculative distribution function F(a) for the normal distribution defined by average avg and standard deviation s.\nwe say that a random quantity is normally distributed with average avg and standard deviation s if the approximate pnorm(a, avg, s) holds for all values of a.\nIf we are willing to use the normal approximation for height, we can estimate the distribution simply from the mean and standard deviation of our values.\nIf we treat the height data as discrete rather than categorical, we see that the data are not very useful because integer values are more common that expected due to rounding. This is called discretization.\nWith rounded data, the normal approximation is particularly useful when computing probabilities of intervals of length 1 that include exactly over integer.\nCode: Using pnorm to calculate probabilities\nGiven male heights x:\n\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(\"heights\")\nx &lt;- heights %&gt;% filter(sex==\"Male\") %&gt;% pull(height)\n\nwe can estimate the probability that a male is taller than 70.5 inches with:\n\n1 - pnorm(70.5, mean(x), sd(x))\n\nCode: Discretization and the normal approximation\n\n# plot distribution of exact heights in data\nplot(prop.table(table(x)), xlab = \"a = Height in inches\", ylab = \"Pr(x = a)\")\n\n\n\n\n\n\n\n\n# probabilities in actual data over length 1 ranges containing a integer\nmean(x &lt;= 68.5) - mean(x &lt;= 67.5)\nmean(x &lt;= 69.5) - mean(x &lt;= 68.5)\nmean(x &lt;= 70.5) - mean(x &lt;= 69.5)\n\n# probabilities in normal approximation match well\npnorm(68.5, mean(x), sd(x)) - pnorm(67.5, mean(x), sd(x))\npnorm(69.5, mean(x), sd(x)) - pnorm(68.5, mean(x), sd(x))\npnorm(70.5, mean(x), sd(x)) - pnorm(69.5, mean(x), sd(x))\n\n# probabilities in actual data over other ranges don't match normal approx as well\nmean(x &lt;= 70.9) - mean(x &lt;= 70.1)\npnorm(70.9, mean(x), sd(x)) - pnorm(70.1, mean(x), sd(x))"
  },
  {
    "objectID": "series/R/2022/12/01/datavisualization_distributions.html#definition-of-quantiles",
    "href": "series/R/2022/12/01/datavisualization_distributions.html#definition-of-quantiles",
    "title": "Data Visualization and Distributions",
    "section": "Definition of quantiles",
    "text": "Definition of quantiles\nDefinition of quantiles\nQuantiles are cut off points that divide a dataset into intervals with set probability. The qth quantile is the value at which q% of the observation are equal to or less than that value.\nUsing the quantile function\nGiven a dataset data and desired quantile q, you can find the q the quantile of data with:\n\nquantile(data,q)\n\nPercentiles\nPercentiles are the quantiles that divide a dataset into 100 intervals each with 1% probability. You can determine all percentiles of a dataset data like this:\n\np &lt;- seq(0.01, 0.09, 0.01)\nquantile(data, p)\n\nQuartiles\nQuartiles divide a dataset into 4 parts each with 25% probability. They are equal to the 25th, 50th and 75th percentiles. The 25th percentile is also known as the 1st quartile, the 50th percentile is also konwn as the median, and the 75th percentile is also knowns as the 3rd quartile.\nThe summary() function returns the minimum, quartiles and maximum of a vector.\nExamples\nLoad the heights dataset from the dslabs package:\n\nlibrary(dslabs)\ndata(\"heights\")\n\nUsesummaryon the heights$height variable to find the quartiles:\n\nsummary(heights$height)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  50.00   66.00   68.50   68.32   71.00   82.68 \n\n\nFind the percentiles of height$height:\n\np &lt;- seq(0.01, 0.99, 0.01)\npercentiles &lt;- quantile(heights$height, p)\n\nConfirm that the 25th and 75th percentiles match that 1st and 3rd quartiles. Note that quantile() returns a named vector. You can access the 25th and 75th percentiles like this (adapt the code for other percentile value):\n\npercentiles[names(percentiles) == \"25%\"]\n\n25% \n 66 \n\npercentiles[names(percentiles) == \"75%\"]\n\n75% \n 71"
  },
  {
    "objectID": "series/R/2022/12/01/datavisualization_distributions.html#finding-quantile-with-qnorm",
    "href": "series/R/2022/12/01/datavisualization_distributions.html#finding-quantile-with-qnorm",
    "title": "Data Visualization and Distributions",
    "section": "Finding quantile with qnorm",
    "text": "Finding quantile with qnorm\nDefiniton of qnorm\n简单来说,qnorm是正态分布累积分布函数(CDF)的反函数， 也就是说它可以视为pnorm的反函数, 这里q指的是quantile, 即分位数\nThe qnorm() function gives the theoretical value of a quantile with probability p of observing a value equal to or less than that quantile value a normal distribution with mean mu and standard deviation sigma:\n\nqnorm(p, mu, sigma)\n\nBy default, mu=0 and sigma=1. Therefore, calling qnorm() with no arguments gives quantiles for the standard normal distribution.\n\nqnorm(p)\n\nRecall that quantiles are defined such that \\(p\\) is the probability of a random observation less than or equal to the quantile.\nRealation to pnorm\nThe pnorm() function gives the probability that a value from a standard normal distribution will be less than or equal to a z-score value z. consider: \\[pnorm(-1.96)\\approx0.025\\] The result of pnorm() is the quantile. Note that: \\[qnorm(0.025)\\approx-1.96\\] qnorm() and pnorm are inverse functions: \\[pnorm(qnorm(0.025))\\equiv0.025\\]\nTheoretical quantiles\nYou can use qnorm() to determine the theoretical quantiles of a dataset: that is, the theoretical value of quantiles assuming that a dataset follows a normal distribution. Run the qnorm() function with the desired probabilities p, mean mu and standard deviation sigma.\nSuppose male heights follow a normal distribution with a mean of 69 inches and standard deviation of 3 inches. The theoretical quantiles are:\n\np &lt;- seq(0.01, 0.99, 0.01)\ntheoretical_quantiles &lt;- qnorm(p, 69, 3)\n\nTheoretical quantiles can be compared to sample quantiles determined with the quantile function in order to evaluate whether the sample follows a normal distribution."
  },
  {
    "objectID": "series/R/2022/12/01/datavisualization_distributions.html#quantile-quantile-plots",
    "href": "series/R/2022/12/01/datavisualization_distributions.html#quantile-quantile-plots",
    "title": "Data Visualization and Distributions",
    "section": "Quantile-Quantile Plots",
    "text": "Quantile-Quantile Plots\nKey Points:\n\nQuantile-quantile plots, or QQ-plot, are used to check whether distributions are well-approximated by a normal distribution.\nGiven a proportion p, the quantile q is the value such that the proportion of values in the data blew q is p.\nIn a QQ-plot, the sample quantiles in the observed data are compared to the theoretical quantiles expected from the normal distribution. If the data are well-approximated by the normal distribution, then the points on the QQ-plot will fall near the identity line(sample = theoretical).\nCalculate sample quantiles (observed quantiles) using the quantile() function.\nCalculate theoretical quantiles with the qnorm() function. qnorm() will caculate quantiles for the standard normal distribution (\\(\\mu=0, \\sigma=1\\)) by default, but it can calculate quantiles for any normal distribution given mean() and sd() arguments.\nCode:\n\n# define x and z\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(heights)\n\nindex &lt;- heights$sex==\"Male\"\nx &lt;- heights$height[index]\nz &lt;- scale(x)\n\n# proportion of data below 69.5\nmean(x &lt;= 69.5)\n\n[1] 0.5147783\n\n# calculate observed and theoretical quantiles\np &lt;- seq(0.05, 0.95, 0.05)\nobserved_quantiles &lt;- quantile(x, p)\ntheoretical_quantiles &lt;- qnorm(p, mean = mean(x), sd = sd(x))\n\n# make QQ-plot\nplot(theoretical_quantiles, observed_quantiles)\nabline(0,1)\n\n\n\n\n\n\n# make QQ-plot with scaled values\nobserved_quantiles &lt;- quantile(z, p)\ntheoretical_quantiles &lt;- qnorm(p)\nplot(theoretical_quantiles, observed_quantiles)\nabline(0,1)"
  },
  {
    "objectID": "series/R/2022/12/01/datavisualization_distributions.html#percentiles-1",
    "href": "series/R/2022/12/01/datavisualization_distributions.html#percentiles-1",
    "title": "Data Visualization and Distributions",
    "section": "Percentiles",
    "text": "Percentiles\nKey Points:\n\nPercentiles are the quantiles obtained when defining \\(p\\) as 0.01, 0.02,…,0.99. They summarize the values at which a certain percent of the observations are equal to or less than that value.\nThe 50th percentile is also known as the median.\nThe quartiles are the 25th, 50th and 75th percentiles."
  },
  {
    "objectID": "series/R/2022/12/01/datavisualization_distributions.html#boxplots",
    "href": "series/R/2022/12/01/datavisualization_distributions.html#boxplots",
    "title": "Data Visualization and Distributions",
    "section": "Boxplots",
    "text": "Boxplots\nR语言如何绘制箱线图\nKey Points:\n\nWhen data do not follow a normal distribution and cannot be succinctly summarized by only the mean and standard deviation, an alternative is to report a five-number summary: range (ignoring outliers) and the quartiles (25th, 50th, 75th percentile).\nIn a boxplot, the box is defined by the 25th and 75th percentiles and the median is a horizontal line through the box. The whiskers show the range excluding outliers, and outliers are plotted separately as individual points.\nThe interquartile range is the distance between the 25th and 75th percentiles.\nBoxplots are particularly useful when comparing multiple distributions."
  },
  {
    "objectID": "series/R/2022/12/01/datavisualization_distributions.html#distribution-of-female-heights",
    "href": "series/R/2022/12/01/datavisualization_distributions.html#distribution-of-female-heights",
    "title": "Data Visualization and Distributions",
    "section": "Distribution of Female Heights",
    "text": "Distribution of Female Heights\nKey Points:\n\nIf a distribution is not normal, it cannot be summarized with only the mean and standard seviation. Provide a histogram, smooth density or boxplot instead.\nA plot can force us to see unexpected results that make us question the quality or implication of our data."
  },
  {
    "objectID": "series/R/2022/12/07/datavisualization_principles.html",
    "href": "series/R/2022/12/07/datavisualization_principles.html",
    "title": "Data Visualization Principles",
    "section": "",
    "text": "Data visualization principles covers some general principles that can serve as guides for effective data visualization.\nAfter completing this section, you will:\n\nunderstand basic principles of effective data visualization.\nunderstand the importance of keeping your goal in mind when deciding on a visualization approach.\nunderstand principles for encoding data, including position, aligned lengths, angles, area, brightness, and color hue.\nknow when to include the number zero in visualizations.\nbe able to use techniques to ease comparisons, such as using common axes, putting visual cues to be compared adjacent to one another, and using color effectively.\n\n\n\nVisual cues for encoding data include position, length, angle, area, brightness and color hue.\nPosition and length are the preferred way to display quantities, followed by angles, which are preferred over area. Brightness and color are even harder to quantify but can sometimes be useful.\nPie charts represent visual cues as both angles and area, while donut charts use only area. Humans are not good at visually quantifying angles and are even worse at quantifying area. Therefore pie and donut charts should be avoided - use a bar plot instead. If you must make a pie chart, include percentages as labels.\nBar plots represent visual cues as position and length. Humans are good at visually quantifying linear measures, making bar plots a strong alternative to pie or donut charts.\n\n\n\nWhen using bar plots, always start at 0. It is deceptive not to start at 0 because bar plots imply length is proportional to the quantity displayed. Cutting off the y-axis can make differences look bigger than they actually are.\nWhen using position rather than length, it is not necessary to include 0 (scatterplot, dot plot, boxplot).\n\n\n\nMake sure your visualizations encode the correct quantities.\nFor example, if you are using a plot that relies on circle area, make sure the area (rather than the radius) is proportional to the quantity.\n\n\n\nIt is easiest to visually extract information from a plot when categories are ordered by a meaningful value. The exact value on which to order will depend on your data and the message you wish to convey with your plot.\nThe default ordering for categories is alphabetical if the categories are strings or by factor level if factors. However, we rarely want alphabetical order.\n\n\n\nA dynamite plot - a bar graph of group averages with error bars denoting standard errors - provides almost no information about a distribution.\nBy showing the data, you provide viewers extra information about distributions.\nJitter is adding a small random shift to each point in order to minimize the number of overlapping points. To add jitter, use the geom_jitter() geometry instead of geom_point(). (See example below.)\nAlpha blending is making points somewhat transparent, helping visualize the density of overlapping points. Add an alpha argument to the geometry.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dslabs)\ndata(heights)\n# dot plot showing the data\nheights %&gt;% ggplot(aes(sex, height)) + geom_point()\n\n\n\n\n\n\n# jittered, alpha blended point plot\nheights %&gt;% ggplot(aes(sex, height)) + geom_jitter(width = 0.1, alpha = 0.2)\n\n\n\n\n\n\n\n\n\n\nEase comparisons by keeping axes the same when comparing data across multiple plots.\nAlign plots vertically to see horizontal changes. Align plots horizontally to see vertical changes.\nBar plots are useful for showing one number but not useful for showing distributions.\n\n\n\nUse transformations when warranted to ease visual interpretation.\nThe log transformation is useful for data with multiplicative changes. The logistic transformation is useful for fold changes in odds. The square root transformation is useful for count data.\n\n\n\nTextbook section on compared visual cues being adjacent\nTextbook section on using color\nTextbook section on considering the color blind\n\n\nWhen two groups are to be compared, it is optimal to place them adjacent in the plot.\nUse color to encode groups to be compared.\nConsider using a color blind friendly palette.\n\n\ncolor_blind_friendly_cols &lt;- c(\"#999999\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\n\np1 &lt;- data.frame(x = 1:8, y = 1:8, col = as.character(1:8)) %&gt;%\n    ggplot(aes(x, y, color = col)) +\n    geom_point(size = 5)\np1 + scale_color_manual(values = color_blind_friendly_cols)\n\n\n\n\n\n\n\n\n\nPlots for two variables\n\n\nConsider using a slope chart or Bland-Altman plot when comparing one variable at two different time points, especially for a small number of observations.\nSlope charts use angle to encode change. Use geom_line() to create slope charts. It is useful when comparing a small number of observations.\nThe Bland-Altman plot (Tukey mean difference plot, MA plot) graphs the difference between conditions on the y-axis and the mean between conditions on the x-axis. It is more appropriate for large numbers of observations than slope charts.\n\n\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(gapminder)\n\n\nwest &lt;- c(\"Western Europe\", \"Northern Europe\", \"Southern Europe\", \"Northern America\", \"Australia and New Zealand\")\n\ndat &lt;- gapminder %&gt;%\n    filter(year %in% c(2010, 2015) & region %in% west & !is.na(life_expectancy) & population &gt; 10^7)\n\ndat %&gt;%\n    mutate(location = ifelse(year == 2010, 1, 2),\n           location = ifelse(year == 2015 & country %in% c(\"United Kingdom\", \"Portugal\"),\n                             location + 0.22, location),\n           hjust = ifelse(year == 2010, 1, 0)) %&gt;%\n    mutate(year = as.factor(year)) %&gt;%\n    ggplot(aes(year, life_expectancy, group = country)) +\n    geom_line(aes(color = country), show.legend = FALSE) +\n    geom_text(aes(x = location, label = country, hjust = hjust), show.legend = FALSE) +\n    xlab(\"\") +\n    ylab(\"Life Expectancy\") \n\n\n\n\n\n\n\n\n\nlibrary(ggrepel)\n\n\ndat %&gt;%\n    mutate(year = paste0(\"life_expectancy_\", year)) %&gt;%\n    select(country, year, life_expectancy) %&gt;% spread(year, life_expectancy) %&gt;%\n    mutate(average = (life_expectancy_2015 + life_expectancy_2010)/2,\n                difference = life_expectancy_2015 - life_expectancy_2010) %&gt;%\n    ggplot(aes(average, difference, label = country)) +\n    geom_point() +\n    geom_text_repel() +\n    geom_abline(lty = 2) +\n    xlab(\"Average of 2010 and 2015\") +\n    ylab(\"Difference between 2015 and 2010\")\n\n\n\n\n\n\n\n\n\nEncoding a third variable\n\n\nEncode a categorical third variable on a scatterplot using color hue or shape. Use the shape argument to control shape.\nEncode a continuous third variable on a using color intensity or size.\n\n\nCase study: vaccines and infectious diseases\ngeom_vline: Add vertical lines\n\n\nVaccines save millions of lives, but misinformation has led some to question the safety of vaccines. The data support vaccines as safe and effective. We visualize data about measles incidence in order to demonstrate the impact of vaccination programs on disease rate.\nThe RColorBrewer package offers several color palettes. Sequential color palettes are best suited for data that span from high to low. Diverging color palettes are best suited for data that are centered and diverge towards high or low values.\nThe geom_tile() geometry creates a grid of colored tiles. Position and length are stronger cues than color for numeric values, but color can be appropriate sometimes.\n\n\n# import data and inspect\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(us_contagious_diseases)\nstr(us_contagious_diseases)\n\n\n# assign dat to the per 10,000 rate of measles, removing Alaska and Hawaii and adjusting for weeks reporting\nthe_disease &lt;- \"Measles\"\ndat &lt;- us_contagious_diseases %&gt;%\n    filter(!state %in% c(\"Hawaii\", \"Alaska\") & disease == the_disease) %&gt;%\n    mutate(rate = count / population * 10000 * 52/weeks_reporting) %&gt;%\n    mutate(state = reorder(state, rate))\n\n# plot disease rates per year in California\ndat %&gt;% filter(state == \"California\" & !is.na(rate)) %&gt;%\n    ggplot(aes(year, rate)) +\n    geom_line() +\n    ylab(\"Cases per 10,000\") +\n    geom_vline(xintercept=1963, col = \"blue\")\n\n\n\n\n\n\n# tile plot of disease rate by state and year\ndat %&gt;% ggplot(aes(year, state, fill=rate)) +\n    geom_tile(color = \"grey50\") +\n    scale_x_continuous(expand = c(0,0)) +\n    scale_fill_gradientn(colors = RColorBrewer::brewer.pal(9, \"Reds\"), trans = \"sqrt\") +\n    geom_vline(xintercept = 1963, col = \"blue\") +\n    theme_minimal() + theme(panel.grid = element_blank()) +\n    ggtitle(the_disease) +\n    ylab(\"\") +\n    xlab(\"\")\n\n\n\n\n\n\n\n\n\n# compute US average measles rate by year\navg &lt;- us_contagious_diseases %&gt;%\n    filter(disease == the_disease) %&gt;% group_by(year) %&gt;%\n    summarize(us_rate = sum(count, na.rm = TRUE)/sum(population, na.rm = TRUE)*10000)\n\n# make line plot of measles rate by year by state\ndat %&gt;%\n    filter(!is.na(rate)) %&gt;%\n    ggplot() +\n    geom_line(aes(year, rate, group = state), color = \"grey50\", \n        show.legend = FALSE, alpha = 0.2, size = 1) +\n    geom_line(mapping = aes(year, us_rate), data = avg, size = 1, col = \"black\") +\n    scale_y_continuous(trans = \"sqrt\", breaks = c(5, 25, 125, 300)) +\n    ggtitle(\"Cases per 10,000 by state\") +\n    xlab(\"\") +\n    ylab(\"\") +\n    geom_text(data = data.frame(x = 1955, y = 50),\n        mapping = aes(x, y, label = \"US average\"), color = \"black\") +\n    geom_vline(xintercept = 1963, col = \"blue\")\n\n\n\n\n\n\n\n\n\nAvoid pseudo-three-dimensional plots\n\nIn general, pseudo-3D plots and gratuitous 3D plots only add confusion. Use regular 2D plots instead.\n\n\nAvoid too many significant digits\n\n\nIn tables, avoid using too many significant digits. Too many digits can distract from the meaning of your data.\nReduce the number of significant digits globally by setting an option. For example, options(digits = 3) will cause all future computations that session to have 3 significant digits.\nReduce the number of digits locally using round() or signif()."
  },
  {
    "objectID": "series/R/2022/12/07/datavisualization_principles.html#overview",
    "href": "series/R/2022/12/07/datavisualization_principles.html#overview",
    "title": "Data Visualization Principles",
    "section": "",
    "text": "Data visualization principles covers some general principles that can serve as guides for effective data visualization.\nAfter completing this section, you will:\n\nunderstand basic principles of effective data visualization.\nunderstand the importance of keeping your goal in mind when deciding on a visualization approach.\nunderstand principles for encoding data, including position, aligned lengths, angles, area, brightness, and color hue.\nknow when to include the number zero in visualizations.\nbe able to use techniques to ease comparisons, such as using common axes, putting visual cues to be compared adjacent to one another, and using color effectively."
  },
  {
    "objectID": "series/R/2022/12/07/datavisualization_principles.html#encoding-data-using-visual-cues",
    "href": "series/R/2022/12/07/datavisualization_principles.html#encoding-data-using-visual-cues",
    "title": "Data Visualization Principles",
    "section": "",
    "text": "Visual cues for encoding data include position, length, angle, area, brightness and color hue.\nPosition and length are the preferred way to display quantities, followed by angles, which are preferred over area. Brightness and color are even harder to quantify but can sometimes be useful.\nPie charts represent visual cues as both angles and area, while donut charts use only area. Humans are not good at visually quantifying angles and are even worse at quantifying area. Therefore pie and donut charts should be avoided - use a bar plot instead. If you must make a pie chart, include percentages as labels.\nBar plots represent visual cues as position and length. Humans are good at visually quantifying linear measures, making bar plots a strong alternative to pie or donut charts."
  },
  {
    "objectID": "series/R/2022/12/07/datavisualization_principles.html#know-when-to-include-zero",
    "href": "series/R/2022/12/07/datavisualization_principles.html#know-when-to-include-zero",
    "title": "Data Visualization Principles",
    "section": "",
    "text": "When using bar plots, always start at 0. It is deceptive not to start at 0 because bar plots imply length is proportional to the quantity displayed. Cutting off the y-axis can make differences look bigger than they actually are.\nWhen using position rather than length, it is not necessary to include 0 (scatterplot, dot plot, boxplot)."
  },
  {
    "objectID": "series/R/2022/12/07/datavisualization_principles.html#do-not-distort-quantitles",
    "href": "series/R/2022/12/07/datavisualization_principles.html#do-not-distort-quantitles",
    "title": "Data Visualization Principles",
    "section": "",
    "text": "Make sure your visualizations encode the correct quantities.\nFor example, if you are using a plot that relies on circle area, make sure the area (rather than the radius) is proportional to the quantity."
  },
  {
    "objectID": "series/R/2022/12/07/datavisualization_principles.html#order-by-a-meaningful-value",
    "href": "series/R/2022/12/07/datavisualization_principles.html#order-by-a-meaningful-value",
    "title": "Data Visualization Principles",
    "section": "",
    "text": "It is easiest to visually extract information from a plot when categories are ordered by a meaningful value. The exact value on which to order will depend on your data and the message you wish to convey with your plot.\nThe default ordering for categories is alphabetical if the categories are strings or by factor level if factors. However, we rarely want alphabetical order."
  },
  {
    "objectID": "series/R/2022/12/07/datavisualization_principles.html#show-the-data",
    "href": "series/R/2022/12/07/datavisualization_principles.html#show-the-data",
    "title": "Data Visualization Principles",
    "section": "",
    "text": "A dynamite plot - a bar graph of group averages with error bars denoting standard errors - provides almost no information about a distribution.\nBy showing the data, you provide viewers extra information about distributions.\nJitter is adding a small random shift to each point in order to minimize the number of overlapping points. To add jitter, use the geom_jitter() geometry instead of geom_point(). (See example below.)\nAlpha blending is making points somewhat transparent, helping visualize the density of overlapping points. Add an alpha argument to the geometry.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dslabs)\ndata(heights)\n# dot plot showing the data\nheights %&gt;% ggplot(aes(sex, height)) + geom_point()\n\n\n\n\n\n\n# jittered, alpha blended point plot\nheights %&gt;% ggplot(aes(sex, height)) + geom_jitter(width = 0.1, alpha = 0.2)"
  },
  {
    "objectID": "series/R/2022/12/07/datavisualization_principles.html#ease-comparisons-use-common-axes",
    "href": "series/R/2022/12/07/datavisualization_principles.html#ease-comparisons-use-common-axes",
    "title": "Data Visualization Principles",
    "section": "",
    "text": "Ease comparisons by keeping axes the same when comparing data across multiple plots.\nAlign plots vertically to see horizontal changes. Align plots horizontally to see vertical changes.\nBar plots are useful for showing one number but not useful for showing distributions."
  },
  {
    "objectID": "series/R/2022/12/07/datavisualization_principles.html#consider-transformations",
    "href": "series/R/2022/12/07/datavisualization_principles.html#consider-transformations",
    "title": "Data Visualization Principles",
    "section": "",
    "text": "Use transformations when warranted to ease visual interpretation.\nThe log transformation is useful for data with multiplicative changes. The logistic transformation is useful for fold changes in odds. The square root transformation is useful for count data."
  },
  {
    "objectID": "series/R/2022/12/07/datavisualization_principles.html#ease-comparisons-compared-visual-cues-should-be-adjacent",
    "href": "series/R/2022/12/07/datavisualization_principles.html#ease-comparisons-compared-visual-cues-should-be-adjacent",
    "title": "Data Visualization Principles",
    "section": "",
    "text": "Textbook section on compared visual cues being adjacent\nTextbook section on using color\nTextbook section on considering the color blind\n\n\nWhen two groups are to be compared, it is optimal to place them adjacent in the plot.\nUse color to encode groups to be compared.\nConsider using a color blind friendly palette.\n\n\ncolor_blind_friendly_cols &lt;- c(\"#999999\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\n\np1 &lt;- data.frame(x = 1:8, y = 1:8, col = as.character(1:8)) %&gt;%\n    ggplot(aes(x, y, color = col)) +\n    geom_point(size = 5)\np1 + scale_color_manual(values = color_blind_friendly_cols)"
  },
  {
    "objectID": "series/R/2022/12/07/datavisualization_principles.html#slope-charts",
    "href": "series/R/2022/12/07/datavisualization_principles.html#slope-charts",
    "title": "Data Visualization Principles",
    "section": "",
    "text": "Plots for two variables\n\n\nConsider using a slope chart or Bland-Altman plot when comparing one variable at two different time points, especially for a small number of observations.\nSlope charts use angle to encode change. Use geom_line() to create slope charts. It is useful when comparing a small number of observations.\nThe Bland-Altman plot (Tukey mean difference plot, MA plot) graphs the difference between conditions on the y-axis and the mean between conditions on the x-axis. It is more appropriate for large numbers of observations than slope charts.\n\n\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(gapminder)\n\n\nwest &lt;- c(\"Western Europe\", \"Northern Europe\", \"Southern Europe\", \"Northern America\", \"Australia and New Zealand\")\n\ndat &lt;- gapminder %&gt;%\n    filter(year %in% c(2010, 2015) & region %in% west & !is.na(life_expectancy) & population &gt; 10^7)\n\ndat %&gt;%\n    mutate(location = ifelse(year == 2010, 1, 2),\n           location = ifelse(year == 2015 & country %in% c(\"United Kingdom\", \"Portugal\"),\n                             location + 0.22, location),\n           hjust = ifelse(year == 2010, 1, 0)) %&gt;%\n    mutate(year = as.factor(year)) %&gt;%\n    ggplot(aes(year, life_expectancy, group = country)) +\n    geom_line(aes(color = country), show.legend = FALSE) +\n    geom_text(aes(x = location, label = country, hjust = hjust), show.legend = FALSE) +\n    xlab(\"\") +\n    ylab(\"Life Expectancy\") \n\n\n\n\n\n\n\n\n\nlibrary(ggrepel)\n\n\ndat %&gt;%\n    mutate(year = paste0(\"life_expectancy_\", year)) %&gt;%\n    select(country, year, life_expectancy) %&gt;% spread(year, life_expectancy) %&gt;%\n    mutate(average = (life_expectancy_2015 + life_expectancy_2010)/2,\n                difference = life_expectancy_2015 - life_expectancy_2010) %&gt;%\n    ggplot(aes(average, difference, label = country)) +\n    geom_point() +\n    geom_text_repel() +\n    geom_abline(lty = 2) +\n    xlab(\"Average of 2010 and 2015\") +\n    ylab(\"Difference between 2015 and 2010\")"
  },
  {
    "objectID": "series/R/2022/12/07/datavisualization_principles.html#encoding-a-third-variable",
    "href": "series/R/2022/12/07/datavisualization_principles.html#encoding-a-third-variable",
    "title": "Data Visualization Principles",
    "section": "",
    "text": "Encoding a third variable\n\n\nEncode a categorical third variable on a scatterplot using color hue or shape. Use the shape argument to control shape.\nEncode a continuous third variable on a using color intensity or size."
  },
  {
    "objectID": "series/R/2022/12/07/datavisualization_principles.html#case-study-vaccines",
    "href": "series/R/2022/12/07/datavisualization_principles.html#case-study-vaccines",
    "title": "Data Visualization Principles",
    "section": "",
    "text": "Case study: vaccines and infectious diseases\ngeom_vline: Add vertical lines\n\n\nVaccines save millions of lives, but misinformation has led some to question the safety of vaccines. The data support vaccines as safe and effective. We visualize data about measles incidence in order to demonstrate the impact of vaccination programs on disease rate.\nThe RColorBrewer package offers several color palettes. Sequential color palettes are best suited for data that span from high to low. Diverging color palettes are best suited for data that are centered and diverge towards high or low values.\nThe geom_tile() geometry creates a grid of colored tiles. Position and length are stronger cues than color for numeric values, but color can be appropriate sometimes.\n\n\n# import data and inspect\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(us_contagious_diseases)\nstr(us_contagious_diseases)\n\n\n# assign dat to the per 10,000 rate of measles, removing Alaska and Hawaii and adjusting for weeks reporting\nthe_disease &lt;- \"Measles\"\ndat &lt;- us_contagious_diseases %&gt;%\n    filter(!state %in% c(\"Hawaii\", \"Alaska\") & disease == the_disease) %&gt;%\n    mutate(rate = count / population * 10000 * 52/weeks_reporting) %&gt;%\n    mutate(state = reorder(state, rate))\n\n# plot disease rates per year in California\ndat %&gt;% filter(state == \"California\" & !is.na(rate)) %&gt;%\n    ggplot(aes(year, rate)) +\n    geom_line() +\n    ylab(\"Cases per 10,000\") +\n    geom_vline(xintercept=1963, col = \"blue\")\n\n\n\n\n\n\n# tile plot of disease rate by state and year\ndat %&gt;% ggplot(aes(year, state, fill=rate)) +\n    geom_tile(color = \"grey50\") +\n    scale_x_continuous(expand = c(0,0)) +\n    scale_fill_gradientn(colors = RColorBrewer::brewer.pal(9, \"Reds\"), trans = \"sqrt\") +\n    geom_vline(xintercept = 1963, col = \"blue\") +\n    theme_minimal() + theme(panel.grid = element_blank()) +\n    ggtitle(the_disease) +\n    ylab(\"\") +\n    xlab(\"\")\n\n\n\n\n\n\n\n\n\n# compute US average measles rate by year\navg &lt;- us_contagious_diseases %&gt;%\n    filter(disease == the_disease) %&gt;% group_by(year) %&gt;%\n    summarize(us_rate = sum(count, na.rm = TRUE)/sum(population, na.rm = TRUE)*10000)\n\n# make line plot of measles rate by year by state\ndat %&gt;%\n    filter(!is.na(rate)) %&gt;%\n    ggplot() +\n    geom_line(aes(year, rate, group = state), color = \"grey50\", \n        show.legend = FALSE, alpha = 0.2, size = 1) +\n    geom_line(mapping = aes(year, us_rate), data = avg, size = 1, col = \"black\") +\n    scale_y_continuous(trans = \"sqrt\", breaks = c(5, 25, 125, 300)) +\n    ggtitle(\"Cases per 10,000 by state\") +\n    xlab(\"\") +\n    ylab(\"\") +\n    geom_text(data = data.frame(x = 1955, y = 50),\n        mapping = aes(x, y, label = \"US average\"), color = \"black\") +\n    geom_vline(xintercept = 1963, col = \"blue\")"
  },
  {
    "objectID": "series/R/2022/12/07/datavisualization_principles.html#avoid-pseudo-and-gratuitous-3d-plots",
    "href": "series/R/2022/12/07/datavisualization_principles.html#avoid-pseudo-and-gratuitous-3d-plots",
    "title": "Data Visualization Principles",
    "section": "",
    "text": "Avoid pseudo-three-dimensional plots\n\nIn general, pseudo-3D plots and gratuitous 3D plots only add confusion. Use regular 2D plots instead."
  },
  {
    "objectID": "series/R/2022/12/07/datavisualization_principles.html#avoid-too-many-significant-digits",
    "href": "series/R/2022/12/07/datavisualization_principles.html#avoid-too-many-significant-digits",
    "title": "Data Visualization Principles",
    "section": "",
    "text": "Avoid too many significant digits\n\n\nIn tables, avoid using too many significant digits. Too many digits can distract from the meaning of your data.\nReduce the number of significant digits globally by setting an option. For example, options(digits = 3) will cause all future computations that session to have 3 significant digits.\nReduce the number of digits locally using round() or signif()."
  },
  {
    "objectID": "series/R/2022/12/03/datavisualization_ggplot2.html",
    "href": "series/R/2022/12/03/datavisualization_ggplot2.html",
    "title": "Introduction to ggplot2",
    "section": "",
    "text": "After completing ggplot2, you will:\n\nbe able to use ggplot2 to create data visualizations in R.\nbe able to explain what the data component of a graph is.\nbe able to identify the geometry component of a graph and know when to use which type of geometry. be able to explain what the aesthetic mapping component of a graph is.\nbe able to understand the scale component of a graph and select an appropriate scale component to use.\n\n\n\nData visualization with ggolot2\nData visualization with ggplot2: Cheat Sheet\nThe R graph gallery example\n\n\nThroughout the series, we will create plots with the ggplot2 package. ggplot2 is part of the tidyverse suite of package, which you can load with library(tidyverse).\nNote that you can also load ggplot2 alone using the command library(ggplot2), instead of loading the entire tidyverse.\nggplot2 uses a grammar of graphics to break plots into building blocks that have intuitive syntax, making it easy to create relatively complex and aesthetically pleasing plots with relatively simple and readable code.\nggplot2 is designed to work excusively with tidy data (rows are observations and columns are variables).\n\n\n\nPlots in ggplot2 consist of 3 main components:\n\n\nData: The dataset being summarized\n\nGeometry: The type of plot(scatterplot, boxplot, barplot, histogram, qqplot, smooth desity, etc.)\n\nAesthetic mapping: Variable mapped to visual cues, such as x-axis and y-axis values and color.\n\n\n\n\nlibrary(dslabs)\ndata(murders)\n\n\n\n\n\nYou can associated a dataset x with a ggplot object with any of the 3 commands:\n\nggplot(data = x)\nggplot(x)\nx %&gt;% ggplot()\n\n\nYou can assign a ggplot object to a variable. If the object is not assigned to a variable, it will automatically be displayed.\nYou can display a ggplot object assigned to a variable by printing that variable.\n\nCode:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dslabs)\ndata(murders)\n\nggplot(data = murders)\n\n\n\n\n\n\nmurders %&gt;% ggplot()\n\n\n\n\n\n\np &lt;- ggplot(data = murders)\n\nclass(p)\n\n[1] \"gg\"     \"ggplot\"\n\nprint(p) # this is equivalent to simply typing p\n\n\n\n\n\n\np \n\n\n\n\n\n\n\n\n\n\nIn ggplot2, graphs are created by adding layers to the ggplot object: DATA %&gt;% ggplot() + LAYER_1 + LAYER_2 + … + LAYER_N\nThe geometry layer defines that plot type and takes the format geom_x where x is the plot type.\nAesthetic mappings describe how properties of the data connect with features of the graph (axis position, color, size, etc.) define aesthetic mapping with aes() function.\naes() uses variable names from the object component (for example, total rather than murders$total).\ngeom_point() creates a scatterplot and requires x and y aesthetic mappings.\ngeom_text() and geom_label add text to a scatterplot and require x, y, and label aesthetic mappings.\nTo determine which aesthetic mappings are required for a geometry, read the help file for that geometry.\nYou can add layers with different aesthetic mappings to the same graph.\n\nCode: Adding layers to a plot\n\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(murders)\n\nmurders %&gt;% ggplot() +\n  geom_point(aes(x = population/10^6, y = total))\n\n\n# add points layer to predefined ggplot object\np &lt;- ggplot(data = murders)\np + geom_point(aes(population/10^6, total))\n\n\n\n\n\n\n# add text layer to scatterplot\np + geom_point(aes(population/10^6, total)) +\n  geom_text(aes(population/10^6, total, label = abb))\n\n\n\n\n\n\n\nCode: Example of aes behavior\n\n# no error from this call\np_test &lt;- p + geom_text(aes(population/10^6, total, lable = abb))\n\n# error - \"abb\" is not a globally defined variable and cannot be found outside of aes\np_test &lt;- p + geom_text(aes(population/10^6, total), label = abb)\n\n\n\n\nYou can modify arguments to geometry functions others than aes() and the data.\nThese arguments are not aesthetic mappings: the affect all data points the same way.\nGlobal aesthetic mappings apply to all geometries and can be defined when you initially call ggplot(). All the geometries added as layers will default to this mapping. Local aesthetic mapping add additional information or override the default mappings.\n\n\n\n\n\n\n\nNudge points a fixed distance\n\n\n\nposition_nudge(x = 0, y = 0) is generally useful for adjusting the position of items on discrete scales by a small amount. Nudging is built in to geom_text() because it’s so useful for moving labels a small distance from what they’re labeling.\n\n\nCode:\n\n# change the size of the points\np + geom_point(aes(population/10^6, total), size = 3) +\n    geom_text(aes(population/10^6, total, label = abb))\n\n\n\n\n\n\n# move text labels slightly to the right\np + geom_point(aes(population/10^6, total), size = 3) +\n    geom_text(aes(population/10^6, total, label = abb), nudge_x = 1)\n\n\n\n\n\n\n# simplify code by adding global aesthetic\np &lt;- murders %&gt;% ggplot(aes(population/10^6, total, label = abb))\np + geom_point(size = 3) +\n    geom_text(nudge_x = 1.5)\n\n\n\n\n\n\n# local aesthetics override global aesthetics\np + geom_point(size = 3) +\n  geom_text(aes(x = 10, y = 800, label = \"Hello there!\"))\n\n\n\n\n\n\n\n\n\n\nTextbook section on scales\nTextbook section on labels and titles\nTextbook section on categories as colors\nTextbook section on annotation, shapes and adjustments\n\n\nConvert the x-axis to log scale with scale_x_continuous(trans = \"log10\") or scale_x_log10(). Similar function exist for the y-axis.\nAdd axis title with xlab() and ylab() function. Add a plot title with the ggtitle() function.\nAdd a color mapping that colors points by a varaibale by defining col argument within aes(). To color all pints the same way, define col outside of aes().\nAdd a line with the geom_abline() geometry. geom_abline() takes arguments slop (default = 1) and intercept(default = 0). Change the color with col or color and line type with lty.\nPlacing the line layer after the point layer will overlay the the line on top of the points. To overlay points on the line, place the line layer before the point layer.\nThere are many additional ways to tweak your graph that can be found in the ggplot2 documentation, cheat sheet or on the internet. For example, you can change the legend title with scale_color_discrete.\n\n\n# define p\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(murders)\n\np &lt;- murders %&gt;% ggplot(aes(population/10^6, total, label = abb))\n\n# log base 10 scale the x-axis and y-axis\np + geom_point(size = 3) +\n    geom_text(nudge_x = 0.05) +\n    scale_x_continuous(trans = \"log10\") +\n    scale_y_continuous(trans = \"log10\")\n\n\n# efficient log scaling of the axes\np + geom_point(size = 3) +\n    geom_text(nudge_x = 0.05) +\n    scale_x_log10() +\n    scale_y_log10()\n\n\n\n\n\n\n\n\n\np + geom_point(size = 3) +\n    geom_text(nudge_x = 0.05) +\n    scale_x_log10() +\n    scale_y_log10() +\n    xlab(\"Population in million(log scale)\") +\n    ylab(\"Total number of murders(log scale)\") +\n    ggtitle(\"US Gun Murders in 2010\")\n\n\n\n\n\n\n\n\n\n# redefine p to be everything except the points layer\np &lt;- murders %&gt;% \n     ggplot(aes(population/10^6, total, label = abb)) +\n     geom_text(nudge_x = 0.075) +\n     scale_x_log10() +\n     scale_y_log10() +\n     xlab(\"Population in million(log scale)\") +\n     ylab(\"Total number of murders(log scale)\") +\n     ggtitle(\"US Gun Murders in 2010\")\n\n\n# make all points blue\np + geom_point(size = 3, color = \"blue\")\n\n\n\n\n\n\n\n\n# color points by region\np + geom_point(aes(col = region), size = 3)\n\n\n\n\n\n\n\n\n\nr &lt;- murders %&gt;% \n     summarize(rate = sum(total) / sum(population) * 10^6) %&gt;%      pull(rate)\n\np &lt;- p + geom_point(aes(col = region), size = 3) +\n         geom_abline(intercept = log10(r)) # slop is default of 1\n\n# change line to dashed and dark grey, line under points\np + geom_abline(intercept = log(r), lty = 2, color = \"darkgrey\") +\n    geom_point(aes(col = region), size = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nLine types in R: Ity\n\n\n\nThe different line types available in R are shown in the figure hereafter. The argument lty can be used to specify the line type. To change line width, the argument lwd can be used.\n\n\n\n\n# capitalize legend title\np &lt;- p + scale_color_discrete(name = \"Region\")\np\n\n\n\n\n\n\n\n\n\n\nTextbook section on add-on packages\nTextbook section on putting it all together\n\n\nThe style of a ggplot graph can be changed using the theme() function.\nThe ggthemes package adds additional themes.\nThe ggrepel package includes a geometry that repels text labels, ensuring they do not overlap with each other: geom_text_repel().\n\n\n# theme used for graphs in the textbook and course\nlibrary(dslabs)\nds_theme_set()\n\n\n# themes from ggthemes\nlibrary(ggthemes)\n\n\np + theme_economist()    # style of the Economist magazine\n\n\n\n\n\n\np + theme_fivethirtyeight()    # style of the FiveThirtyEight website\n\n\n\n\n\n\n\n\n\n# load libraries\nlibrary(tidyverse)\nlibrary(ggrepel)\nlibrary(ggthemes)\nlibrary(dslabs)\ndata(murders)\n\n\n# define the intercept\nr &lt;- murders %&gt;%\n    summarize(rate = sum(total) / sum(population) * 10^6) %&gt;%\n    .$rate\n    \n# make the plot, combining all elements\nmurders %&gt;%\n    ggplot(aes(population/10^6, total, label = abb)) +\n    geom_abline(intercept = log10(r), lty = 2, color = \"darkgrey\") +\n    geom_point(aes(col = region), size = 3) +\n    geom_text_repel() +\n    scale_x_log10() +\n    scale_y_log10() +\n    xlab(\"Population in millions (log scale)\") +\n    ylab(\"Total number of murders (log scale)\") +\n    ggtitle(\"US Gun Murders in 2010\") +\n    scale_color_discrete(name = \"Region\") +\n    theme_economist()\n\n\n\n\n\n\n\n\n\n\nTextbook section on histograms\nTextbook section on density plots\nTextbook section on grids of plots\n\n\ngeom_histogram() creates a histogram. Use the binwidth argument to change the width of bins, the fill argument to change the bar fill color, and the col argument to change bar outline color.\ngeom_density() creates smooth density plots. Change the fill color of the plot with the fill argument.\ngeom_qq() creates a quantile-quantile plot. This geometry requires the sample argument. By default, the data are compared to a standard normal distribution with a mean of 0 and standard deviation of 1. This can be changed with the dparams argument, or the sample data can be scaled.\nPlots can be arranged adjacent to each other using the grid.arrange() function from the gridExtra package. First, create the plots and save them to objects (p1, p2, …). Then pass the plot objects to grid.arrange().\n\n\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(heights)\n\n# define p\np &lt;- heights %&gt;% \n  filter(sex == \"Male\") %&gt;% \n  ggplot(aes(x=height))\n\n\n# basic histograms\np + geom_histogram() + ggtitle(\"binwidth is default\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\np + geom_histogram(binwidth = 1) + ggtitle(\"binwidth is 1\")\n\n\n\n\n\n\n# histogram with blue fill, black outline, labels and title\np + geom_histogram(binwidth = 1, fill =\"blue\", col = \"black\") + \n  xlab(\"Male heights in inches\") +\n  ggtitle(\"histogram\")\n\n\n\n\n\n\n\n\n\np + geom_density()\n\n\n\n\n\n\np + geom_density(fill = \"blue\", col = \"red\") +\n  xlab(\"Male heights in inches\") +\n  ylab(\"proportion of Male heights\") +\n  ggtitle(\"Male heights distribution\")\n\n\n\n\n\n\n\n\n\n# basic QQ-plot\np &lt;- heights %&gt;% filter(sex == \"Male\") %&gt;% \n  ggplot(aes(sample = height))\np + geom_qq()\n\n\n\n\n\n\n# QQ-plot against a normal distribution with same mean/sd as data\nparams &lt;- heights %&gt;% \n  filter(sex == \"Male\") %&gt;% \n  summarize(mean = mean(height), sd = sd(height))\np + geom_qq(dparams = params) +\n  geom_abline()\n\n\n\n\n\n\n# QQ-plot of scaled data against the standard normal distribution\nheights %&gt;% \n  ggplot(aes(sample = scale(height))) +\n  geom_qq() +\n  geom_abline()\n\n\n\n\n\n\n\n\n# define plots p1, p2, p3\np &lt;- heights %&gt;% filter(sex == \"Male\") %&gt;% ggplot(aes(x = height))\np1 &lt;- p + geom_histogram(binwidth = 1, fill = \"blue\", col = \"black\")\np2 &lt;- p + geom_histogram(binwidth = 2, fill = \"blue\", col = \"black\")\np3 &lt;- p + geom_histogram(binwidth = 3, fill = \"blue\", col = \"black\")\n\n\n# arrange plots next to each other in 1 row, 3 columns\nlibrary(gridExtra)\n\n\ngrid.arrange(p1, p2, p3, ncol = 3)"
  },
  {
    "objectID": "series/R/2022/12/03/datavisualization_ggplot2.html#overview",
    "href": "series/R/2022/12/03/datavisualization_ggplot2.html#overview",
    "title": "Introduction to ggplot2",
    "section": "",
    "text": "After completing ggplot2, you will:\n\nbe able to use ggplot2 to create data visualizations in R.\nbe able to explain what the data component of a graph is.\nbe able to identify the geometry component of a graph and know when to use which type of geometry. be able to explain what the aesthetic mapping component of a graph is.\nbe able to understand the scale component of a graph and select an appropriate scale component to use."
  },
  {
    "objectID": "series/R/2022/12/03/datavisualization_ggplot2.html#ggplot",
    "href": "series/R/2022/12/03/datavisualization_ggplot2.html#ggplot",
    "title": "Introduction to ggplot2",
    "section": "",
    "text": "Data visualization with ggolot2\nData visualization with ggplot2: Cheat Sheet\nThe R graph gallery example\n\n\nThroughout the series, we will create plots with the ggplot2 package. ggplot2 is part of the tidyverse suite of package, which you can load with library(tidyverse).\nNote that you can also load ggplot2 alone using the command library(ggplot2), instead of loading the entire tidyverse.\nggplot2 uses a grammar of graphics to break plots into building blocks that have intuitive syntax, making it easy to create relatively complex and aesthetically pleasing plots with relatively simple and readable code.\nggplot2 is designed to work excusively with tidy data (rows are observations and columns are variables)."
  },
  {
    "objectID": "series/R/2022/12/03/datavisualization_ggplot2.html#graph-components",
    "href": "series/R/2022/12/03/datavisualization_ggplot2.html#graph-components",
    "title": "Introduction to ggplot2",
    "section": "",
    "text": "Plots in ggplot2 consist of 3 main components:\n\n\nData: The dataset being summarized\n\nGeometry: The type of plot(scatterplot, boxplot, barplot, histogram, qqplot, smooth desity, etc.)\n\nAesthetic mapping: Variable mapped to visual cues, such as x-axis and y-axis values and color.\n\n\n\n\nlibrary(dslabs)\ndata(murders)"
  },
  {
    "objectID": "series/R/2022/12/03/datavisualization_ggplot2.html#creating-a-new-plot",
    "href": "series/R/2022/12/03/datavisualization_ggplot2.html#creating-a-new-plot",
    "title": "Introduction to ggplot2",
    "section": "",
    "text": "You can associated a dataset x with a ggplot object with any of the 3 commands:\n\nggplot(data = x)\nggplot(x)\nx %&gt;% ggplot()\n\n\nYou can assign a ggplot object to a variable. If the object is not assigned to a variable, it will automatically be displayed.\nYou can display a ggplot object assigned to a variable by printing that variable.\n\nCode:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dslabs)\ndata(murders)\n\nggplot(data = murders)\n\n\n\n\n\n\nmurders %&gt;% ggplot()\n\n\n\n\n\n\np &lt;- ggplot(data = murders)\n\nclass(p)\n\n[1] \"gg\"     \"ggplot\"\n\nprint(p) # this is equivalent to simply typing p\n\n\n\n\n\n\np"
  },
  {
    "objectID": "series/R/2022/12/03/datavisualization_ggplot2.html#layers",
    "href": "series/R/2022/12/03/datavisualization_ggplot2.html#layers",
    "title": "Introduction to ggplot2",
    "section": "",
    "text": "In ggplot2, graphs are created by adding layers to the ggplot object: DATA %&gt;% ggplot() + LAYER_1 + LAYER_2 + … + LAYER_N\nThe geometry layer defines that plot type and takes the format geom_x where x is the plot type.\nAesthetic mappings describe how properties of the data connect with features of the graph (axis position, color, size, etc.) define aesthetic mapping with aes() function.\naes() uses variable names from the object component (for example, total rather than murders$total).\ngeom_point() creates a scatterplot and requires x and y aesthetic mappings.\ngeom_text() and geom_label add text to a scatterplot and require x, y, and label aesthetic mappings.\nTo determine which aesthetic mappings are required for a geometry, read the help file for that geometry.\nYou can add layers with different aesthetic mappings to the same graph.\n\nCode: Adding layers to a plot\n\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(murders)\n\nmurders %&gt;% ggplot() +\n  geom_point(aes(x = population/10^6, y = total))\n\n\n# add points layer to predefined ggplot object\np &lt;- ggplot(data = murders)\np + geom_point(aes(population/10^6, total))\n\n\n\n\n\n\n# add text layer to scatterplot\np + geom_point(aes(population/10^6, total)) +\n  geom_text(aes(population/10^6, total, label = abb))\n\n\n\n\n\n\n\nCode: Example of aes behavior\n\n# no error from this call\np_test &lt;- p + geom_text(aes(population/10^6, total, lable = abb))\n\n# error - \"abb\" is not a globally defined variable and cannot be found outside of aes\np_test &lt;- p + geom_text(aes(population/10^6, total), label = abb)"
  },
  {
    "objectID": "series/R/2022/12/03/datavisualization_ggplot2.html#thinkering",
    "href": "series/R/2022/12/03/datavisualization_ggplot2.html#thinkering",
    "title": "Introduction to ggplot2",
    "section": "",
    "text": "You can modify arguments to geometry functions others than aes() and the data.\nThese arguments are not aesthetic mappings: the affect all data points the same way.\nGlobal aesthetic mappings apply to all geometries and can be defined when you initially call ggplot(). All the geometries added as layers will default to this mapping. Local aesthetic mapping add additional information or override the default mappings.\n\n\n\n\n\n\n\nNudge points a fixed distance\n\n\n\nposition_nudge(x = 0, y = 0) is generally useful for adjusting the position of items on discrete scales by a small amount. Nudging is built in to geom_text() because it’s so useful for moving labels a small distance from what they’re labeling.\n\n\nCode:\n\n# change the size of the points\np + geom_point(aes(population/10^6, total), size = 3) +\n    geom_text(aes(population/10^6, total, label = abb))\n\n\n\n\n\n\n# move text labels slightly to the right\np + geom_point(aes(population/10^6, total), size = 3) +\n    geom_text(aes(population/10^6, total, label = abb), nudge_x = 1)\n\n\n\n\n\n\n# simplify code by adding global aesthetic\np &lt;- murders %&gt;% ggplot(aes(population/10^6, total, label = abb))\np + geom_point(size = 3) +\n    geom_text(nudge_x = 1.5)\n\n\n\n\n\n\n# local aesthetics override global aesthetics\np + geom_point(size = 3) +\n  geom_text(aes(x = 10, y = 800, label = \"Hello there!\"))"
  },
  {
    "objectID": "series/R/2022/12/03/datavisualization_ggplot2.html#scales-labels-and-colors",
    "href": "series/R/2022/12/03/datavisualization_ggplot2.html#scales-labels-and-colors",
    "title": "Introduction to ggplot2",
    "section": "",
    "text": "Textbook section on scales\nTextbook section on labels and titles\nTextbook section on categories as colors\nTextbook section on annotation, shapes and adjustments\n\n\nConvert the x-axis to log scale with scale_x_continuous(trans = \"log10\") or scale_x_log10(). Similar function exist for the y-axis.\nAdd axis title with xlab() and ylab() function. Add a plot title with the ggtitle() function.\nAdd a color mapping that colors points by a varaibale by defining col argument within aes(). To color all pints the same way, define col outside of aes().\nAdd a line with the geom_abline() geometry. geom_abline() takes arguments slop (default = 1) and intercept(default = 0). Change the color with col or color and line type with lty.\nPlacing the line layer after the point layer will overlay the the line on top of the points. To overlay points on the line, place the line layer before the point layer.\nThere are many additional ways to tweak your graph that can be found in the ggplot2 documentation, cheat sheet or on the internet. For example, you can change the legend title with scale_color_discrete.\n\n\n# define p\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(murders)\n\np &lt;- murders %&gt;% ggplot(aes(population/10^6, total, label = abb))\n\n# log base 10 scale the x-axis and y-axis\np + geom_point(size = 3) +\n    geom_text(nudge_x = 0.05) +\n    scale_x_continuous(trans = \"log10\") +\n    scale_y_continuous(trans = \"log10\")\n\n\n# efficient log scaling of the axes\np + geom_point(size = 3) +\n    geom_text(nudge_x = 0.05) +\n    scale_x_log10() +\n    scale_y_log10()\n\n\n\n\n\n\n\n\n\np + geom_point(size = 3) +\n    geom_text(nudge_x = 0.05) +\n    scale_x_log10() +\n    scale_y_log10() +\n    xlab(\"Population in million(log scale)\") +\n    ylab(\"Total number of murders(log scale)\") +\n    ggtitle(\"US Gun Murders in 2010\")\n\n\n\n\n\n\n\n\n\n# redefine p to be everything except the points layer\np &lt;- murders %&gt;% \n     ggplot(aes(population/10^6, total, label = abb)) +\n     geom_text(nudge_x = 0.075) +\n     scale_x_log10() +\n     scale_y_log10() +\n     xlab(\"Population in million(log scale)\") +\n     ylab(\"Total number of murders(log scale)\") +\n     ggtitle(\"US Gun Murders in 2010\")\n\n\n# make all points blue\np + geom_point(size = 3, color = \"blue\")\n\n\n\n\n\n\n\n\n# color points by region\np + geom_point(aes(col = region), size = 3)\n\n\n\n\n\n\n\n\n\nr &lt;- murders %&gt;% \n     summarize(rate = sum(total) / sum(population) * 10^6) %&gt;%      pull(rate)\n\np &lt;- p + geom_point(aes(col = region), size = 3) +\n         geom_abline(intercept = log10(r)) # slop is default of 1\n\n# change line to dashed and dark grey, line under points\np + geom_abline(intercept = log(r), lty = 2, color = \"darkgrey\") +\n    geom_point(aes(col = region), size = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nLine types in R: Ity\n\n\n\nThe different line types available in R are shown in the figure hereafter. The argument lty can be used to specify the line type. To change line width, the argument lwd can be used.\n\n\n\n\n# capitalize legend title\np &lt;- p + scale_color_discrete(name = \"Region\")\np"
  },
  {
    "objectID": "series/R/2022/12/03/datavisualization_ggplot2.html#add-on-packages",
    "href": "series/R/2022/12/03/datavisualization_ggplot2.html#add-on-packages",
    "title": "Introduction to ggplot2",
    "section": "",
    "text": "Textbook section on add-on packages\nTextbook section on putting it all together\n\n\nThe style of a ggplot graph can be changed using the theme() function.\nThe ggthemes package adds additional themes.\nThe ggrepel package includes a geometry that repels text labels, ensuring they do not overlap with each other: geom_text_repel().\n\n\n# theme used for graphs in the textbook and course\nlibrary(dslabs)\nds_theme_set()\n\n\n# themes from ggthemes\nlibrary(ggthemes)\n\n\np + theme_economist()    # style of the Economist magazine\n\n\n\n\n\n\np + theme_fivethirtyeight()    # style of the FiveThirtyEight website\n\n\n\n\n\n\n\n\n\n# load libraries\nlibrary(tidyverse)\nlibrary(ggrepel)\nlibrary(ggthemes)\nlibrary(dslabs)\ndata(murders)\n\n\n# define the intercept\nr &lt;- murders %&gt;%\n    summarize(rate = sum(total) / sum(population) * 10^6) %&gt;%\n    .$rate\n    \n# make the plot, combining all elements\nmurders %&gt;%\n    ggplot(aes(population/10^6, total, label = abb)) +\n    geom_abline(intercept = log10(r), lty = 2, color = \"darkgrey\") +\n    geom_point(aes(col = region), size = 3) +\n    geom_text_repel() +\n    scale_x_log10() +\n    scale_y_log10() +\n    xlab(\"Population in millions (log scale)\") +\n    ylab(\"Total number of murders (log scale)\") +\n    ggtitle(\"US Gun Murders in 2010\") +\n    scale_color_discrete(name = \"Region\") +\n    theme_economist()"
  },
  {
    "objectID": "series/R/2022/12/03/datavisualization_ggplot2.html#other-examples",
    "href": "series/R/2022/12/03/datavisualization_ggplot2.html#other-examples",
    "title": "Introduction to ggplot2",
    "section": "",
    "text": "Textbook section on histograms\nTextbook section on density plots\nTextbook section on grids of plots\n\n\ngeom_histogram() creates a histogram. Use the binwidth argument to change the width of bins, the fill argument to change the bar fill color, and the col argument to change bar outline color.\ngeom_density() creates smooth density plots. Change the fill color of the plot with the fill argument.\ngeom_qq() creates a quantile-quantile plot. This geometry requires the sample argument. By default, the data are compared to a standard normal distribution with a mean of 0 and standard deviation of 1. This can be changed with the dparams argument, or the sample data can be scaled.\nPlots can be arranged adjacent to each other using the grid.arrange() function from the gridExtra package. First, create the plots and save them to objects (p1, p2, …). Then pass the plot objects to grid.arrange().\n\n\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(heights)\n\n# define p\np &lt;- heights %&gt;% \n  filter(sex == \"Male\") %&gt;% \n  ggplot(aes(x=height))\n\n\n# basic histograms\np + geom_histogram() + ggtitle(\"binwidth is default\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\np + geom_histogram(binwidth = 1) + ggtitle(\"binwidth is 1\")\n\n\n\n\n\n\n# histogram with blue fill, black outline, labels and title\np + geom_histogram(binwidth = 1, fill =\"blue\", col = \"black\") + \n  xlab(\"Male heights in inches\") +\n  ggtitle(\"histogram\")\n\n\n\n\n\n\n\n\n\np + geom_density()\n\n\n\n\n\n\np + geom_density(fill = \"blue\", col = \"red\") +\n  xlab(\"Male heights in inches\") +\n  ylab(\"proportion of Male heights\") +\n  ggtitle(\"Male heights distribution\")\n\n\n\n\n\n\n\n\n\n# basic QQ-plot\np &lt;- heights %&gt;% filter(sex == \"Male\") %&gt;% \n  ggplot(aes(sample = height))\np + geom_qq()\n\n\n\n\n\n\n# QQ-plot against a normal distribution with same mean/sd as data\nparams &lt;- heights %&gt;% \n  filter(sex == \"Male\") %&gt;% \n  summarize(mean = mean(height), sd = sd(height))\np + geom_qq(dparams = params) +\n  geom_abline()\n\n\n\n\n\n\n# QQ-plot of scaled data against the standard normal distribution\nheights %&gt;% \n  ggplot(aes(sample = scale(height))) +\n  geom_qq() +\n  geom_abline()\n\n\n\n\n\n\n\n\n# define plots p1, p2, p3\np &lt;- heights %&gt;% filter(sex == \"Male\") %&gt;% ggplot(aes(x = height))\np1 &lt;- p + geom_histogram(binwidth = 1, fill = \"blue\", col = \"black\")\np2 &lt;- p + geom_histogram(binwidth = 2, fill = \"blue\", col = \"black\")\np3 &lt;- p + geom_histogram(binwidth = 3, fill = \"blue\", col = \"black\")\n\n\n# arrange plots next to each other in 1 row, 3 columns\nlibrary(gridExtra)\n\n\ngrid.arrange(p1, p2, p3, ncol = 3)"
  },
  {
    "objectID": "series/R/2022/11/28/rbasics_vectors_sorting.html",
    "href": "series/R/2022/11/28/rbasics_vectors_sorting.html",
    "title": "Refining R Vectors and Essential Sorting Techniques",
    "section": "",
    "text": "In today’s blog, we’ll delve into two fundamental R concepts: vectors and sorting. Both are crucial when dealing with data, and a good understanding of these will lay a solid foundation for more complex data operations."
  },
  {
    "objectID": "series/R/2022/11/28/rbasics_vectors_sorting.html#creating-numeric-and-character-vectors",
    "href": "series/R/2022/11/28/rbasics_vectors_sorting.html#creating-numeric-and-character-vectors",
    "title": "Refining R Vectors and Essential Sorting Techniques",
    "section": "Creating Numeric and Character Vectors",
    "text": "Creating Numeric and Character Vectors\nCreating vectors is straightforward. Use the c() function, which stand for ” combine”.\n\n# Number Vector\ncodes &lt;- c(380, 124, 818)\ncodes\n\n# Character Vector\ncountry &lt;- c(\"italy\", \"canada\", \"egypt\")\ncountry"
  },
  {
    "objectID": "series/R/2022/11/28/rbasics_vectors_sorting.html#naming-the-elements-of-a-vector",
    "href": "series/R/2022/11/28/rbasics_vectors_sorting.html#naming-the-elements-of-a-vector",
    "title": "Refining R Vectors and Essential Sorting Techniques",
    "section": "Naming the Elements of a Vector",
    "text": "Naming the Elements of a Vector\n\n\nUsing names() function\n\ncodes &lt;- c(380, 124, 818)\ncountry &lt;- c(\"italy\", \"canada\", \"egypt\")\nnames(codes) &lt;- country\n\n\n\nUsing c() function\n\n# Note that two lines of code below have the same result\ncodes &lt;- c(italy = 380, canada = 124, egypt = 818)\ncodes &lt;- c(\"italy\" = 380, \"canada\" = 124, \"egypt\" = 818)"
  },
  {
    "objectID": "series/R/2022/11/28/rbasics_vectors_sorting.html#generating-numeric-sequences",
    "href": "series/R/2022/11/28/rbasics_vectors_sorting.html#generating-numeric-sequences",
    "title": "Refining R Vectors and Essential Sorting Techniques",
    "section": "Generating Numeric Sequences",
    "text": "Generating Numeric Sequences\nFor generating a sequence of numbers, use seq() or : operator.\n\n# Using seq()\nsequence &lt;- seq(from = 1, to = 10, by =2)\nsequence \n\n# Using :\nsequemce &lt;- 1:10\nsequemce"
  },
  {
    "objectID": "series/R/2022/11/28/rbasics_vectors_sorting.html#accessing-specific-elements-or-parts-of-a-vector",
    "href": "series/R/2022/11/28/rbasics_vectors_sorting.html#accessing-specific-elements-or-parts-of-a-vector",
    "title": "Refining R Vectors and Essential Sorting Techniques",
    "section": "Accessing Specific Elements or Parts of a Vector",
    "text": "Accessing Specific Elements or Parts of a Vector\nTo access specific elements in a vector, use brackets [] and specify the index.\n\n# Using square bracket to access specific elements of a vector\ncodes[2]\ncodes[c(1, 3)]\ncodes[1:2]\n\n# If the entries of a vector are named, they may be accessed by referring to their name\ncodes[\"canada\"]\ncodes[c(\"egypt\", \"italy\")]"
  },
  {
    "objectID": "series/R/2022/11/28/rbasics_vectors_sorting.html#coercing-data-into-different-types",
    "href": "series/R/2022/11/28/rbasics_vectors_sorting.html#coercing-data-into-different-types",
    "title": "Refining R Vectors and Essential Sorting Techniques",
    "section": "Coercing Data into Different Types",
    "text": "Coercing Data into Different Types\nData coercion is the process of converting data from one type to another. Below are some common R functions used for coercion:\n\n\nas.numeric(): Converts to numeric type.\n\nchar_vector &lt;- c(\"1\", \"2\", \"3\")\nnum_vector &lt;- as.numeric(char_vector)\nprint(num_vector)\n\n# verify a data type\nclass(num_vector)\n\n\n\nas.character(): Converts to character type.\n\nnum_vector &lt;- c(1, 2, 3)\nchar_vector &lt;- as.character(num_vector)\nprint(char_vector)\n\n\n\nas.factor(): Converts to factor type.\n\nchar_vector &lt;- c(\"male\", \"female\", \"male\")\nfactor_vector &lt;- as.factor(char_vector)\nprint(factor_vector)\n\n\n\nas.integer(): Converts to integer type.\n\nnum_vector &lt;- c(1.2, 2.5, 3.7)\nint_vector &lt;- as.integer(num_vector)\nprint(int_vector)\n\n\n\nas.logical(): Converts to logical type.\nAny non-zero numeric value will be converted to TRUE and zero will be converted to FALSE. For character vectors, “TRUE” will be converted to TRUE and anything else will be converted to FALSE.\n\nnum_vector &lt;- c(1, 0, 2)\nlogical_vector &lt;- as.logical(num_vector)\nprint(logical_vector)\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nYou can also coerce matrices and data frames to other types using these same functions. But remember that when coercing complex types like lists or data frames, every element must be convertible to the final type, or the operation will result in an error or NA values.\n\n\nQuestion\n\nwhy class(3L) is integer ?\nwhy 3L-3 equals 0 ?"
  },
  {
    "objectID": "series/R/2022/11/28/rbasics_vectors_sorting.html#sorting-vectors",
    "href": "series/R/2022/11/28/rbasics_vectors_sorting.html#sorting-vectors",
    "title": "Refining R Vectors and Essential Sorting Techniques",
    "section": "Sorting Vectors",
    "text": "Sorting Vectors\nTo sort a vector in ascending or descending order, you can use the sort() function.\n\n# load package and dataset\nlibrary(dslabs)\ndata(murders)\n\n# Sorting\nx &lt;- sort(murders$total) # puts elements in order\n\n# Descending order\ny &lt;- sort(murders$total, decreasing = TRUE) # put elements from big to small"
  },
  {
    "objectID": "series/R/2022/11/28/rbasics_vectors_sorting.html#finding-indices-of-sorted-elements",
    "href": "series/R/2022/11/28/rbasics_vectors_sorting.html#finding-indices-of-sorted-elements",
    "title": "Refining R Vectors and Essential Sorting Techniques",
    "section": "Finding Indices of Sorted Elements",
    "text": "Finding Indices of Sorted Elements\nIf you want to get the indices of the sorted elements (rather than the sorted elements themselves), you can use the order() function.\n\nindex &lt;- order(x) # returns index that will put x in order\nx[index] # rearrange by this index puts elements in order\norder(x)\n\nindex &lt;- order(murders$total) # order murder numbers by small to big\nmurders$abb[index] # order abbreviations by total murders"
  },
  {
    "objectID": "series/R/2022/11/28/rbasics_vectors_sorting.html#finding-maxima-and-minima",
    "href": "series/R/2022/11/28/rbasics_vectors_sorting.html#finding-maxima-and-minima",
    "title": "Refining R Vectors and Essential Sorting Techniques",
    "section": "Finding Maxima and Minima",
    "text": "Finding Maxima and Minima\nR provides function max(), min(), which.max(), and which.min() to find the maximum and minimum elements and their indices:\n\n# Max and Min\nmax_value &lt;- max(murders$total) # return the largest elements\nmax_value\n\nmin_value &lt;- min(murders$total) # return the smallest elements\nmin_value\n\n# Indices of Max and Min\nmax_index &lt;- which.max(murders$total) # index with highest number of murders(第几个数字最大)\nmax_index # 第5个数字最大\nmurders$state[max_index] # state name with highest number of total murders\n\nmin_index &lt;- which.min(murders$total) \nmin_index # 第46个数字最小\nmurders$state[min_index] # state name with lowest number of total murders"
  },
  {
    "objectID": "series/R/2022/11/28/rbasics_vectors_sorting.html#ranking-elements",
    "href": "series/R/2022/11/28/rbasics_vectors_sorting.html#ranking-elements",
    "title": "Refining R Vectors and Essential Sorting Techniques",
    "section": "Ranking Elements",
    "text": "Ranking Elements\nThe rank function provides the ranks of the elements in a vector:\n\nrank(murders$population) \n\n\n\n\nTable 1: The Differences of Sort, Order and Rank\n\n\nOriginal\nSort\nOrder\nRank\n\n\n31\n4\n2\n3\n\n\n4\n15\n3\n1\n\n\n15\n31\n1\n2\n\n\n92\n65\n5\n5\n\n\n65\n92\n4\n4\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nExplanation of Table 1\n\nSort: 按从小到大排列\nOrder: Sort对应数字在原来数字排列中的顺序\nRank: Original原来数字在Sort顺序中的排名"
  },
  {
    "objectID": "series/R/2022/11/28/rbasics_vectors_sorting.html#vector-arithmetic",
    "href": "series/R/2022/11/28/rbasics_vectors_sorting.html#vector-arithmetic",
    "title": "Refining R Vectors and Essential Sorting Techniques",
    "section": "Vector Arithmetic",
    "text": "Vector Arithmetic\nYou can perform arithmetic operations between vectors and number, as well as between vectors themselves."
  },
  {
    "objectID": "series/R/2022/11/28/rbasics_vectors_sorting.html#arithmetic-with-a-single-number",
    "href": "series/R/2022/11/28/rbasics_vectors_sorting.html#arithmetic-with-a-single-number",
    "title": "Refining R Vectors and Essential Sorting Techniques",
    "section": "Arithmetic with a Single Number",
    "text": "Arithmetic with a Single Number\nYou can perform an operation between a vector and a single number, which applies the operation to each element of the vector:\n\n# Adding 2 to all elements of a vector\nnew_vec &lt;- codes +2\nnew_vec"
  },
  {
    "objectID": "series/R/2022/11/28/rbasics_vectors_sorting.html#arithmetic-with-two-vectors",
    "href": "series/R/2022/11/28/rbasics_vectors_sorting.html#arithmetic-with-two-vectors",
    "title": "Refining R Vectors and Essential Sorting Techniques",
    "section": "Arithmetic with Two Vectors",
    "text": "Arithmetic with Two Vectors\nYou can also perform arithmetic operations between two vectors of the same length:\n\n# Addition of two vectors\nvec1 &lt;- c(1,2,3)\nvec2 &lt;- c(4,5,6)\nresult &lt;- vec1 + vec2 # we add two vectors element-wise \nprint(result)"
  },
  {
    "objectID": "series/R/2022/11/28/rbasics_vectors_sorting.html#example-for-vector-arithmetic-by-murders-dataset",
    "href": "series/R/2022/11/28/rbasics_vectors_sorting.html#example-for-vector-arithmetic-by-murders-dataset",
    "title": "Refining R Vectors and Essential Sorting Techniques",
    "section": "Example for Vector Arithmetic by Murders dataset",
    "text": "Example for Vector Arithmetic by Murders dataset\n\n# The name of the state with the maximum population is found by doing the following\nmurders$state[which.max(murders$population)]\n\n# how to obtain the murder rate\nmurder_rate &lt;- murders$total / murders$population * 100000\n\n# ordering the states by murder rate, in decreasing order\nmurders$state[order(murder_rate, decreasing=TRUE)]"
  },
  {
    "objectID": "series/R/2022/11/27/rbasics_an_introduction_to_r.html",
    "href": "series/R/2022/11/27/rbasics_an_introduction_to_r.html",
    "title": "An Introduction to R: Mastering the Basics",
    "section": "",
    "text": "R is a language and environment for statistical computing and graphics 1. It provides a comprehensive set of tools and libraries that make it a preferred choice among data scientists, statisticians, and researcher.\nIn this blog, I will mainly explore the basics of R programming, including objects, operations, functions, and data types.\nHowever, before start this blog, please make sure you already set up R development environment.\nFor more information about how to setting up, you can read Posts page: how to install R and Rstudio."
  },
  {
    "objectID": "series/R/2022/11/27/rbasics_an_introduction_to_r.html#running-a-single-line-of-code",
    "href": "series/R/2022/11/27/rbasics_an_introduction_to_r.html#running-a-single-line-of-code",
    "title": "An Introduction to R: Mastering the Basics",
    "section": "Running a Single Line of Code",
    "text": "Running a Single Line of Code\n\nplace the cursor anywhere on the line;\npress `Ctrl + Enter` on a Windows/Linux machine;\npress `Cmd + Enter` on a Mac;\nOr, click “source” on the editor pane."
  },
  {
    "objectID": "series/R/2022/11/27/rbasics_an_introduction_to_r.html#running-an-entire-script",
    "href": "series/R/2022/11/27/rbasics_an_introduction_to_r.html#running-an-entire-script",
    "title": "An Introduction to R: Mastering the Basics",
    "section": "Running an Entire Script",
    "text": "Running an Entire Script\n\nplace the cursor anywhere on the line;\npress `Ctrl+Shift+Enter` on a Windows/Linux machine;\npress `Command+Shift+Return` on Mac;\nOr click “Source” on the editor pane."
  },
  {
    "objectID": "series/R/2022/11/27/rbasics_an_introduction_to_r.html#objects",
    "href": "series/R/2022/11/27/rbasics_an_introduction_to_r.html#objects",
    "title": "An Introduction to R: Mastering the Basics",
    "section": "Objects",
    "text": "Objects\nIn R, everything is an object. Object are entitles that hold data, which can be manipulated by invoking functions5. Here are the common types of objects:\n\nVectors: A vector is a basic data structure in R. It contains elements of the same type. For instance, numeric_vector &lt;- c(1, 2, 3) creates a numeric vector.\nMatrices: A matrix is a two-dimensional data structure where elements are arranged in rows and columns, and all elements are of the same type.\nLists: A list is an R-object that can contain many different types of elements inside it like vectors, functions, and even another list.\nData frames: Data frames are used for storing data tables. They are a list of vectors of equal length. For example, you might create a data frame to hold a dataset for data analysis."
  },
  {
    "objectID": "series/R/2022/11/27/rbasics_an_introduction_to_r.html#operations",
    "href": "series/R/2022/11/27/rbasics_an_introduction_to_r.html#operations",
    "title": "An Introduction to R: Mastering the Basics",
    "section": "Operations",
    "text": "Operations\nOperations in R refer to the tasks that can be performed on R objects. They’re a fundamental part of the language, allowing for the manipulation, comparison, and assignment of data6.\n\nArithmetic Operations\nArithmetic operations perform mathematical calculations. Here are some examples:\n\nAddition (+): 5 + 3 returns 8\nSubtraction (-): 5 - 3 returns 2\nMultiplication (*): 5 * 3 returns 15\nDivision (/): 5 / 3 returns 1.6666667\nExponentiation (^ or **): 5^3 or 5**3 returns 125\nModulus (%%): 5 %% 3 returns 2 (remainder of the division)\nInteger Division (%/%): 5 %/% 3 returns 1 (quotient of the division)\n\n\n\nRelational Operations\nRelational operations compare values and return a logical output (TRUE or FALSE). They’re often used in conditional statements. Here are some examples:\n\nLess than (&lt;): 5 &lt; 3 returns FALSE\nGreater than (&gt;): 5 &gt; 3 returns TRUE\nLess than or equal to (&lt;=): 5 &lt;= 3 returns FALSE\nGreater than or equal to (&gt;=): 5 &gt;= 3 returns TRUE\nEquals to (==): 5 == 3 returns FALSE\nNot equal to (!=): 5 != 3 returns TRUE\n\n\n\nLogical Operations\nLogical operations perform boolean logic on values. Here are some examples:\n\nAnd (&): Returns TRUE if both operands are TRUE. For example, TRUE & FALSE returns FALSE.\nOr (|): Returns TRUE if either operand is TRUE. For example, TRUE | FALSE returns TRUE.\nNot (!): Negates the value of the operand. For example, !TRUE returns FALSE.\nElementwise And (&&): Similar to &, but only evaluates the first element of vectors and ignores the rest.\nElementwise Or (||): Similar to |, but only evaluates the first element of vectors and ignores the rest.\n\n\n\nAssignment Operations\nAssignment operations store a value in a variable:\n\n&lt;-: This is the most common assignment operator in R. For example, x &lt;- 5 assigns the value 5 to the variable x.\n=: Similar to &lt;-, but usually used within functions. For example, mean(x = 1:5) computes the mean of the numbers from 1 to 5.\n&lt;&lt;-: This is the global assignment operator. It assigns a value to a variable in the global environment, even from within a function."
  },
  {
    "objectID": "series/R/2022/11/27/rbasics_an_introduction_to_r.html#functions",
    "href": "series/R/2022/11/27/rbasics_an_introduction_to_r.html#functions",
    "title": "An Introduction to R: Mastering the Basics",
    "section": "Functions",
    "text": "Functions\nFunctions are the backbone of any programming language, and R is no exception. Functions are sets of instructions that perform a task, and R has a multitude of built-in functions, as well as the capability for users to define their own.\n\nBuilt-in Functions\nR provides many built-in functions, which perform predefined tasks. Here are a few examples:\n\nmean(x): Computes the arithmetic mean of a numeric vector x.\nsum(x): Calculates the sum of all the values in x.\nmax(x): Finds the maximum value in x.\nmin(x): Finds the minimum value in x.\nsd(x): Calculates the standard deviation of x.\nlength(x): Returns the number of elements in x.\nstr(x): Provides a compact, human-readable description of x.\nhelp(x) or ?function_name: To access help files documents of functions\n\nFor each of these, x would be the argument, and it is typically a vector of some kind.\n\n\nUser-Defined Functions\nIn addition to the built-in functions, R allows you to define your own functions. This is particularly useful for tasks you need to perform frequently. User-defined functions are created with the function() command. Here’s an example:\n\n1# Define a function that calculates the average of squares of two numbers\navg_of_squares &lt;- function(a, b) {\n    return((a^2 + b^2)/2)\n}\n\n\n1\n\nTo make your code more readable, use intuitive variable names and include comments (using the “#” symbol) to remind yourself why you wrote a particular line of code.\n\n\n\n\nIn this function, a and b are the arguments. This function calculates the squares of a and b, sums them, and then divides by 2 to find the average. It then returns this result.\n\n\nSpecial Functions\nThere are some special types of functions in R, such as:\n\nAnonymous functions: These are functions that are defined without a name. They are used when a function is only needed once, often in the context of apply-type functions. For example, sapply(1:5, function(x) x^2) applies the anonymous function function(x) x^2 to the vector 1:5.\nPrimitive functions: These are basic functions in R that are implemented in C for efficiency. Examples include basic arithmetic operations (+, -, *, /) and others like sum(), prod(), and mean()."
  },
  {
    "objectID": "series/R/2022/11/27/rbasics_an_introduction_to_r.html#data-types",
    "href": "series/R/2022/11/27/rbasics_an_introduction_to_r.html#data-types",
    "title": "An Introduction to R: Mastering the Basics",
    "section": "Data Types",
    "text": "Data Types\nData types determine the kind of operations that can be performed on data, and R offers several basic data types7.\n\n\n\n\n\n\nNote\n\n\n\nThe code data(\"dataset_name\") and data(dataset_name) do the same thing. The code will work regardless of whether the quotes are present. It is a bit faster to leave out the quotes (as we do in the Code at the bottom of this page), so that is usually what we recommend, but it is your choice.\n\n\n\nNumeric\nThe numeric (or double) data type is used for real numbers (numbers with decimal points). Numeric is the default computational data type in R. If you assign a number to a variable without explicitly declaring its type, R will interpret it as a numeric. For example, x &lt;- 7.14 assigns a numeric value of 7.14 to x.\n\n\nInteger\nThe integer data type is used for integer numbers (whole numbers without decimal points). In R, you declare an integer by appending an L to the integer value. For example, x &lt;- 7L assigns an integer value of 7 to x.\n\n\nLogical\nThe logical data type is used for boolean values: TRUE and FALSE. Logical data types are often the result of logical operations. For example, the operation 5 &gt; 3 returns TRUE, which is a logical value.\n\n\nCharacter\nThe character data type is used for text or string data. To create a character string in R, you enclose the text in either single or double quotes. For example, x &lt;- “Hello, R!” assigns a character string of Hello, R! to x.\n\n\nComplex\nThe complex data type is used for complex numbers, which have both real and imaginary parts. In R, complex numbers are represented as x + yi, where x is the real part and y is the imaginary part. For example, x &lt;- 3 + 2i assigns a complex value of 3 + 2i to x.\n\n\nRaw\nThe raw data type is used for “raw” bytes. It can hold a stream of raw bytes, which are displayed as hexadecimal. This is not commonly used unless you are doing something fairly advanced, like writing a package to interface to other software or reading binary data directly from a connection.\n\n\n\n\n\n\nKnowledge Extension\n\n\n\n\n\n\n\n\nflowchart LR\n  A{Data Type}---&gt;B[numeric]\n  A{Data Type}---&gt;C[integer]\n  A{Data Type}---&gt;D[complex]\n  A{Data Type}---&gt;E[character]\n  A{Data Type}---&gt;F[logical]\n  A{Data Type}---&gt;G[Raw]\n  \nlinkStyle default stroke:red\nlinkStyle 0 stroke:green\nlinkStyle 3 stroke:blue\nlinkStyle 4 stroke:black\n\n\nFigure 1: Data Type in R\n\n\n\n\n\n\n\n# Loading the dslabs package and the murders dataset\nlibrary(dslabs) \ndata(murders) \n\n# Determining that the murders dataset is of the \"data frame\" class\nclass(murders) \n\n# Finding out more about the structure of the object\nstr(murders) \n\n# Showing the first 6 lines of the dataset\nhead(murders) \n\n# Using the accessor operator $ to obtain the population column\nmurders$population \n\n# Displaying the variable names in the murders dataset\nnames(murders) \n\n# Determining how many entries are in a vector\npop &lt;- murders$population \nlength(pop) \n\n# Vectors can be of class numeric and character\nclass(pop) \nclass(murders$state) \n\n# Logical vectors are either TRUE or FALSE\nz &lt;- 3 == 2 \nz \nclass(z) \n\n# Factors are another type of class\nclass(murders$region) \n\n# Obtaining the levels of a factor\nlevels(murders$region)"
  },
  {
    "objectID": "series/R/2022/11/27/rbasics_an_introduction_to_r.html#footnotes",
    "href": "series/R/2022/11/27/rbasics_an_introduction_to_r.html#footnotes",
    "title": "An Introduction to R: Mastering the Basics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://www.r-project.org/about.html↩︎\nhttps://www.tutorialspoint.com/r/r_packages.htm↩︎\nhttps://www.theanalysisfactor.com/the-advantages-of-rstudio/↩︎\nhttps://support.posit.co/hc/en-us/articles/200484448-Editing-and-Executing-Code-in-the-RStudio-IDE↩︎\nhttps://www.geeksforgeeks.org/r-objects/↩︎\nhttps://www.w3schools.com/r/r_operators.asp↩︎\nhttps://www.programiz.com/r/data-types↩︎"
  },
  {
    "objectID": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html",
    "href": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html",
    "title": "Indexing, Data Wrangling and Plots",
    "section": "",
    "text": "In this section, I will introduce the R commands and techniques that help you wrangle, analyze, and visualize data.\nIn Indexing, you will: - Subset a vector based on properties of another vector.\n\nUse multiple logical operators to index vectors.\nExtract the indices of vector elements satisfying one or more logical conditions.\nExtract the indices of vector elements matching with another vector.\nDetermine which elements in one vector are present in another vector.\n\nIn basic data wrangling, you will:\n\nWrangle data tables using functions in the dplyr package.\nModify a data table by adding or changing columns.\nSubset rows in a data table.\nSubset columns in a data table.\nPerform a series of operations using the pipe operator.\nCreate data frames.\n\nIn basic plots, you will: - Plot data in scatter plots, box plots, and histograms.\nIn summarizing with dplyr, you will: - Use summarize() to facilitate summarizing data in dplyr.\n\nLearn about the dot placeholder.\nLearn how to group and then summarize in dplyr.\nLearn how to sort data tables in dplyr.\n\nIn the rest section, you will: - Learn how to subset and summarize data using data.table.\n\nLearn how to sort data frames using data.table.\n\n\n\n\nWe can use logicals to index vectors.\nUsing the function sum()on a logical vector returns the number of entries that are true.\nThe logical operator “&” makes two logicals true only when they are both true.\n\n\n# defining murder rate as before\nmurder_rate &lt;- murders$total / murders$population * 100000\n# creating a logical vector that specifies if the murder rate in that state is less than or equal to 0.71\nindex &lt;- murder_rate &lt;= 0.71\n# determining which states have murder rates less than or equal to 0.71\nmurders$state[index]\n# calculating how many states have a murder rate less than or equal to 0.71\nsum(index)\n\n# creating the two logical vectors representing our conditions\nwest &lt;- murders$region == \"West\"\nsafe &lt;- murder_rate &lt;= 1\n# defining an index and identifying states with both conditions true\nindex &lt;- safe & west\nmurders$state[index]\n\n\n\n\nThe function which() gives us the entries of a logical vector that are true.\nThe function match() looks for entries in a vector and returns the index needed to access them.\nWe use the function %in% if we want to know whether or not each element of a first vector is in a second vector.\n\n\nx &lt;- c(FALSE, TRUE, FALSE, TRUE, TRUE, FALSE)\nwhich(x)    # returns indices that are TRUE\n\n# to determine the murder rate in Massachusetts we may do the following\nindex &lt;- which(murders$state == \"Massachusetts\")\nindex\nmurder_rate[index]\n\n# to obtain the indices and subsequent murder rates of New York, Florida, Texas, we do:\nindex &lt;- match(c(\"New York\", \"Florida\", \"Texas\"), murders$state)\nindex\nmurders$state[index]\nmurder_rate[index]\n\nx &lt;- c(\"a\", \"b\", \"c\", \"d\", \"e\")\ny &lt;- c(\"a\", \"d\", \"f\")\ny %in% x\n\n# to see if Boston, Dakota, and Washington are states\nc(\"Boston\", \"Dakota\", \"Washington\") %in% murders$state\n\n\n\n\nTo change a data table by adding a new column, or changing an existing one, we use the mutate() function.\nTo filter the data by subsetting rows, we use the function filter().\nTo subset the data by selecting specific columns, we use the select() function.\nWe can perform a series of operations by sending the results of one function to another function using the pipe operator, %&gt;%.\n\n\nThe default settings in R have changed as of version 4.0, and it is no longer necessary to include the code stringsAsFactors = FALSE in order to keep strings as characters. Putting the entries in quotes, as in the example, is adequate to keep strings as characters. The stringsAsFactors = FALSE code is useful in certain other situations, but you do not need to include it when you create data frames in this manner.\n\n\nWe can use the data.frame() function to create data frames.\nFormerly, the data.frame() function turned characters into factors by default. To avoid this, we could utilize the stringsAsFactors argument and set it equal to false. As of R 4.0, it is no longer necessary to include the stringsAsFactors argument, because R no longer turns characters into factors by default.\n\n\n# creating a data frame with stringAsFactors = FALSE\ngrades &lt;- data.frame(names = c(\"John\", \"Juan\", \"Jean\", \"Yao\"), \n                     exam_1 = c(95, 80, 90, 85), \n                     exam_2 = c(90, 85, 85, 90),\n                     stringsAsFactors = FALSE)\n\n\n\n\nWe can create a simple scatterplot using the function plot().\nHistograms are graphical summaries that give you a general overview of the types of values you have. In R, they can be produced using the hist() function.\nBoxplots provide a more compact summary of a distribution than a histogram and are more useful for comparing distributions. They can be produced using the boxplot() function.\n\n\nlibrary(dplyr)\nlibrary(dslabs)\ndata(\"murders\")\n\n\n# a simple scatterplot of total murders versus population\nx &lt;- murders$population /10^6\ny &lt;- murders$total\nplot(x, y)\n\n\n\n\n\n\n\n\n# a histogram of murder rates\nmurders &lt;- mutate(murders, rate = total / population * 100000)\nhist(murders$rate)\n\n\n\n\n\n\n# boxplots of murder rates by region\nboxplot(rate~region, data = murders)\n\n\n\n\n\n\n\n\n\n\nSummarizing data is an important part of data analysis.\nSome summary ststistics are the mean, median, and standard deviation.\nThe summarize() function from dplyr provides an easy way to compute summary statics.\n\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(murders)\nmurders &lt;- mutate(murders, rate = total / population * 10^5)\n\n\n# minimum, median, and maximum murder rate for the states in the West region\ns &lt;- murders %&gt;% \n  filter(region == \"West\") %&gt;%\n  summarize(minimum = min(rate), \n            median = median(rate), \n            maximum = max(rate))\ns\n\n   minimum   median  maximum\n1 0.514592 1.292453 3.629527\n\n# accessing the components with the accessor $\ns$median\n\n[1] 1.292453\n\ns$maximum\n\n[1] 3.629527\n\n# average rate unadjusted by population size\nmean(murders$rate)\n\n[1] 2.779125\n\n# average rate adjusted by population size\nus_murder_rate &lt;- murders %&gt;% \n  summarize(rate = sum(total) / sum(population) * 10^5)\nus_murder_rate\n\n      rate\n1 3.034555\n\n\n\n\n\nThe quantile() function can be used to return the min, median, and max in a single line of code.\n\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(murders)\nmurders &lt;- mutate(murders, rate = total / population * 10^5)\n\n\n# minimum, median, and maximum murder rate for the states in the West region using quantile\n# note that this returns a vector\nmurders %&gt;% \n  filter(region == \"West\") %&gt;%\n  summarize(range = quantile(rate, c(0, 0.5, 1)))\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n     range\n1 0.514592\n2 1.292453\n3 3.629527\n\n# returning minimum, median, and maximum as a data frame\nmy_quantile &lt;- function(x){\n  r &lt;-  quantile(x, c(0, 0.5, 1))\n  data.frame(minimum = r[1], median = r[2], maximum = r[3]) \n}\nmurders %&gt;% \n  filter(region == \"West\") %&gt;%\n  summarize(my_quantile(rate))\n\n   minimum   median  maximum\n1 0.514592 1.292453 3.629527\n\n\n\n\n\nThe pull() function can be used to access values stored in data when using pipes: when a data object is piped that object and its columns can be accessed using the pull() function.\n\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(murders)\nmurders &lt;- mutate(murders, rate = total / population * 10^5)\n\n\n# average rate adjusted by population size\nus_murder_rate &lt;- murders %&gt;% \n  summarize(rate = sum(total) / sum(population) * 10^5)\nus_murder_rate\n\n      rate\n1 3.034555\n\n# us_murder_rate is stored as a data frame\nclass(us_murder_rate)\n\n[1] \"data.frame\"\n\n# the pull function can return it as a numeric value\nus_murder_rate %&gt;% pull(rate)\n\n[1] 3.034555\n\n# using pull to save the number directly\nus_murder_rate &lt;- murders %&gt;% \n  summarize(rate = sum(total) / sum(population) * 10^5) %&gt;%\n  pull(rate)\nus_murder_rate\n\n[1] 3.034555\n\n# us_murder_rate is now stored as a number\nclass(us_murder_rate)\n\n[1] \"numeric\"\n\n\n\n\n\nThe dot (.) can be thought of as a placeholder for the data being passed through the pipe.\n\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(murders)\nmurders &lt;- mutate(murders, rate = total / population * 10^5)\n\n\n# average rate adjusted by population size\nus_murder_rate &lt;- murders %&gt;% \n  summarize(rate = sum(total) / sum(population) * 10^5)\nus_murder_rate\n\n      rate\n1 3.034555\n\n# using the dot to access the rate\nus_murder_rate &lt;- murders %&gt;% \n  summarize(rate = sum(total) / sum(population) * 10^5) %&gt;%\n  .$rate\nus_murder_rate\n\n[1] 3.034555\n\nclass(us_murder_rate)\n\n[1] \"numeric\"\n\n\n\n\n\nSplitting data into groups and then computing summaries for each group is a common operation in data exploration.\nWe can use the dplyr group_by() function to create a special grouped data frame to facilitate such summaries.\n\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(murders)\nmurders &lt;- mutate(murders, rate = total / population * 10^5)\n\n\n# group by region\nmurders %&gt;% group_by(region)\n\n# A tibble: 51 × 6\n# Groups:   region [4]\n   state                abb   region    population total  rate\n   &lt;chr&gt;                &lt;chr&gt; &lt;fct&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Alabama              AL    South        4779736   135  2.82\n 2 Alaska               AK    West          710231    19  2.68\n 3 Arizona              AZ    West         6392017   232  3.63\n 4 Arkansas             AR    South        2915918    93  3.19\n 5 California           CA    West        37253956  1257  3.37\n 6 Colorado             CO    West         5029196    65  1.29\n 7 Connecticut          CT    Northeast    3574097    97  2.71\n 8 Delaware             DE    South         897934    38  4.23\n 9 District of Columbia DC    South         601723    99 16.5 \n10 Florida              FL    South       19687653   669  3.40\n# ℹ 41 more rows\n\n# summarize after grouping\nmurders %&gt;% \n  group_by(region) %&gt;%\n  summarize(median = median(rate))\n\n# A tibble: 4 × 2\n  region        median\n  &lt;fct&gt;          &lt;dbl&gt;\n1 Northeast       1.80\n2 South           3.40\n3 North Central   1.97\n4 West            1.29\n\n\n\n\n\nTo order an entire table, we can use the dplyr function arrange().\nWe can also use nested sorting to order by additional columns.\nThe function head() returns on the first few lines of a table.\nThe function top_n() returns the top n rows of a table.\n\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(murders)\nmurders &lt;- mutate(murders, rate = total / population * 10^5)\n\n\n# order the states by population size\nmurders %&gt;% arrange(population) %&gt;% head()\n\n                 state abb        region population total       rate\n1              Wyoming  WY          West     563626     5  0.8871131\n2 District of Columbia  DC         South     601723    99 16.4527532\n3              Vermont  VT     Northeast     625741     2  0.3196211\n4         North Dakota  ND North Central     672591     4  0.5947151\n5               Alaska  AK          West     710231    19  2.6751860\n6         South Dakota  SD North Central     814180     8  0.9825837\n\n# order the states by murder rate - the default is ascending order\nmurders %&gt;% arrange(rate) %&gt;% head()\n\n          state abb        region population total      rate\n1       Vermont  VT     Northeast     625741     2 0.3196211\n2 New Hampshire  NH     Northeast    1316470     5 0.3798036\n3        Hawaii  HI          West    1360301     7 0.5145920\n4  North Dakota  ND North Central     672591     4 0.5947151\n5          Iowa  IA North Central    3046355    21 0.6893484\n6         Idaho  ID          West    1567582    12 0.7655102\n\n# order the states by murder rate in descending order\nmurders %&gt;% arrange(desc(rate)) %&gt;% head()\n\n                 state abb        region population total      rate\n1 District of Columbia  DC         South     601723    99 16.452753\n2            Louisiana  LA         South    4533372   351  7.742581\n3             Missouri  MO North Central    5988927   321  5.359892\n4             Maryland  MD         South    5773552   293  5.074866\n5       South Carolina  SC         South    4625364   207  4.475323\n6             Delaware  DE         South     897934    38  4.231937\n\n# order the states by region and then by murder rate within region\nmurders %&gt;% arrange(region, rate) %&gt;% head()\n\n          state abb    region population total      rate\n1       Vermont  VT Northeast     625741     2 0.3196211\n2 New Hampshire  NH Northeast    1316470     5 0.3798036\n3         Maine  ME Northeast    1328361    11 0.8280881\n4  Rhode Island  RI Northeast    1052567    16 1.5200933\n5 Massachusetts  MA Northeast    6547629   118 1.8021791\n6      New York  NY Northeast   19378102   517 2.6679599\n\n# return the top 10 states by murder rate\nmurders %&gt;% top_n(10, rate)\n\n                  state abb        region population total      rate\n1               Arizona  AZ          West    6392017   232  3.629527\n2              Delaware  DE         South     897934    38  4.231937\n3  District of Columbia  DC         South     601723    99 16.452753\n4               Georgia  GA         South    9920000   376  3.790323\n5             Louisiana  LA         South    4533372   351  7.742581\n6              Maryland  MD         South    5773552   293  5.074866\n7              Michigan  MI North Central    9883640   413  4.178622\n8           Mississippi  MS         South    2967297   120  4.044085\n9              Missouri  MO North Central    5988927   321  5.359892\n10       South Carolina  SC         South    4625364   207  4.475323\n\n# return the top 10 states ranked by murder rate, sorted by murder rate\nmurders %&gt;% arrange(desc(rate)) %&gt;% top_n(10)\n\nSelecting by rate\n\n\n                  state abb        region population total      rate\n1  District of Columbia  DC         South     601723    99 16.452753\n2             Louisiana  LA         South    4533372   351  7.742581\n3              Missouri  MO North Central    5988927   321  5.359892\n4              Maryland  MD         South    5773552   293  5.074866\n5        South Carolina  SC         South    4625364   207  4.475323\n6              Delaware  DE         South     897934    38  4.231937\n7              Michigan  MI North Central    9883640   413  4.178622\n8           Mississippi  MS         South    2967297   120  4.044085\n9               Georgia  GA         South    9920000   376  3.790323\n10              Arizona  AZ          West    6392017   232  3.629527\n\n\n\n\n\nIn this course, we often use tidyverse packages to illustrate because these packages tend to have code that is very readable for beginners.\nThere are other approaches to wrangling and analyzing data in R that are faster and better at handling large objects, such as the data.table package.\nSelecting in data.table uses notation similar to that used with matrices.\nTo add a column in data.table, you can use the := function.\nBecause the data.table package is designed to avoid wasting memory, when you make a copy of a table, it does not create a new object. The := function changes by reference. If you want to make an actual copy, you need to use the copy() function.\nSide note: the R language has a new, built-in pipe operator as of version 4.1: |&gt;. This works similarly to the pipe %&gt;% you are already familiar with. You can read more about the |&gt; pipe here External link.\n\n\n# install the data.table package before you use it!\ninstall.packages(\"data.table\")\n\n# load data.table package\nlibrary(data.table)\n\n# load other packages and datasets\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(murders)\n\n# convert the data frame into a data.table object\nmurders &lt;- setDT(murders)\n\n# selecting in dplyr\nselect(murders, state, region)\n\n# selecting in data.table - 2 methods\nmurders[, c(\"state\", \"region\")] |&gt; head()\nmurders[, .(state, region)] |&gt; head()\n\n# adding or changing a column in dplyr\nmurders &lt;- mutate(murders, rate = total / population * 10^5)\n\n# adding or changing a column in data.table\nmurders[, rate := total / population * 100000]\nhead(murders)\nmurders[, \":=\"(rate = total / population * 100000, rank = rank(population))]\n\n# y is referring to x and := changes by reference\nx &lt;- data.table(a = 1)\ny &lt;- x\n\nx[,a := 2]\ny\n\ny[,a := 1]\nx\n\n# use copy to make an actual copy\nx &lt;- data.table(a = 1)\ny &lt;- copy(x)\nx[,a := 2]\ny\n\n\n\nSubsetting in data.table uses notation similar to that used with matrices.\n\n\n# load packages and prepare the data\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(murders)\nlibrary(data.table)\nmurders &lt;- setDT(murders)\nmurders &lt;- mutate(murders, rate = total / population * 10^5)\nmurders[, rate := total / population * 100000]\n\n# subsetting in dplyr\nfilter(murders, rate &lt;= 0.7)\n\n# subsetting in data.table\nmurders[rate &lt;= 0.7]\n\n# combining filter and select in data.table\nmurders[rate &lt;= 0.7, .(state, rate)]\n\n# combining filter and select in dplyr\nmurders %&gt;% filter(rate &lt;= 0.7) %&gt;% select(state, rate)\n\n\n\n\nIn data.table we can call functions inside .()and they will be applied to rows.\nThe group_by followed by summarize in dplyr is performed in one line in data.table using the by argument.\n\n\n# load packages and prepare the data - heights dataset\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(heights)\nheights &lt;- setDT(heights)\n\n# summarizing in dplyr\ns &lt;- heights %&gt;% \n  summarize(average = mean(height), standard_deviation = sd(height))\n  \n# summarizing in data.table\ns &lt;- heights[, .(average = mean(height), standard_deviation = sd(height))]\n\n# subsetting and then summarizing in dplyr\ns &lt;- heights %&gt;% \n  filter(sex == \"Female\") %&gt;%\n  summarize(average = mean(height), standard_deviation = sd(height))\n  \n# subsetting and then summarizing in data.table\ns &lt;- heights[sex == \"Female\", .(average = mean(height), standard_deviation = sd(height))]\n\n# previously defined function\nmedian_min_max &lt;- function(x){\n  qs &lt;- quantile(x, c(0.5, 0, 1))\n  data.frame(median = qs[1], minimum = qs[2], maximum = qs[3])\n}\n\n# multiple summaries in data.table\nheights[, .(median_min_max(height))]\n\n# grouping then summarizing in data.table\nheights[, .(average = mean(height), standard_deviation = sd(height)), by = sex]\n\n\n\n\nTo order rows in a data frame using data.table, we can use the same approach we used for filtering.\nThe default sort is an ascending order, but we can also sort tables in descending order.\nWe can also perform nested sorting by including multiple variables in the desired sort order.\n\n\n# load packages and datasets and prepare the data\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(data.table)\nlibrary(dslabs)\ndata(murders)\nmurders &lt;- setDT(murders)\nmurders[, rate := total / population * 100000]\n\n# order by population\nmurders[order(population)] |&gt; head()\n\n# order by population in descending order\nmurders[order(population, decreasing = TRUE)] \n\n# order by region and then murder rate\nmurders[order(region, rate)]"
  },
  {
    "objectID": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#indexing",
    "href": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#indexing",
    "title": "Indexing, Data Wrangling and Plots",
    "section": "",
    "text": "We can use logicals to index vectors.\nUsing the function sum()on a logical vector returns the number of entries that are true.\nThe logical operator “&” makes two logicals true only when they are both true.\n\n\n# defining murder rate as before\nmurder_rate &lt;- murders$total / murders$population * 100000\n# creating a logical vector that specifies if the murder rate in that state is less than or equal to 0.71\nindex &lt;- murder_rate &lt;= 0.71\n# determining which states have murder rates less than or equal to 0.71\nmurders$state[index]\n# calculating how many states have a murder rate less than or equal to 0.71\nsum(index)\n\n# creating the two logical vectors representing our conditions\nwest &lt;- murders$region == \"West\"\nsafe &lt;- murder_rate &lt;= 1\n# defining an index and identifying states with both conditions true\nindex &lt;- safe & west\nmurders$state[index]"
  },
  {
    "objectID": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#indexing-functions",
    "href": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#indexing-functions",
    "title": "Indexing, Data Wrangling and Plots",
    "section": "",
    "text": "The function which() gives us the entries of a logical vector that are true.\nThe function match() looks for entries in a vector and returns the index needed to access them.\nWe use the function %in% if we want to know whether or not each element of a first vector is in a second vector.\n\n\nx &lt;- c(FALSE, TRUE, FALSE, TRUE, TRUE, FALSE)\nwhich(x)    # returns indices that are TRUE\n\n# to determine the murder rate in Massachusetts we may do the following\nindex &lt;- which(murders$state == \"Massachusetts\")\nindex\nmurder_rate[index]\n\n# to obtain the indices and subsequent murder rates of New York, Florida, Texas, we do:\nindex &lt;- match(c(\"New York\", \"Florida\", \"Texas\"), murders$state)\nindex\nmurders$state[index]\nmurder_rate[index]\n\nx &lt;- c(\"a\", \"b\", \"c\", \"d\", \"e\")\ny &lt;- c(\"a\", \"d\", \"f\")\ny %in% x\n\n# to see if Boston, Dakota, and Washington are states\nc(\"Boston\", \"Dakota\", \"Washington\") %in% murders$state"
  },
  {
    "objectID": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#basic-data-wrangling",
    "href": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#basic-data-wrangling",
    "title": "Indexing, Data Wrangling and Plots",
    "section": "",
    "text": "To change a data table by adding a new column, or changing an existing one, we use the mutate() function.\nTo filter the data by subsetting rows, we use the function filter().\nTo subset the data by selecting specific columns, we use the select() function.\nWe can perform a series of operations by sending the results of one function to another function using the pipe operator, %&gt;%."
  },
  {
    "objectID": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#creating-data-frames",
    "href": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#creating-data-frames",
    "title": "Indexing, Data Wrangling and Plots",
    "section": "",
    "text": "The default settings in R have changed as of version 4.0, and it is no longer necessary to include the code stringsAsFactors = FALSE in order to keep strings as characters. Putting the entries in quotes, as in the example, is adequate to keep strings as characters. The stringsAsFactors = FALSE code is useful in certain other situations, but you do not need to include it when you create data frames in this manner.\n\n\nWe can use the data.frame() function to create data frames.\nFormerly, the data.frame() function turned characters into factors by default. To avoid this, we could utilize the stringsAsFactors argument and set it equal to false. As of R 4.0, it is no longer necessary to include the stringsAsFactors argument, because R no longer turns characters into factors by default.\n\n\n# creating a data frame with stringAsFactors = FALSE\ngrades &lt;- data.frame(names = c(\"John\", \"Juan\", \"Jean\", \"Yao\"), \n                     exam_1 = c(95, 80, 90, 85), \n                     exam_2 = c(90, 85, 85, 90),\n                     stringsAsFactors = FALSE)"
  },
  {
    "objectID": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#basic-plots",
    "href": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#basic-plots",
    "title": "Indexing, Data Wrangling and Plots",
    "section": "",
    "text": "We can create a simple scatterplot using the function plot().\nHistograms are graphical summaries that give you a general overview of the types of values you have. In R, they can be produced using the hist() function.\nBoxplots provide a more compact summary of a distribution than a histogram and are more useful for comparing distributions. They can be produced using the boxplot() function.\n\n\nlibrary(dplyr)\nlibrary(dslabs)\ndata(\"murders\")\n\n\n# a simple scatterplot of total murders versus population\nx &lt;- murders$population /10^6\ny &lt;- murders$total\nplot(x, y)\n\n\n\n\n\n\n\n\n# a histogram of murder rates\nmurders &lt;- mutate(murders, rate = total / population * 100000)\nhist(murders$rate)\n\n\n\n\n\n\n# boxplots of murder rates by region\nboxplot(rate~region, data = murders)"
  },
  {
    "objectID": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#the-summarize-function",
    "href": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#the-summarize-function",
    "title": "Indexing, Data Wrangling and Plots",
    "section": "",
    "text": "Summarizing data is an important part of data analysis.\nSome summary ststistics are the mean, median, and standard deviation.\nThe summarize() function from dplyr provides an easy way to compute summary statics.\n\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(murders)\nmurders &lt;- mutate(murders, rate = total / population * 10^5)\n\n\n# minimum, median, and maximum murder rate for the states in the West region\ns &lt;- murders %&gt;% \n  filter(region == \"West\") %&gt;%\n  summarize(minimum = min(rate), \n            median = median(rate), \n            maximum = max(rate))\ns\n\n   minimum   median  maximum\n1 0.514592 1.292453 3.629527\n\n# accessing the components with the accessor $\ns$median\n\n[1] 1.292453\n\ns$maximum\n\n[1] 3.629527\n\n# average rate unadjusted by population size\nmean(murders$rate)\n\n[1] 2.779125\n\n# average rate adjusted by population size\nus_murder_rate &lt;- murders %&gt;% \n  summarize(rate = sum(total) / sum(population) * 10^5)\nus_murder_rate\n\n      rate\n1 3.034555"
  },
  {
    "objectID": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#summarizing-with-more-than-one-value",
    "href": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#summarizing-with-more-than-one-value",
    "title": "Indexing, Data Wrangling and Plots",
    "section": "",
    "text": "The quantile() function can be used to return the min, median, and max in a single line of code.\n\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(murders)\nmurders &lt;- mutate(murders, rate = total / population * 10^5)\n\n\n# minimum, median, and maximum murder rate for the states in the West region using quantile\n# note that this returns a vector\nmurders %&gt;% \n  filter(region == \"West\") %&gt;%\n  summarize(range = quantile(rate, c(0, 0.5, 1)))\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n     range\n1 0.514592\n2 1.292453\n3 3.629527\n\n# returning minimum, median, and maximum as a data frame\nmy_quantile &lt;- function(x){\n  r &lt;-  quantile(x, c(0, 0.5, 1))\n  data.frame(minimum = r[1], median = r[2], maximum = r[3]) \n}\nmurders %&gt;% \n  filter(region == \"West\") %&gt;%\n  summarize(my_quantile(rate))\n\n   minimum   median  maximum\n1 0.514592 1.292453 3.629527"
  },
  {
    "objectID": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#pull-to-access-to-columns",
    "href": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#pull-to-access-to-columns",
    "title": "Indexing, Data Wrangling and Plots",
    "section": "",
    "text": "The pull() function can be used to access values stored in data when using pipes: when a data object is piped that object and its columns can be accessed using the pull() function.\n\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(murders)\nmurders &lt;- mutate(murders, rate = total / population * 10^5)\n\n\n# average rate adjusted by population size\nus_murder_rate &lt;- murders %&gt;% \n  summarize(rate = sum(total) / sum(population) * 10^5)\nus_murder_rate\n\n      rate\n1 3.034555\n\n# us_murder_rate is stored as a data frame\nclass(us_murder_rate)\n\n[1] \"data.frame\"\n\n# the pull function can return it as a numeric value\nus_murder_rate %&gt;% pull(rate)\n\n[1] 3.034555\n\n# using pull to save the number directly\nus_murder_rate &lt;- murders %&gt;% \n  summarize(rate = sum(total) / sum(population) * 10^5) %&gt;%\n  pull(rate)\nus_murder_rate\n\n[1] 3.034555\n\n# us_murder_rate is now stored as a number\nclass(us_murder_rate)\n\n[1] \"numeric\""
  },
  {
    "objectID": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#the-dot-placeholder",
    "href": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#the-dot-placeholder",
    "title": "Indexing, Data Wrangling and Plots",
    "section": "",
    "text": "The dot (.) can be thought of as a placeholder for the data being passed through the pipe.\n\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(murders)\nmurders &lt;- mutate(murders, rate = total / population * 10^5)\n\n\n# average rate adjusted by population size\nus_murder_rate &lt;- murders %&gt;% \n  summarize(rate = sum(total) / sum(population) * 10^5)\nus_murder_rate\n\n      rate\n1 3.034555\n\n# using the dot to access the rate\nus_murder_rate &lt;- murders %&gt;% \n  summarize(rate = sum(total) / sum(population) * 10^5) %&gt;%\n  .$rate\nus_murder_rate\n\n[1] 3.034555\n\nclass(us_murder_rate)\n\n[1] \"numeric\""
  },
  {
    "objectID": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#group-then-summarize",
    "href": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#group-then-summarize",
    "title": "Indexing, Data Wrangling and Plots",
    "section": "",
    "text": "Splitting data into groups and then computing summaries for each group is a common operation in data exploration.\nWe can use the dplyr group_by() function to create a special grouped data frame to facilitate such summaries.\n\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(murders)\nmurders &lt;- mutate(murders, rate = total / population * 10^5)\n\n\n# group by region\nmurders %&gt;% group_by(region)\n\n# A tibble: 51 × 6\n# Groups:   region [4]\n   state                abb   region    population total  rate\n   &lt;chr&gt;                &lt;chr&gt; &lt;fct&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Alabama              AL    South        4779736   135  2.82\n 2 Alaska               AK    West          710231    19  2.68\n 3 Arizona              AZ    West         6392017   232  3.63\n 4 Arkansas             AR    South        2915918    93  3.19\n 5 California           CA    West        37253956  1257  3.37\n 6 Colorado             CO    West         5029196    65  1.29\n 7 Connecticut          CT    Northeast    3574097    97  2.71\n 8 Delaware             DE    South         897934    38  4.23\n 9 District of Columbia DC    South         601723    99 16.5 \n10 Florida              FL    South       19687653   669  3.40\n# ℹ 41 more rows\n\n# summarize after grouping\nmurders %&gt;% \n  group_by(region) %&gt;%\n  summarize(median = median(rate))\n\n# A tibble: 4 × 2\n  region        median\n  &lt;fct&gt;          &lt;dbl&gt;\n1 Northeast       1.80\n2 South           3.40\n3 North Central   1.97\n4 West            1.29"
  },
  {
    "objectID": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#sorting-data-tables",
    "href": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#sorting-data-tables",
    "title": "Indexing, Data Wrangling and Plots",
    "section": "",
    "text": "To order an entire table, we can use the dplyr function arrange().\nWe can also use nested sorting to order by additional columns.\nThe function head() returns on the first few lines of a table.\nThe function top_n() returns the top n rows of a table.\n\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(murders)\nmurders &lt;- mutate(murders, rate = total / population * 10^5)\n\n\n# order the states by population size\nmurders %&gt;% arrange(population) %&gt;% head()\n\n                 state abb        region population total       rate\n1              Wyoming  WY          West     563626     5  0.8871131\n2 District of Columbia  DC         South     601723    99 16.4527532\n3              Vermont  VT     Northeast     625741     2  0.3196211\n4         North Dakota  ND North Central     672591     4  0.5947151\n5               Alaska  AK          West     710231    19  2.6751860\n6         South Dakota  SD North Central     814180     8  0.9825837\n\n# order the states by murder rate - the default is ascending order\nmurders %&gt;% arrange(rate) %&gt;% head()\n\n          state abb        region population total      rate\n1       Vermont  VT     Northeast     625741     2 0.3196211\n2 New Hampshire  NH     Northeast    1316470     5 0.3798036\n3        Hawaii  HI          West    1360301     7 0.5145920\n4  North Dakota  ND North Central     672591     4 0.5947151\n5          Iowa  IA North Central    3046355    21 0.6893484\n6         Idaho  ID          West    1567582    12 0.7655102\n\n# order the states by murder rate in descending order\nmurders %&gt;% arrange(desc(rate)) %&gt;% head()\n\n                 state abb        region population total      rate\n1 District of Columbia  DC         South     601723    99 16.452753\n2            Louisiana  LA         South    4533372   351  7.742581\n3             Missouri  MO North Central    5988927   321  5.359892\n4             Maryland  MD         South    5773552   293  5.074866\n5       South Carolina  SC         South    4625364   207  4.475323\n6             Delaware  DE         South     897934    38  4.231937\n\n# order the states by region and then by murder rate within region\nmurders %&gt;% arrange(region, rate) %&gt;% head()\n\n          state abb    region population total      rate\n1       Vermont  VT Northeast     625741     2 0.3196211\n2 New Hampshire  NH Northeast    1316470     5 0.3798036\n3         Maine  ME Northeast    1328361    11 0.8280881\n4  Rhode Island  RI Northeast    1052567    16 1.5200933\n5 Massachusetts  MA Northeast    6547629   118 1.8021791\n6      New York  NY Northeast   19378102   517 2.6679599\n\n# return the top 10 states by murder rate\nmurders %&gt;% top_n(10, rate)\n\n                  state abb        region population total      rate\n1               Arizona  AZ          West    6392017   232  3.629527\n2              Delaware  DE         South     897934    38  4.231937\n3  District of Columbia  DC         South     601723    99 16.452753\n4               Georgia  GA         South    9920000   376  3.790323\n5             Louisiana  LA         South    4533372   351  7.742581\n6              Maryland  MD         South    5773552   293  5.074866\n7              Michigan  MI North Central    9883640   413  4.178622\n8           Mississippi  MS         South    2967297   120  4.044085\n9              Missouri  MO North Central    5988927   321  5.359892\n10       South Carolina  SC         South    4625364   207  4.475323\n\n# return the top 10 states ranked by murder rate, sorted by murder rate\nmurders %&gt;% arrange(desc(rate)) %&gt;% top_n(10)\n\nSelecting by rate\n\n\n                  state abb        region population total      rate\n1  District of Columbia  DC         South     601723    99 16.452753\n2             Louisiana  LA         South    4533372   351  7.742581\n3              Missouri  MO North Central    5988927   321  5.359892\n4              Maryland  MD         South    5773552   293  5.074866\n5        South Carolina  SC         South    4625364   207  4.475323\n6              Delaware  DE         South     897934    38  4.231937\n7              Michigan  MI North Central    9883640   413  4.178622\n8           Mississippi  MS         South    2967297   120  4.044085\n9               Georgia  GA         South    9920000   376  3.790323\n10              Arizona  AZ          West    6392017   232  3.629527"
  },
  {
    "objectID": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#introduction-to-data.table",
    "href": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#introduction-to-data.table",
    "title": "Indexing, Data Wrangling and Plots",
    "section": "",
    "text": "In this course, we often use tidyverse packages to illustrate because these packages tend to have code that is very readable for beginners.\nThere are other approaches to wrangling and analyzing data in R that are faster and better at handling large objects, such as the data.table package.\nSelecting in data.table uses notation similar to that used with matrices.\nTo add a column in data.table, you can use the := function.\nBecause the data.table package is designed to avoid wasting memory, when you make a copy of a table, it does not create a new object. The := function changes by reference. If you want to make an actual copy, you need to use the copy() function.\nSide note: the R language has a new, built-in pipe operator as of version 4.1: |&gt;. This works similarly to the pipe %&gt;% you are already familiar with. You can read more about the |&gt; pipe here External link.\n\n\n# install the data.table package before you use it!\ninstall.packages(\"data.table\")\n\n# load data.table package\nlibrary(data.table)\n\n# load other packages and datasets\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(murders)\n\n# convert the data frame into a data.table object\nmurders &lt;- setDT(murders)\n\n# selecting in dplyr\nselect(murders, state, region)\n\n# selecting in data.table - 2 methods\nmurders[, c(\"state\", \"region\")] |&gt; head()\nmurders[, .(state, region)] |&gt; head()\n\n# adding or changing a column in dplyr\nmurders &lt;- mutate(murders, rate = total / population * 10^5)\n\n# adding or changing a column in data.table\nmurders[, rate := total / population * 100000]\nhead(murders)\nmurders[, \":=\"(rate = total / population * 100000, rank = rank(population))]\n\n# y is referring to x and := changes by reference\nx &lt;- data.table(a = 1)\ny &lt;- x\n\nx[,a := 2]\ny\n\ny[,a := 1]\nx\n\n# use copy to make an actual copy\nx &lt;- data.table(a = 1)\ny &lt;- copy(x)\nx[,a := 2]\ny"
  },
  {
    "objectID": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#subsetting-with-data.table",
    "href": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#subsetting-with-data.table",
    "title": "Indexing, Data Wrangling and Plots",
    "section": "",
    "text": "Subsetting in data.table uses notation similar to that used with matrices.\n\n\n# load packages and prepare the data\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(murders)\nlibrary(data.table)\nmurders &lt;- setDT(murders)\nmurders &lt;- mutate(murders, rate = total / population * 10^5)\nmurders[, rate := total / population * 100000]\n\n# subsetting in dplyr\nfilter(murders, rate &lt;= 0.7)\n\n# subsetting in data.table\nmurders[rate &lt;= 0.7]\n\n# combining filter and select in data.table\nmurders[rate &lt;= 0.7, .(state, rate)]\n\n# combining filter and select in dplyr\nmurders %&gt;% filter(rate &lt;= 0.7) %&gt;% select(state, rate)"
  },
  {
    "objectID": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#summarizing-with-data.table",
    "href": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#summarizing-with-data.table",
    "title": "Indexing, Data Wrangling and Plots",
    "section": "",
    "text": "In data.table we can call functions inside .()and they will be applied to rows.\nThe group_by followed by summarize in dplyr is performed in one line in data.table using the by argument.\n\n\n# load packages and prepare the data - heights dataset\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(dslabs)\ndata(heights)\nheights &lt;- setDT(heights)\n\n# summarizing in dplyr\ns &lt;- heights %&gt;% \n  summarize(average = mean(height), standard_deviation = sd(height))\n  \n# summarizing in data.table\ns &lt;- heights[, .(average = mean(height), standard_deviation = sd(height))]\n\n# subsetting and then summarizing in dplyr\ns &lt;- heights %&gt;% \n  filter(sex == \"Female\") %&gt;%\n  summarize(average = mean(height), standard_deviation = sd(height))\n  \n# subsetting and then summarizing in data.table\ns &lt;- heights[sex == \"Female\", .(average = mean(height), standard_deviation = sd(height))]\n\n# previously defined function\nmedian_min_max &lt;- function(x){\n  qs &lt;- quantile(x, c(0.5, 0, 1))\n  data.frame(median = qs[1], minimum = qs[2], maximum = qs[3])\n}\n\n# multiple summaries in data.table\nheights[, .(median_min_max(height))]\n\n# grouping then summarizing in data.table\nheights[, .(average = mean(height), standard_deviation = sd(height)), by = sex]"
  },
  {
    "objectID": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#sorting-data-frames",
    "href": "series/R/2022/11/29/rbaiscs_indexing_wrangling_plots.html#sorting-data-frames",
    "title": "Indexing, Data Wrangling and Plots",
    "section": "",
    "text": "To order rows in a data frame using data.table, we can use the same approach we used for filtering.\nThe default sort is an ascending order, but we can also sort tables in descending order.\nWe can also perform nested sorting by including multiple variables in the desired sort order.\n\n\n# load packages and datasets and prepare the data\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(data.table)\nlibrary(dslabs)\ndata(murders)\nmurders &lt;- setDT(murders)\nmurders[, rate := total / population * 100000]\n\n# order by population\nmurders[order(population)] |&gt; head()\n\n# order by population in descending order\nmurders[order(population, decreasing = TRUE)] \n\n# order by region and then murder rate\nmurders[order(region, rate)]"
  },
  {
    "objectID": "series/R/2022/11/30/rbasics_programming.html",
    "href": "series/R/2022/11/30/rbasics_programming.html",
    "title": "Programming Basics",
    "section": "",
    "text": "In this section, I will introduce you to general programming features like if-else and for loop commands so that you can write your own functions to perform various operations on datasets.\nIn programming basics, you will:\n\nUnderstand some of the programming capabilities of R.\n\nIn basic condationals, you will:\n\nUse basic conditional expressions to perform different operations. Check if any or all elements of a logical vector are TRUE.\n\nIn function, you will:\n\nDefine and call functions to perform various operations.\nPass arguments to functions, and return variables/objects from functions.\n\nIn loops, you will: - Use for-loops to perform repeated operations.\n\nArticulate in-built functions of R that you could try for yourself.\n\n\nIntroduction to Programming in R\n\n\n\nThe most common conditional expression in programming is an if-else statement, which has the form “if [condition], perform [expression], else perform [alternative expression]”.\nThe ifelse() function works similarly to an if-else statement, but it is particularly useful since it works on vectors by examining each element of the vector and returning a corresponding answer accordingly.\nThe any() function takes a vector of logicals and returns true if any of the entries are true.\nThe all() function takes a vector of logicals and returns true if all of the entries are true.\n\n\n# an example showing the general structure of an if-else statement\na &lt;- 0\nif(a!=0){\n  print(1/a)\n} else{\n  print(\"No reciprocal for 0.\")\n}\n\n# an example that tells us which states, if any, have a murder rate less than 0.5\nlibrary(dslabs)\ndata(murders)\nmurder_rate &lt;- murders$total / murders$population*100000\nind &lt;- which.min(murder_rate)\nif(murder_rate[ind] &lt; 0.5){\n  print(murders$state[ind]) \n} else{\n  print(\"No state has murder rate that low\")\n}\n\n# changing the condition to &lt; 0.25 changes the result\nif(murder_rate[ind] &lt; 0.25){\n  print(murders$state[ind]) \n} else{\n  print(\"No state has a murder rate that low.\")\n}\n\n# the ifelse() function works similarly to an if-else conditional\na &lt;- 0\nifelse(a &gt; 0, 1/a, NA)\n\n# the ifelse() function is particularly useful on vectors\na &lt;- c(0,1,2,-4,5)\nresult &lt;- ifelse(a &gt; 0, 1/a, NA)\n\n# the ifelse() function is also helpful for replacing missing values\ndata(na_example)\nno_nas &lt;- ifelse(is.na(na_example), 0, na_example) \nsum(is.na(no_nas))\n\n# the any() and all() functions evaluate logical vectors\nz &lt;- c(TRUE, TRUE, FALSE)\nany(z)\nall(z)\n\n\n\n\nThe R function called function() tells R you are about to define a new function.\nFunctions are objects, so must be assigned a variable name with the arrow operator.\n\nThe general way to define functions is:\n\n\ndecide the function name, which will be an object,\n\n\ntype function() with your function’s arguments in parentheses, - (3) write all the operations inside brackets.\n\n\n\nVariables defined inside a function are not saved in the workspace.\n\n\n# example of defining a function to compute the average of a vector x\navg &lt;- function(x){\n  s &lt;- sum(x)\n  n &lt;- length(x)\n  s/n\n}\n\n# we see that the above function and the pre-built R mean() function are identical\nx &lt;- 1:100\nidentical(mean(x), avg(x))\n\n# variables inside a function are not defined in the workspace\ns &lt;- 3\navg(1:10)\ns\n\n# the general form of a function\nmy_function &lt;- function(VARIABLE_NAME){\n  perform operations on VARIABLE_NAME and calculate VALUE\n  VALUE\n}\n\n# functions can have multiple arguments as well as default values\navg &lt;- function(x, arithmetic = TRUE){\n  n &lt;- length(x)\n  ifelse(arithmetic, sum(x)/n, prod(x)^(1/n))\n}\n\n\n\n\nFor-loops perform the same task over and over while changing the variable. They let us define the range that our variable takes, and then changes the value with each loop and evaluates the expression every time inside the loop.\nThe general form of a for-loop is: “For i in [some range], do operations”. This i changes across the range of values and the operations assume i is a value you’re interested in computing on.\nAt the end of the loop, the value of i is the last value of the range.\n\n\n# creating a function that computes the sum of integers 1 through n\ncompute_s_n &lt;- function(n){\n  x &lt;- 1:n\n  sum(x)\n}\n\n# a very simple for-loop\nfor(i in 1:5){\n  print(i)\n}\n\n# a for-loop for our summation\nm &lt;- 25\ns_n &lt;- vector(length = m) # create an empty vector\nfor(n in 1:m){\n  s_n[n] &lt;- compute_s_n(n)\n}\n\n# creating a plot for our summation function\nn &lt;- 1:m\nplot(n, s_n)\n\n# a table of values comparing our function to the summation formula\nhead(data.frame(s_n = s_n, formula = n*(n+1)/2))\n\n# overlaying our function with the summation formula\nplot(n, s_n)\nlines(n, n*(n+1)/2)"
  },
  {
    "objectID": "series/R/2022/11/30/rbasics_programming.html#programming-basics-1",
    "href": "series/R/2022/11/30/rbasics_programming.html#programming-basics-1",
    "title": "Programming Basics",
    "section": "",
    "text": "Introduction to Programming in R"
  },
  {
    "objectID": "series/R/2022/11/30/rbasics_programming.html#basic-condationals",
    "href": "series/R/2022/11/30/rbasics_programming.html#basic-condationals",
    "title": "Programming Basics",
    "section": "",
    "text": "The most common conditional expression in programming is an if-else statement, which has the form “if [condition], perform [expression], else perform [alternative expression]”.\nThe ifelse() function works similarly to an if-else statement, but it is particularly useful since it works on vectors by examining each element of the vector and returning a corresponding answer accordingly.\nThe any() function takes a vector of logicals and returns true if any of the entries are true.\nThe all() function takes a vector of logicals and returns true if all of the entries are true.\n\n\n# an example showing the general structure of an if-else statement\na &lt;- 0\nif(a!=0){\n  print(1/a)\n} else{\n  print(\"No reciprocal for 0.\")\n}\n\n# an example that tells us which states, if any, have a murder rate less than 0.5\nlibrary(dslabs)\ndata(murders)\nmurder_rate &lt;- murders$total / murders$population*100000\nind &lt;- which.min(murder_rate)\nif(murder_rate[ind] &lt; 0.5){\n  print(murders$state[ind]) \n} else{\n  print(\"No state has murder rate that low\")\n}\n\n# changing the condition to &lt; 0.25 changes the result\nif(murder_rate[ind] &lt; 0.25){\n  print(murders$state[ind]) \n} else{\n  print(\"No state has a murder rate that low.\")\n}\n\n# the ifelse() function works similarly to an if-else conditional\na &lt;- 0\nifelse(a &gt; 0, 1/a, NA)\n\n# the ifelse() function is particularly useful on vectors\na &lt;- c(0,1,2,-4,5)\nresult &lt;- ifelse(a &gt; 0, 1/a, NA)\n\n# the ifelse() function is also helpful for replacing missing values\ndata(na_example)\nno_nas &lt;- ifelse(is.na(na_example), 0, na_example) \nsum(is.na(no_nas))\n\n# the any() and all() functions evaluate logical vectors\nz &lt;- c(TRUE, TRUE, FALSE)\nany(z)\nall(z)"
  },
  {
    "objectID": "series/R/2022/11/30/rbasics_programming.html#functions",
    "href": "series/R/2022/11/30/rbasics_programming.html#functions",
    "title": "Programming Basics",
    "section": "",
    "text": "The R function called function() tells R you are about to define a new function.\nFunctions are objects, so must be assigned a variable name with the arrow operator.\n\nThe general way to define functions is:\n\n\ndecide the function name, which will be an object,\n\n\ntype function() with your function’s arguments in parentheses, - (3) write all the operations inside brackets.\n\n\n\nVariables defined inside a function are not saved in the workspace.\n\n\n# example of defining a function to compute the average of a vector x\navg &lt;- function(x){\n  s &lt;- sum(x)\n  n &lt;- length(x)\n  s/n\n}\n\n# we see that the above function and the pre-built R mean() function are identical\nx &lt;- 1:100\nidentical(mean(x), avg(x))\n\n# variables inside a function are not defined in the workspace\ns &lt;- 3\navg(1:10)\ns\n\n# the general form of a function\nmy_function &lt;- function(VARIABLE_NAME){\n  perform operations on VARIABLE_NAME and calculate VALUE\n  VALUE\n}\n\n# functions can have multiple arguments as well as default values\navg &lt;- function(x, arithmetic = TRUE){\n  n &lt;- length(x)\n  ifelse(arithmetic, sum(x)/n, prod(x)^(1/n))\n}"
  },
  {
    "objectID": "series/R/2022/11/30/rbasics_programming.html#for-loops",
    "href": "series/R/2022/11/30/rbasics_programming.html#for-loops",
    "title": "Programming Basics",
    "section": "",
    "text": "For-loops perform the same task over and over while changing the variable. They let us define the range that our variable takes, and then changes the value with each loop and evaluates the expression every time inside the loop.\nThe general form of a for-loop is: “For i in [some range], do operations”. This i changes across the range of values and the operations assume i is a value you’re interested in computing on.\nAt the end of the loop, the value of i is the last value of the range.\n\n\n# creating a function that computes the sum of integers 1 through n\ncompute_s_n &lt;- function(n){\n  x &lt;- 1:n\n  sum(x)\n}\n\n# a very simple for-loop\nfor(i in 1:5){\n  print(i)\n}\n\n# a for-loop for our summation\nm &lt;- 25\ns_n &lt;- vector(length = m) # create an empty vector\nfor(n in 1:m){\n  s_n[n] &lt;- compute_s_n(n)\n}\n\n# creating a plot for our summation function\nn &lt;- 1:m\nplot(n, s_n)\n\n# a table of values comparing our function to the summation formula\nhead(data.frame(s_n = s_n, formula = n*(n+1)/2))\n\n# overlaying our function with the summation formula\nplot(n, s_n)\nlines(n, n*(n+1)/2)"
  },
  {
    "objectID": "series/R/2022/12/05/datavisualization_gapminder.html",
    "href": "series/R/2022/12/05/datavisualization_gapminder.html",
    "title": "Gapminder Data Sets",
    "section": "",
    "text": "After completing Gapminder, you will: - understand how Hans Rosling and the Gapminder Foundation use effective data visualization to convey data-based trends.\n\nbe able to apply the ggplot2 techniques from the previous section to answer questions using data.\nunderstand how fixed scales across plots can ease comparisons.\nbe able to modify graphs to improve data visualization.\n\nCase study: Trends in World Health and Economics\nData Source form Gapminder\nWe will use this data to answer the following questions about World Health and Economics: - Is it still fair to consider the world as divided into the West and the developing world? - Has income inequality across countries worsened over the last 40 years?\n\n\n\nA selection of world health and economics statistics from the Gapminder project can be found in the dslabs package as data(gapminder).\nMost people have misconceptions about world health and economics, which can be addressed by considering real data.\n\n\nlibrary(dslabs)\nlibrary(tidyverse)\ndata(\"gapminder\")\n\n\nhead(gapminder)\n\n              country year infant_mortality life_expectancy fertility\n1             Albania 1960           115.40           62.87      6.19\n2             Algeria 1960           148.20           47.50      7.65\n3              Angola 1960           208.00           35.98      7.32\n4 Antigua and Barbuda 1960               NA           62.97      4.43\n5           Argentina 1960            59.87           65.39      3.11\n6             Armenia 1960               NA           66.86      4.55\n  population          gdp continent          region\n1    1636054           NA    Europe Southern Europe\n2   11124892  13828152297    Africa Northern Africa\n3    5270844           NA    Africa   Middle Africa\n4      54681           NA  Americas       Caribbean\n5   20619075 108322326649  Americas   South America\n6    1867396           NA      Asia    Western Asia\n\nnames(gapminder)\n\n[1] \"country\"          \"year\"             \"infant_mortality\" \"life_expectancy\" \n[5] \"fertility\"        \"population\"       \"gdp\"              \"continent\"       \n[9] \"region\"          \n\n\n\ngapminder %&gt;% \n  filter(year == 2015 & country %in% c(\"Sri Lanka\", \"Turkey\")) %&gt;% \n  select(country, infant_mortality)\n\n    country infant_mortality\n1 Sri Lanka              8.4\n2    Turkey             11.6\n\n\n\n\n\n\nA prevalent worldview is that the world is divided into two groups of countries:\n\nWestern world: high life expectancy, low fertility rate\nDeveloping world: lower life expectancy, higher fertility rate\n\n\nGapminder data can be used to evaluate the validity of this view.\nA scatterplot of life expectancy versus fertility rate in 1962 suggests that this viewpoint was grounded in reality 50 years ago. Is it still the case today?\n\n\n# basic scatterplot of life expectancy versus fertility\nds_theme_set() # set plot theme\nfilter(gapminder, year == 1962) %&gt;% \n  ggplot(aes(fertility, life_expectancy)) +\n  geom_point()\n\n\n\n\n\n\n# add color as continent\nfilter(gapminder, year == 1962) %&gt;% \n  ggplot(aes(fertility, life_expectancy, color = continent)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\nFaceting makes multiple side-by-side plots stratified by some variable. This is a way to ease comparisons.\nThe facet_grid() function allows faceting by up to two variables, with rows faceted by one variable and columns faceted by the other variable. To facet by only one variable, use the dot operator as the other variable.\nThe facet_wrap() function facets by one variable and automatically wraps the series of plots so they have readable dimensions.\nFaceting keeps the axes fixed across all plots, easing comparisons between plots.\nThe data suggest that the developing versus Western world view no longer makes sense in 2012.\n\n ggplot2-分面(facet) 一页多图数据可视化章节学习facet\n\n\n# facet by continent and year\nfilter(gapminder, year %in% c(1962, 2012)) %&gt;% \n  ggplot(aes(fertility, life_expectancy, col = continent)) +\n  geom_point() +\n  facet_grid(continent ~ year)\n\n\n\n\n\n\n# facet by year only \nfilter(gapminder, year %in% c(1962, 2012)) %&gt;% \n  ggplot(aes(fertility, life_expectancy, col = continent)) +\n  geom_point() +\n  facet_grid(. ~ year)\n\n\n\n\n\n\n# facet by year, plots wrapped onto multiple rows\nyears &lt;- c(1962, 1980, 1990, 2000, 2012)\ncontinents &lt;- c(\"Europ\", \"Asia\")\ngapminder %&gt;% \n  filter(year %in% years & continent %in% continent) %&gt;% \n  ggplot(aes(fertility, life_expectancy, col = continent)) +\n  geom_point() +\n  facet_wrap(. ~ year)\n\n\n\n\n\n\n\n\n\n\nTime series plots have time on the x-axis and a variable of interest on the y-axis.\nThe geom_line() geometry connects adjacent data points to form a continuous line. A line plot is appropriate when points are regularly spaced, densely packed and from a single data series.\nYou can plot multiple lines on the same graph. Remember to group or color by a variable so that the lines are plotted independently.\nLabeling is usually preferred over legends. However, legends are easier to make and appear by default. Add a label with geom_text(), specifying the coordinates where the label should appear on the graph.\n\n\n# scatterplot of US fertility by year\ngapminder %&gt;% \n  filter(country == \"United States\") %&gt;% \n  ggplot(aes(year, fertility)) +\n  geom_point()\n\n\n\n\n\n\n# line plot of US fertility by year\ngapminder %&gt;% \n  filter(country == \"United States\") %&gt;% \n  ggplot(aes(year, fertility)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n# line plot fertility time series for two countries- only one line (incorrect)\ncountries &lt;- c(\"South Korea\", \"Germany\")\ngapminder %&gt;% filter(country %in% countries) %&gt;%\n    ggplot(aes(year, fertility)) +\n    geom_line()\n\n\n\n\n\n\n# line plot fertility time series for two countries - one line per country\ngapminder %&gt;% filter(country %in% countries) %&gt;%\n    ggplot(aes(year, fertility, group = country)) +\n    geom_line()\n\n\n\n\n\n\n# fertility time series for two countries - lines colored by country\ngapminder %&gt;% filter(country %in% countries) %&gt;%\n    ggplot(aes(year, fertility, col = country)) +\n    geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nlabels data frame as the data to ensure where to start label text \n\n\n\n# life expectancy time series - lines colored by country and labeled, no legend\nlabels &lt;- data.frame(country = countries, x = c(1975, 1965), y = c(60, 72))\ngapminder %&gt;% filter(country %in% countries) %&gt;%\n    ggplot(aes(year, life_expectancy, col = country)) +\n    geom_line() +\n    geom_text(data = labels, aes(x, y, label = country), size = 5) +\n    theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\nWe use GDP data to compute income in US dollars per day, adjusted for inflation.\nLog transformations covert multiplicative changes into additive changes.\ncommon transformations are the log base 2 transformation and the log base 10 transformation. The choice of base depends on the range of the data. The natural log is not recommended for visualization because it is difficult to interpret.\nThe mode of a distribution is the value with the highest frequency. The mode of a normal distribution is the average. A distribution can have multiple local modes.\nThere are two ways to use log transformations in plots: transform the data before plotting or transform the axes of the plot. Log scales have the advantage of showing the original values as axis labels, while log transformed values ease interpretation of intermediate values between labels.\nScale the x-axis using scale_x_continuous() or scale_x_log10() layers in ggplot2. Similar functions exist for the y-axis.\nIn 1970, income distribution is bimodal, consistent with the dichotomous Western versus developing worldview.\n\n\n# add dollars per day variable\ngapminder &lt;- gapminder %&gt;% \n  mutate(dollars_per_day = gdp/population/365)\n\n# histogram of dollars per day\npast_year &lt;- 1970\ngapminder %&gt;% \n  filter(year == past_year & !is.na(gdp)) %&gt;% \n  ggplot(aes(dollars_per_day)) +\n  geom_histogram(binwidth = 1, color = \"black\")\n\n\n\n\n\n\n# repeat histogram with log2 scaled data\ngapminder %&gt;%\n    filter(year == past_year & !is.na(gdp)) %&gt;%\n    ggplot(aes(log2(dollars_per_day))) +\n    geom_histogram(binwidth = 1, color = \"black\")\n\n\n\n\n\n\n# repeat histogram with log2 scaled x-axis\ngapminder %&gt;%\n    filter(year == past_year & !is.na(gdp)) %&gt;%\n    ggplot(aes(dollars_per_day)) +\n    geom_histogram(binwidth = 1, color = \"black\") +\n    scale_x_continuous(trans = \"log2\")\n\n\n\n\n\n\n\n\n\n\nMake boxplots stratified by a categorical variable using the geom_boxplot() geometry.\nRotate axis labels by changing the theme through element_text(). You can change the angle and justification of the text labels.\nConsider ordering your factors by a meaningful value with the reorder function, which changes the order of factor levels based on a related numeric vector. This is a way to ease comparisons.\nShow the data by adding data points to the boxplot with a geom_point layer. This adds information beyond the five-number summary to your plot, but too many data points it can obfuscate your message.\n\n\n# add dollars per day variable\ngapminder &lt;- gapminder %&gt;% \n  mutate(dollars_per_day = gdp/population/365)\n\n# number of regions\nlength(levels(gapminder$region))\n\n[1] 22\n\n# boxplot of GDP by region in 1970\npast_year &lt;- 1970\np &lt;- gapminder %&gt;% \n     filter(year == past_year & !is.na(gdp)) %&gt;% \n     ggplot(aes(region, dollars_per_day))\np + geom_boxplot()\n\n\n\n\n\n\n# roation name on x-axis\np + geom_boxplot() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nReorder a variable with ggplot2\n\n\n\n# by default, factor order is alphabetical\nfac &lt;- factor(c(\"Asia\", \"Asia\", \"West\", \"West\", \"West\"))\nlevels(fac)\n\n[1] \"Asia\" \"West\"\n\n# reorder factor by the category means\nvalue &lt;- c(10, 11, 12, 6, 4)\nfac &lt;- reorder(fac, value, FUN = mean)\nlevels(fac)\n\n[1] \"West\" \"Asia\"\n\n\n\n\n# reorder by median income and color by continent \np &lt;- gapminder %&gt;%\n    filter(year == past_year & !is.na(gdp)) %&gt;%\n    mutate(region = reorder(region, dollars_per_day, FUN = median)) %&gt;%  # reorder\n    ggplot(aes(region, dollars_per_day, fill = continent)) + # color by continent \n    geom_boxplot() +\n    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n    xlab(\"\")\np\n\n\n\n\n\n\n# log2 scale y-axis\np + scale_y_continuous(trans = \"log2\")\n\n\n\n\n\n\n# add data points\np + scale_y_continuous(trans = \"log2\") + geom_point(show.legend = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nintersect(交集);union(并集);setdiff(找不同);setequal(判断相同)\n\n\n\n\nUse intersect to find the overlap between two vectors.\nTo make boxplots where grouped variables are adjacaent, color the boxplot by a factor instead of faceting by that factor. This is a way to ease comparisions.\nThe data suggest that the income gap between rich and poor countries has narrowed, not expended.\n\n\n# add dollars per day variable and define past year\ngapminder &lt;- gapminder %&gt;% \n  mutate(dollars_per_day = gdp/population/365)\npast_year &lt;- 1970\n\n# define Western countries\nwest &lt;- c(\"Western Europe\", \"Northern Europe\", \"Southern Europe\", \"Northern America\", \"Australia and New Zealand\")\n\n# facet by West vs Devloping \ngapminder %&gt;% \n  filter(year == past_year & !is.na(gdp)) %&gt;% \n  mutate(group = ifelse(region %in% west, \"West\", \"Developing\")) %&gt;% \n  ggplot(aes(dollars_per_day)) +\n  geom_histogram(binwidth = 1, color = \"black\") +\n  scale_x_continuous(trans = \"log2\") +\n  facet_grid(. ~group)\n\n\n\n\n\n\n# facet by West/Developing and year\npresent_year &lt;- 2010\ngapminder %&gt;%\n    filter(year %in% c(past_year, present_year) & !is.na(gdp)) %&gt;%\n    mutate(group = ifelse(region %in% west, \"West\", \"Developing\")) %&gt;%\n    ggplot(aes(dollars_per_day)) +\n    geom_histogram(binwidth = 1, color = \"black\") +\n    scale_x_continuous(trans = \"log2\") +\n    facet_grid(year ~ group)\n\n\n\n\n\n\n\n\n\n# define countries that have data available in both years\ncountry_list_1 &lt;- gapminder %&gt;% \n  filter(year == past_year & !is.na(dollars_per_day)) %&gt;% .$country\n\ncountry_list_2 &lt;- gapminder %&gt;% \n  filter(year == present_year & !is.na(dollars_per_day)) %&gt;% .$country\n\ncountry_list &lt;- intersect(country_list_1, country_list_2)\n\n# make histogram including only countries with data availabe in both years\ngapminder %&gt;% \n  filter(year %in% c(past_year, present_year) & country %in% country_list) %&gt;% # keep only selected countries\n  mutate(group = ifelse(region %in% west, \"West\", \"Developing\")) %&gt;% \n  ggplot(aes(dollars_per_day)) +\n  geom_histogram(binwidth = 1, color = \"black\") +\n  scale_x_continuous(trans = \"log2\") +\n  facet_grid(year ~ group)\n\n\n\n\n\n\n\n\n\np &lt;- gapminder %&gt;% \n  filter(year %in% c(past_year, present_year) & country %in% country_list) %&gt;%\n  mutate(region = reorder(region, dollars_per_day, FUN = median)) %&gt;% \n  ggplot() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n  xlab(\"\") + scale_y_continuous(trans = \"log2\") \n\np + geom_boxplot(aes(region, dollars_per_day, fill = continent)) +\n  facet_grid(year ~ .)\n\n\n\n\n\n\n# arrange matching boxplots next to each other, colored by year\np + geom_boxplot(aes(region, dollars_per_day, fill = factor(year)))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\ndplyr处理数据时常用的的函数\n在 R Dplyr 包中使用 case when 语句\n\n\n\n\n\nChange the y-axis of density plots to variable counts using ..count.. as the y argument.\nThe case_when() function defines a factor whose levels are defined by a variety of logical operations to group data.\nPlot stacked density plots using position=\"stack\".\nDefine a weight aesthetic mapping to change the relative weights of density plots-for example, this allow weighting of plots by population rather than number of countries.\n\n\n# see the code below the previous video for variable definitions\n\n# smooth density plots - area under each curve adds to 1\ngapminder %&gt;% \n  filter(year == past_year & country %in% country_list) %&gt;% \n  mutate(group = ifelse(region %in% west, \"West\", \"Developing\")) %&gt;% group_by(group) %&gt;% \n  summarize(n = n()) %&gt;% knitr::kable()\n\n\n\ngroup\nn\n\n\n\nDeveloping\n87\n\n\nWest\n21\n\n\n\n\n# smooth density plots - variable counts on y-axis\np &lt;- gapminder %&gt;% \n  filter(year == past_year & country %in% country_list) %&gt;% \n  mutate(group = ifelse(region %in% west, \"West\", \"Developing\")) %&gt;%\n  ggplot(aes(dollars_per_day, y = ..count.., fill = group)) +\n  scale_x_continuous(trans = \"log2\")\np + geom_density(alpha = 0.2, bw = 0.75) + facet_grid(year ~ .)\n\n\n\n\n\n\n\n\n\n# add group as a factor, grouping regions\ngapminder &lt;- gapminder %&gt;% \n  mutate(group = case_when(\n    .$region %in% west ~ \"West\",\n    .$region %in% c(\"Eastern Asia\", \"South-Eastern Asia\") ~ \"East Asia\", \n    .$region %in% c(\"Caribbean\", \"Central America\", \"South America\") ~ \"Latin America\",\n    .$continent == \"Africa\" & .$region != \"Northern Africa\" ~ \"Sub-Saharan Africa\", TRUE ~ \"Others\"))\n\n# reorder factor levels\ngapminder &lt;- gapminder %&gt;% \n  mutate(group = factor(group, levels = c(\"Others\", \"Latin America\", \"East Asia\", \"Sub-Saharan Africa\", \"West\")))\n\n\n\n# note you must redefine p with the new gapminder object first\np &lt;- gapminder %&gt;% \n  filter(year %in% c(past_year, present_year) & country %in% country_list) %&gt;% \n  ggplot(aes(dollars_per_day, fill = group)) +\n  scale_x_continuous(trans = \"log2\")\n\n# stacked density plot\np + geom_density(alpha = 0.2, bw = 0.75, position = \"stack\") +\n  facet_grid(year ~ .)\n\n\n\n\n\n\n\n\n\ngapminder %&gt;% \n  filter(year %in% c(past_year, present_year) & country %in% country_list) %&gt;% \n  group_by(year) %&gt;% \n  mutate(weight = population/sum(population*2)) %&gt;% \n  ungroup() %&gt;% \n  ggplot(aes(dollars_per_day, fill = group, weight = weight)) +\n  scale_x_continuous(trans = \"log2\") +\n  geom_density(alpha = 0.2, bw = 0.75, position = \"stack\") + facet_grid(year ~ .)\n\n\n\n\n\n\n\n\n\nEcological Fallacy\n\n\nThe breaks argument allows us to set the location of the axis labels and tick marks.\nthe logistic or logit transformation is defined as \\(f(p)=log\\frac{1}{1-p}\\), or the log of odds. This scale is useful for highlighting difference near 0 or near 1 and converts fold changes into constant increase.\nThe ecological fallacy is assuming that conclusion made from the average of a group apply to all members of that group.\n\n\n# define gapminder\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(gapminder)\n\n\n# add additional cases\ngapminder &lt;- gapminder %&gt;%\n    mutate(group = case_when(\n        .$region %in% west ~ \"The West\",\n        .$region %in% \"Northern Africa\" ~ \"Northern Africa\",\n        .$region %in% c(\"Eastern Asia\", \"South-Eastern Asia\") ~ \"East Asia\",\n        .$region == \"Southern Asia\" ~ \"Southern Asia\",\n        .$region %in% c(\"Central America\", \"South America\", \"Caribbean\") ~ \"Latin America\",\n        .$continent == \"Africa\" & .$region != \"Northern Africa\" ~ \"Sub-Saharan Africa\",\n        .$region %in% c(\"Melanesia\", \"Micronesia\", \"Polynesia\") ~ \"Pacific Islands\"))\n\n# define a data frame with group average income and average infant survival rate\nsurv_income &lt;- gapminder %&gt;%\n    filter(year %in% present_year & !is.na(gdp) & !is.na(infant_mortality) & !is.na(group)) %&gt;%\n    group_by(group) %&gt;%\n    summarize(income = sum(gdp)/sum(population)/365,\n                        infant_survival_rate = 1 - sum(infant_mortality/1000*population)/sum(population))\nsurv_income %&gt;% arrange(income)\n\n# A tibble: 7 × 3\n  group              income infant_survival_rate\n  &lt;chr&gt;               &lt;dbl&gt;                &lt;dbl&gt;\n1 Sub-Saharan Africa   1.76                0.936\n2 Southern Asia        2.07                0.952\n3 Pacific Islands      2.70                0.956\n4 Northern Africa      4.94                0.970\n5 Latin America       13.2                 0.983\n6 East Asia           13.4                 0.985\n7 The West            77.1                 0.995\n\n# plot infant survival versus income, with transformed axes\nsurv_income %&gt;% ggplot(aes(income, infant_survival_rate, label = group, color = group)) +\n    scale_x_continuous(trans = \"log2\", limit = c(0.25, 150)) +\n    scale_y_continuous(trans = \"logit\", limit = c(0.875, .9981),\n                                       breaks = c(.85, .90, .95, .99, .995, .998)) +\n    geom_label(size = 3, show.legend = FALSE)"
  },
  {
    "objectID": "series/R/2022/12/05/datavisualization_gapminder.html#overview",
    "href": "series/R/2022/12/05/datavisualization_gapminder.html#overview",
    "title": "Gapminder Data Sets",
    "section": "",
    "text": "After completing Gapminder, you will: - understand how Hans Rosling and the Gapminder Foundation use effective data visualization to convey data-based trends.\n\nbe able to apply the ggplot2 techniques from the previous section to answer questions using data.\nunderstand how fixed scales across plots can ease comparisons.\nbe able to modify graphs to improve data visualization."
  },
  {
    "objectID": "series/R/2022/12/05/datavisualization_gapminder.html#introduction-to-gapminder",
    "href": "series/R/2022/12/05/datavisualization_gapminder.html#introduction-to-gapminder",
    "title": "Gapminder Data Sets",
    "section": "",
    "text": "Case study: Trends in World Health and Economics\nData Source form Gapminder\nWe will use this data to answer the following questions about World Health and Economics: - Is it still fair to consider the world as divided into the West and the developing world? - Has income inequality across countries worsened over the last 40 years?"
  },
  {
    "objectID": "series/R/2022/12/05/datavisualization_gapminder.html#gapminder-dataset",
    "href": "series/R/2022/12/05/datavisualization_gapminder.html#gapminder-dataset",
    "title": "Gapminder Data Sets",
    "section": "",
    "text": "A selection of world health and economics statistics from the Gapminder project can be found in the dslabs package as data(gapminder).\nMost people have misconceptions about world health and economics, which can be addressed by considering real data.\n\n\nlibrary(dslabs)\nlibrary(tidyverse)\ndata(\"gapminder\")\n\n\nhead(gapminder)\n\n              country year infant_mortality life_expectancy fertility\n1             Albania 1960           115.40           62.87      6.19\n2             Algeria 1960           148.20           47.50      7.65\n3              Angola 1960           208.00           35.98      7.32\n4 Antigua and Barbuda 1960               NA           62.97      4.43\n5           Argentina 1960            59.87           65.39      3.11\n6             Armenia 1960               NA           66.86      4.55\n  population          gdp continent          region\n1    1636054           NA    Europe Southern Europe\n2   11124892  13828152297    Africa Northern Africa\n3    5270844           NA    Africa   Middle Africa\n4      54681           NA  Americas       Caribbean\n5   20619075 108322326649  Americas   South America\n6    1867396           NA      Asia    Western Asia\n\nnames(gapminder)\n\n[1] \"country\"          \"year\"             \"infant_mortality\" \"life_expectancy\" \n[5] \"fertility\"        \"population\"       \"gdp\"              \"continent\"       \n[9] \"region\"          \n\n\n\ngapminder %&gt;% \n  filter(year == 2015 & country %in% c(\"Sri Lanka\", \"Turkey\")) %&gt;% \n  select(country, infant_mortality)\n\n    country infant_mortality\n1 Sri Lanka              8.4\n2    Turkey             11.6"
  },
  {
    "objectID": "series/R/2022/12/05/datavisualization_gapminder.html#life-expectancy-and-fertility-rates",
    "href": "series/R/2022/12/05/datavisualization_gapminder.html#life-expectancy-and-fertility-rates",
    "title": "Gapminder Data Sets",
    "section": "",
    "text": "A prevalent worldview is that the world is divided into two groups of countries:\n\nWestern world: high life expectancy, low fertility rate\nDeveloping world: lower life expectancy, higher fertility rate\n\n\nGapminder data can be used to evaluate the validity of this view.\nA scatterplot of life expectancy versus fertility rate in 1962 suggests that this viewpoint was grounded in reality 50 years ago. Is it still the case today?\n\n\n# basic scatterplot of life expectancy versus fertility\nds_theme_set() # set plot theme\nfilter(gapminder, year == 1962) %&gt;% \n  ggplot(aes(fertility, life_expectancy)) +\n  geom_point()\n\n\n\n\n\n\n# add color as continent\nfilter(gapminder, year == 1962) %&gt;% \n  ggplot(aes(fertility, life_expectancy, color = continent)) +\n  geom_point()"
  },
  {
    "objectID": "series/R/2022/12/05/datavisualization_gapminder.html#faceting",
    "href": "series/R/2022/12/05/datavisualization_gapminder.html#faceting",
    "title": "Gapminder Data Sets",
    "section": "",
    "text": "Faceting makes multiple side-by-side plots stratified by some variable. This is a way to ease comparisons.\nThe facet_grid() function allows faceting by up to two variables, with rows faceted by one variable and columns faceted by the other variable. To facet by only one variable, use the dot operator as the other variable.\nThe facet_wrap() function facets by one variable and automatically wraps the series of plots so they have readable dimensions.\nFaceting keeps the axes fixed across all plots, easing comparisons between plots.\nThe data suggest that the developing versus Western world view no longer makes sense in 2012.\n\n ggplot2-分面(facet) 一页多图数据可视化章节学习facet\n\n\n# facet by continent and year\nfilter(gapminder, year %in% c(1962, 2012)) %&gt;% \n  ggplot(aes(fertility, life_expectancy, col = continent)) +\n  geom_point() +\n  facet_grid(continent ~ year)\n\n\n\n\n\n\n# facet by year only \nfilter(gapminder, year %in% c(1962, 2012)) %&gt;% \n  ggplot(aes(fertility, life_expectancy, col = continent)) +\n  geom_point() +\n  facet_grid(. ~ year)\n\n\n\n\n\n\n# facet by year, plots wrapped onto multiple rows\nyears &lt;- c(1962, 1980, 1990, 2000, 2012)\ncontinents &lt;- c(\"Europ\", \"Asia\")\ngapminder %&gt;% \n  filter(year %in% years & continent %in% continent) %&gt;% \n  ggplot(aes(fertility, life_expectancy, col = continent)) +\n  geom_point() +\n  facet_wrap(. ~ year)"
  },
  {
    "objectID": "series/R/2022/12/05/datavisualization_gapminder.html#time-series-plots",
    "href": "series/R/2022/12/05/datavisualization_gapminder.html#time-series-plots",
    "title": "Gapminder Data Sets",
    "section": "",
    "text": "Time series plots have time on the x-axis and a variable of interest on the y-axis.\nThe geom_line() geometry connects adjacent data points to form a continuous line. A line plot is appropriate when points are regularly spaced, densely packed and from a single data series.\nYou can plot multiple lines on the same graph. Remember to group or color by a variable so that the lines are plotted independently.\nLabeling is usually preferred over legends. However, legends are easier to make and appear by default. Add a label with geom_text(), specifying the coordinates where the label should appear on the graph.\n\n\n# scatterplot of US fertility by year\ngapminder %&gt;% \n  filter(country == \"United States\") %&gt;% \n  ggplot(aes(year, fertility)) +\n  geom_point()\n\n\n\n\n\n\n# line plot of US fertility by year\ngapminder %&gt;% \n  filter(country == \"United States\") %&gt;% \n  ggplot(aes(year, fertility)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n# line plot fertility time series for two countries- only one line (incorrect)\ncountries &lt;- c(\"South Korea\", \"Germany\")\ngapminder %&gt;% filter(country %in% countries) %&gt;%\n    ggplot(aes(year, fertility)) +\n    geom_line()\n\n\n\n\n\n\n# line plot fertility time series for two countries - one line per country\ngapminder %&gt;% filter(country %in% countries) %&gt;%\n    ggplot(aes(year, fertility, group = country)) +\n    geom_line()\n\n\n\n\n\n\n# fertility time series for two countries - lines colored by country\ngapminder %&gt;% filter(country %in% countries) %&gt;%\n    ggplot(aes(year, fertility, col = country)) +\n    geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nlabels data frame as the data to ensure where to start label text \n\n\n\n# life expectancy time series - lines colored by country and labeled, no legend\nlabels &lt;- data.frame(country = countries, x = c(1975, 1965), y = c(60, 72))\ngapminder %&gt;% filter(country %in% countries) %&gt;%\n    ggplot(aes(year, life_expectancy, col = country)) +\n    geom_line() +\n    geom_text(data = labels, aes(x, y, label = country), size = 5) +\n    theme(legend.position = \"none\")"
  },
  {
    "objectID": "series/R/2022/12/05/datavisualization_gapminder.html#transformations",
    "href": "series/R/2022/12/05/datavisualization_gapminder.html#transformations",
    "title": "Gapminder Data Sets",
    "section": "",
    "text": "We use GDP data to compute income in US dollars per day, adjusted for inflation.\nLog transformations covert multiplicative changes into additive changes.\ncommon transformations are the log base 2 transformation and the log base 10 transformation. The choice of base depends on the range of the data. The natural log is not recommended for visualization because it is difficult to interpret.\nThe mode of a distribution is the value with the highest frequency. The mode of a normal distribution is the average. A distribution can have multiple local modes.\nThere are two ways to use log transformations in plots: transform the data before plotting or transform the axes of the plot. Log scales have the advantage of showing the original values as axis labels, while log transformed values ease interpretation of intermediate values between labels.\nScale the x-axis using scale_x_continuous() or scale_x_log10() layers in ggplot2. Similar functions exist for the y-axis.\nIn 1970, income distribution is bimodal, consistent with the dichotomous Western versus developing worldview.\n\n\n# add dollars per day variable\ngapminder &lt;- gapminder %&gt;% \n  mutate(dollars_per_day = gdp/population/365)\n\n# histogram of dollars per day\npast_year &lt;- 1970\ngapminder %&gt;% \n  filter(year == past_year & !is.na(gdp)) %&gt;% \n  ggplot(aes(dollars_per_day)) +\n  geom_histogram(binwidth = 1, color = \"black\")\n\n\n\n\n\n\n# repeat histogram with log2 scaled data\ngapminder %&gt;%\n    filter(year == past_year & !is.na(gdp)) %&gt;%\n    ggplot(aes(log2(dollars_per_day))) +\n    geom_histogram(binwidth = 1, color = \"black\")\n\n\n\n\n\n\n# repeat histogram with log2 scaled x-axis\ngapminder %&gt;%\n    filter(year == past_year & !is.na(gdp)) %&gt;%\n    ggplot(aes(dollars_per_day)) +\n    geom_histogram(binwidth = 1, color = \"black\") +\n    scale_x_continuous(trans = \"log2\")"
  },
  {
    "objectID": "series/R/2022/12/05/datavisualization_gapminder.html#stratify-and-boxplot",
    "href": "series/R/2022/12/05/datavisualization_gapminder.html#stratify-and-boxplot",
    "title": "Gapminder Data Sets",
    "section": "",
    "text": "Make boxplots stratified by a categorical variable using the geom_boxplot() geometry.\nRotate axis labels by changing the theme through element_text(). You can change the angle and justification of the text labels.\nConsider ordering your factors by a meaningful value with the reorder function, which changes the order of factor levels based on a related numeric vector. This is a way to ease comparisons.\nShow the data by adding data points to the boxplot with a geom_point layer. This adds information beyond the five-number summary to your plot, but too many data points it can obfuscate your message.\n\n\n# add dollars per day variable\ngapminder &lt;- gapminder %&gt;% \n  mutate(dollars_per_day = gdp/population/365)\n\n# number of regions\nlength(levels(gapminder$region))\n\n[1] 22\n\n# boxplot of GDP by region in 1970\npast_year &lt;- 1970\np &lt;- gapminder %&gt;% \n     filter(year == past_year & !is.na(gdp)) %&gt;% \n     ggplot(aes(region, dollars_per_day))\np + geom_boxplot()\n\n\n\n\n\n\n# roation name on x-axis\np + geom_boxplot() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nReorder a variable with ggplot2\n\n\n\n# by default, factor order is alphabetical\nfac &lt;- factor(c(\"Asia\", \"Asia\", \"West\", \"West\", \"West\"))\nlevels(fac)\n\n[1] \"Asia\" \"West\"\n\n# reorder factor by the category means\nvalue &lt;- c(10, 11, 12, 6, 4)\nfac &lt;- reorder(fac, value, FUN = mean)\nlevels(fac)\n\n[1] \"West\" \"Asia\"\n\n\n\n\n# reorder by median income and color by continent \np &lt;- gapminder %&gt;%\n    filter(year == past_year & !is.na(gdp)) %&gt;%\n    mutate(region = reorder(region, dollars_per_day, FUN = median)) %&gt;%  # reorder\n    ggplot(aes(region, dollars_per_day, fill = continent)) + # color by continent \n    geom_boxplot() +\n    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n    xlab(\"\")\np\n\n\n\n\n\n\n# log2 scale y-axis\np + scale_y_continuous(trans = \"log2\")\n\n\n\n\n\n\n# add data points\np + scale_y_continuous(trans = \"log2\") + geom_point(show.legend = FALSE)"
  },
  {
    "objectID": "series/R/2022/12/05/datavisualization_gapminder.html#comparing-distributions",
    "href": "series/R/2022/12/05/datavisualization_gapminder.html#comparing-distributions",
    "title": "Gapminder Data Sets",
    "section": "",
    "text": "Important\n\n\n\nintersect(交集);union(并集);setdiff(找不同);setequal(判断相同)\n\n\n\n\nUse intersect to find the overlap between two vectors.\nTo make boxplots where grouped variables are adjacaent, color the boxplot by a factor instead of faceting by that factor. This is a way to ease comparisions.\nThe data suggest that the income gap between rich and poor countries has narrowed, not expended.\n\n\n# add dollars per day variable and define past year\ngapminder &lt;- gapminder %&gt;% \n  mutate(dollars_per_day = gdp/population/365)\npast_year &lt;- 1970\n\n# define Western countries\nwest &lt;- c(\"Western Europe\", \"Northern Europe\", \"Southern Europe\", \"Northern America\", \"Australia and New Zealand\")\n\n# facet by West vs Devloping \ngapminder %&gt;% \n  filter(year == past_year & !is.na(gdp)) %&gt;% \n  mutate(group = ifelse(region %in% west, \"West\", \"Developing\")) %&gt;% \n  ggplot(aes(dollars_per_day)) +\n  geom_histogram(binwidth = 1, color = \"black\") +\n  scale_x_continuous(trans = \"log2\") +\n  facet_grid(. ~group)\n\n\n\n\n\n\n# facet by West/Developing and year\npresent_year &lt;- 2010\ngapminder %&gt;%\n    filter(year %in% c(past_year, present_year) & !is.na(gdp)) %&gt;%\n    mutate(group = ifelse(region %in% west, \"West\", \"Developing\")) %&gt;%\n    ggplot(aes(dollars_per_day)) +\n    geom_histogram(binwidth = 1, color = \"black\") +\n    scale_x_continuous(trans = \"log2\") +\n    facet_grid(year ~ group)\n\n\n\n\n\n\n\n\n\n# define countries that have data available in both years\ncountry_list_1 &lt;- gapminder %&gt;% \n  filter(year == past_year & !is.na(dollars_per_day)) %&gt;% .$country\n\ncountry_list_2 &lt;- gapminder %&gt;% \n  filter(year == present_year & !is.na(dollars_per_day)) %&gt;% .$country\n\ncountry_list &lt;- intersect(country_list_1, country_list_2)\n\n# make histogram including only countries with data availabe in both years\ngapminder %&gt;% \n  filter(year %in% c(past_year, present_year) & country %in% country_list) %&gt;% # keep only selected countries\n  mutate(group = ifelse(region %in% west, \"West\", \"Developing\")) %&gt;% \n  ggplot(aes(dollars_per_day)) +\n  geom_histogram(binwidth = 1, color = \"black\") +\n  scale_x_continuous(trans = \"log2\") +\n  facet_grid(year ~ group)\n\n\n\n\n\n\n\n\n\np &lt;- gapminder %&gt;% \n  filter(year %in% c(past_year, present_year) & country %in% country_list) %&gt;%\n  mutate(region = reorder(region, dollars_per_day, FUN = median)) %&gt;% \n  ggplot() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n  xlab(\"\") + scale_y_continuous(trans = \"log2\") \n\np + geom_boxplot(aes(region, dollars_per_day, fill = continent)) +\n  facet_grid(year ~ .)\n\n\n\n\n\n\n# arrange matching boxplots next to each other, colored by year\np + geom_boxplot(aes(region, dollars_per_day, fill = factor(year)))"
  },
  {
    "objectID": "series/R/2022/12/05/datavisualization_gapminder.html#density-plots",
    "href": "series/R/2022/12/05/datavisualization_gapminder.html#density-plots",
    "title": "Gapminder Data Sets",
    "section": "",
    "text": "Tip\n\n\n\n\ndplyr处理数据时常用的的函数\n在 R Dplyr 包中使用 case when 语句\n\n\n\n\n\nChange the y-axis of density plots to variable counts using ..count.. as the y argument.\nThe case_when() function defines a factor whose levels are defined by a variety of logical operations to group data.\nPlot stacked density plots using position=\"stack\".\nDefine a weight aesthetic mapping to change the relative weights of density plots-for example, this allow weighting of plots by population rather than number of countries.\n\n\n# see the code below the previous video for variable definitions\n\n# smooth density plots - area under each curve adds to 1\ngapminder %&gt;% \n  filter(year == past_year & country %in% country_list) %&gt;% \n  mutate(group = ifelse(region %in% west, \"West\", \"Developing\")) %&gt;% group_by(group) %&gt;% \n  summarize(n = n()) %&gt;% knitr::kable()\n\n\n\ngroup\nn\n\n\n\nDeveloping\n87\n\n\nWest\n21\n\n\n\n\n# smooth density plots - variable counts on y-axis\np &lt;- gapminder %&gt;% \n  filter(year == past_year & country %in% country_list) %&gt;% \n  mutate(group = ifelse(region %in% west, \"West\", \"Developing\")) %&gt;%\n  ggplot(aes(dollars_per_day, y = ..count.., fill = group)) +\n  scale_x_continuous(trans = \"log2\")\np + geom_density(alpha = 0.2, bw = 0.75) + facet_grid(year ~ .)\n\n\n\n\n\n\n\n\n\n# add group as a factor, grouping regions\ngapminder &lt;- gapminder %&gt;% \n  mutate(group = case_when(\n    .$region %in% west ~ \"West\",\n    .$region %in% c(\"Eastern Asia\", \"South-Eastern Asia\") ~ \"East Asia\", \n    .$region %in% c(\"Caribbean\", \"Central America\", \"South America\") ~ \"Latin America\",\n    .$continent == \"Africa\" & .$region != \"Northern Africa\" ~ \"Sub-Saharan Africa\", TRUE ~ \"Others\"))\n\n# reorder factor levels\ngapminder &lt;- gapminder %&gt;% \n  mutate(group = factor(group, levels = c(\"Others\", \"Latin America\", \"East Asia\", \"Sub-Saharan Africa\", \"West\")))\n\n\n\n# note you must redefine p with the new gapminder object first\np &lt;- gapminder %&gt;% \n  filter(year %in% c(past_year, present_year) & country %in% country_list) %&gt;% \n  ggplot(aes(dollars_per_day, fill = group)) +\n  scale_x_continuous(trans = \"log2\")\n\n# stacked density plot\np + geom_density(alpha = 0.2, bw = 0.75, position = \"stack\") +\n  facet_grid(year ~ .)\n\n\n\n\n\n\n\n\n\ngapminder %&gt;% \n  filter(year %in% c(past_year, present_year) & country %in% country_list) %&gt;% \n  group_by(year) %&gt;% \n  mutate(weight = population/sum(population*2)) %&gt;% \n  ungroup() %&gt;% \n  ggplot(aes(dollars_per_day, fill = group, weight = weight)) +\n  scale_x_continuous(trans = \"log2\") +\n  geom_density(alpha = 0.2, bw = 0.75, position = \"stack\") + facet_grid(year ~ .)"
  },
  {
    "objectID": "series/R/2022/12/05/datavisualization_gapminder.html#ecological-fallacy",
    "href": "series/R/2022/12/05/datavisualization_gapminder.html#ecological-fallacy",
    "title": "Gapminder Data Sets",
    "section": "",
    "text": "Ecological Fallacy\n\n\nThe breaks argument allows us to set the location of the axis labels and tick marks.\nthe logistic or logit transformation is defined as \\(f(p)=log\\frac{1}{1-p}\\), or the log of odds. This scale is useful for highlighting difference near 0 or near 1 and converts fold changes into constant increase.\nThe ecological fallacy is assuming that conclusion made from the average of a group apply to all members of that group.\n\n\n# define gapminder\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(gapminder)\n\n\n# add additional cases\ngapminder &lt;- gapminder %&gt;%\n    mutate(group = case_when(\n        .$region %in% west ~ \"The West\",\n        .$region %in% \"Northern Africa\" ~ \"Northern Africa\",\n        .$region %in% c(\"Eastern Asia\", \"South-Eastern Asia\") ~ \"East Asia\",\n        .$region == \"Southern Asia\" ~ \"Southern Asia\",\n        .$region %in% c(\"Central America\", \"South America\", \"Caribbean\") ~ \"Latin America\",\n        .$continent == \"Africa\" & .$region != \"Northern Africa\" ~ \"Sub-Saharan Africa\",\n        .$region %in% c(\"Melanesia\", \"Micronesia\", \"Polynesia\") ~ \"Pacific Islands\"))\n\n# define a data frame with group average income and average infant survival rate\nsurv_income &lt;- gapminder %&gt;%\n    filter(year %in% present_year & !is.na(gdp) & !is.na(infant_mortality) & !is.na(group)) %&gt;%\n    group_by(group) %&gt;%\n    summarize(income = sum(gdp)/sum(population)/365,\n                        infant_survival_rate = 1 - sum(infant_mortality/1000*population)/sum(population))\nsurv_income %&gt;% arrange(income)\n\n# A tibble: 7 × 3\n  group              income infant_survival_rate\n  &lt;chr&gt;               &lt;dbl&gt;                &lt;dbl&gt;\n1 Sub-Saharan Africa   1.76                0.936\n2 Southern Asia        2.07                0.952\n3 Pacific Islands      2.70                0.956\n4 Northern Africa      4.94                0.970\n5 Latin America       13.2                 0.983\n6 East Asia           13.4                 0.985\n7 The West            77.1                 0.995\n\n# plot infant survival versus income, with transformed axes\nsurv_income %&gt;% ggplot(aes(income, infant_survival_rate, label = group, color = group)) +\n    scale_x_continuous(trans = \"log2\", limit = c(0.25, 150)) +\n    scale_y_continuous(trans = \"logit\", limit = c(0.875, .9981),\n                                       breaks = c(.85, .90, .95, .99, .995, .998)) +\n    geom_label(size = 3, show.legend = FALSE)"
  },
  {
    "objectID": "series/R/2022/12/08/probability_discreteprobability.html",
    "href": "series/R/2022/12/08/probability_discreteprobability.html",
    "title": "Discrete Probability",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "posts/blogsforr/2022/11/30/christmastree.html",
    "href": "posts/blogsforr/2022/11/30/christmastree.html",
    "title": "Christmas Tree",
    "section": "",
    "text": "Let us use ggplot2 to make a Christmas Tree.\nCode\nFigure 1 shows use ggplot2 to make a Christmas Tree.\n\nrm(list = ls())\nlibrary(ggplot2) \n\n# create data\nx &lt;- c(8,7,6,7,6,5,6,5,4,5,4,3,4,3,2,3,2,1,0.5,0.1)\n\ndat1 &lt;- data.frame(x1 = 1:length(x), x2 = x)\ndat2 &lt;- data.frame(x1 = 1:length(x), x2 = -x)\ndat1$xvar &lt;- dat2$xvar &lt;- NA\ndat1$yvar &lt;- dat2$yvar &lt;- NA\ndat1$siz &lt;- dat2$siz &lt;- NA\ndat1$col &lt;- dat2$col &lt;- NA\n\n# set threshold for christmas balls\ndec_threshold = -0.5\n\n# create random places, sizes and colors for christmas balls\nset.seed(2512)\nfor (row in 1:nrow(dat1)){\n\nif (rnorm(1) &gt; dec_threshold){\n\ndat1$xvar[row] &lt;- row\ndat1$yvar[row] &lt;- sample(1:dat1$x2[row]-1,1)\ndat1$siz[row] &lt;- runif(1,0.5,1.5)\ndat1$col[row] &lt;- sample(1:5, 1)\n}\n\nif (rnorm(1) &gt; dec_threshold){\n\ndat2$xvar[row] &lt;- row\ndat2$yvar[row] &lt;- sample(1:dat2$x2[row],1)\ndat2$siz[row] &lt;- runif(1,0.5,1.5)\ndat2$col[row] &lt;- sample(1:5, 1)\n}\n}\n\n# plot the christmas tree\nggplot() +\ngeom_bar(data = dat1, aes(x=x1, y=x2),stat = \"identity\", fill = '#31a354') +\ngeom_bar(data = dat2, aes(x=x1, y=x2),stat = \"identity\", fill = '#31a354') +\ngeom_point(data = dat1,aes(x = xvar, y = yvar, size = siz, colour = as.factor(col)) ) +\ngeom_point(data = dat2,aes(x = xvar, y = yvar, size = siz, colour = as.factor(col)) ) +\ncoord_flip() + theme_minimal()+ theme(legend.position=\"none\",\naxis.title.x=element_blank(),\naxis.text.x=element_blank(),\naxis.ticks.x=element_blank(),\naxis.title.y=element_blank(),\naxis.text.y=element_blank(),\naxis.ticks.y=element_blank()) +\nggtitle('Merry Christmas') +\ntheme(plot.title = element_text(color = \"red\", hjust = 0.5))\n\n\n\nFigure 1: Christmas Tree\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/blogsforr/2022/12/01/dynamicgraph.html",
    "href": "posts/blogsforr/2022/12/01/dynamicgraph.html",
    "title": "Dynamic Graph",
    "section": "",
    "text": "Here is an example shows how to use gganmate package to make a dynamic graph."
  },
  {
    "objectID": "posts/blogsforr/2022/12/01/dynamicgraph.html#data-from-mtcars",
    "href": "posts/blogsforr/2022/12/01/dynamicgraph.html#data-from-mtcars",
    "title": "Dynamic Graph",
    "section": "Data from mtcars",
    "text": "Data from mtcars\n\nlibrary(ggplot2)\nlibrary(gganimate)\n\nggplot(mtcars, aes(factor(cyl), mpg)) + \n  geom_boxplot() + \n  # Here comes the gganimate code\n  transition_states(\n    gear,\n    transition_length = 2,\n    state_length = 1\n  ) +\n  enter_fade() + \n  exit_shrink() +\n  ease_aes('sine-in-out')"
  },
  {
    "objectID": "posts/blogsforr/2023/01/19/installation.html",
    "href": "posts/blogsforr/2023/01/19/installation.html",
    "title": "How to install R and Rstudio",
    "section": "",
    "text": "R is an open-source programming language and software environment for statistical computing, data analysis, and graphics. It was developed by Ross Ihaka and Robert Gentleman in 1993 and has since become a popular tool for data analysis and visualization in academia, government, and industry."
  },
  {
    "objectID": "posts/blogsforr/2023/01/19/installation.html#installing-r-and-rstudio-on-windows",
    "href": "posts/blogsforr/2023/01/19/installation.html#installing-r-and-rstudio-on-windows",
    "title": "How to install R and Rstudio",
    "section": "Installing R and RStudio on Windows:",
    "text": "Installing R and RStudio on Windows:\n\nGo to the R website (https://cran.r-project.org) and download the latest version of R for Windows.\nOnce the download is complete, run the setup file and follow the on-screen instructions to install R on your computer.\nNext, go to the RStudio website (https://rstudio.com) and download the latest version of RStudio Desktop for Windows.\nRun the setup file and follow the on-screen instructions to install RStudio on your computer.\nOnce both R and RStudio are installed, you can launch RStudio from the Windows Start menu."
  },
  {
    "objectID": "posts/blogsforr/2023/01/19/installation.html#installing-r-and-rstudio-on-mac",
    "href": "posts/blogsforr/2023/01/19/installation.html#installing-r-and-rstudio-on-mac",
    "title": "How to install R and Rstudio",
    "section": "Installing R and RStudio on Mac:",
    "text": "Installing R and RStudio on Mac:\n\nGo to the R website (https://cran.r-project.org) and download the latest version of R for Mac.\nOnce the download is complete, open the downloaded file and follow the on-screen instructions to install R on your computer.\nNext, go to the RStudio website (https://rstudio.com) and download the latest version of RStudio Desktop for Mac.\nOnce the download is complete, open the downloaded file and follow the on-screen instructions to install RStudio on your computer.\nOnce both R and RStudio are installed, you can launch RStudio from the Applications folder on your Mac."
  },
  {
    "objectID": "posts/blogsforr/2023/01/19/installation.html#installing-r-and-rstudio-on-linux",
    "href": "posts/blogsforr/2023/01/19/installation.html#installing-r-and-rstudio-on-linux",
    "title": "How to install R and Rstudio",
    "section": "Installing R and RStudio on Linux:",
    "text": "Installing R and RStudio on Linux:\n\nGo to the R website (https://cran.r-project.org) and download the latest version of R for Linux.\nOnce the download is complete, open a terminal window and navigate to the directory where the downloaded file is located.\n\nRun the following command to install R:\nsudo apt-get install r-base\n\nNext, go to the RStudio website (https://rstudio.com) and download the latest version of RStudio Desktop for Linux.\nOnce the download is complete, open a terminal window and navigate to the directory where the downloaded file is located.\n\nRun the following command to install RStudio:\nsudo dpkg -i rstudio-*.deb\n\nOnce both R and RStudio are installed, you can launch RStudio from the Applications menu on your Linux computer."
  },
  {
    "objectID": "posts/blogsforr/2023/01/19/installation.html#installing-r-and-rstudio-on-mac-and-linux-using-homebrew",
    "href": "posts/blogsforr/2023/01/19/installation.html#installing-r-and-rstudio-on-mac-and-linux-using-homebrew",
    "title": "How to install R and Rstudio",
    "section": "Installing R and RStudio on Mac and Linux using Homebrew",
    "text": "Installing R and RStudio on Mac and Linux using Homebrew\nHomebrew is a package manager for Mac and Linux that makes it easy to install and manage software. Here’s how to install R and RStudio using Homebrew:\nMac:\n\n\nIf you don’t already have Homebrew installed, run the following command in your terminal to install it:\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\n\nOnce Homebrew is installed, run the following command to install R:\nbrew install r\n\n\nNext, run the following command in your terminal to install:\nbrew install --cask rstudio\n\nOnce both R and RStudio are installed, you can launch RStudio from the Applications folder on your Mac.\nLinux:\n\nSame instruction as mac to install Homebrew on Linux.\n\nOnce Homebrew is installed, run the following command to install R:\nbrew install r\n\nNext, go to the RStudio website (https://rstudio.com) and download the latest version of RStudio Desktop for Linux.\nOnce the download is complete, open a terminal window and navigate to the directory where the downloaded file is located.\n\nRun the following command to install RStudio:\nsudo dpkg -i rstudio-*.deb\n\nOnce both R and RStudio are installed, you can launch RStudio from the Applications menu on your Linux computer."
  },
  {
    "objectID": "posts/blogsforpython/2023/04/07/python.html",
    "href": "posts/blogsforpython/2023/04/07/python.html",
    "title": "New to Python?",
    "section": "",
    "text": "123154654\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/shiny/2023/04/05/costcalculator.html",
    "href": "projects/shiny/2023/04/05/costcalculator.html",
    "title": "Cost Calculator",
    "section": "",
    "text": "Introduction to Shiny\nShiny is an R package for creating interactive web applications directly from R without requiring web development knowledge. A Shiny app generally consists of a user interface (UI) and a server component that contains the app’s logic and computations.\nPurpose of this app\nThis Shiny app is a service fee calculator designed to calculate and track service fees based on various parameters, such as customer name, service type, add-on services, and service time. The app also allows users to apply or remove a 15% Goods and Services Tax (GST) on the total cost.\nUser Interface (UI)\nThe UI is divided into three main sections:\n\nHeader Panel: Contains the app’s title “服务费用计算器” (Service Fee Calculator).\nSidebar Panel: Includes input fields for customer name, service type, add-on services, service time, and service date. It also has action buttons for adding/removing GST, adding a service record, and generating a chart.\nMain Panel: Displays the calculated total cost, a table of service records, a time series plot of service costs, and a download button for exporting the service records as a CSV file.\nServer Component\nThe server component handles the app’s logic and computations, including:\n\nCalculating the total cost: Determines the total cost based on service type, add-on services, and service time.\nApplying/removing GST: Applies or removes a 15% GST on the total cost based on user input.\nManaging service records: Stores service records in a reactive data frame, updates the records when a new entry is added, and arranges the records in descending order by date.\nGenerating a time series plot: Creates a time series plot of service costs using ggplot2 when the “生成图表” (Generate Chart) button is clicked.\nDownloading service records: Allows users to download service records as a CSV file, with a filename containing the current date.\n\nIn summary, this Shiny app is a user-friendly service fee calculator that helps users input various parameters, calculate the total cost, apply or remove GST, store and display service records, and generate a time series plot of service costs.\n\n# load packages    \nlibrary(shiny)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(shinythemes)\n\n\ncustom_css &lt;- \"\n.record-table {\n  margin-top: 20px;\n}\n\"\n\n# 定义 UI 组件\nui &lt;- bootstrapPage(\n  theme = shinytheme(\"flatly\"),\n  headerPanel(\"服务费用计算器\"),\n  sidebarPanel(\n    textInput(inputId = \"name\", label = \"客户名字：\", value = \"\"),\n    selectInput(inputId = \"service\", label = \"服务类型：\", \n                choices = c(\"日常清洁\", \"深层清洁\", \"搬出/搬入\")),\n    checkboxGroupInput(inputId = \"addone\", label = \"附加服务：\", \n                       choices = c(\"烤箱\" = \"烤箱\", \"窗户\" = \"窗户\", \"墙和天花板\" = \"墙和天花板\")),\n    numericInput(inputId = \"oven_num\", label = \"烤箱数量：\", value = 1, min = 1),\n    numericInput(inputId = \"window_num\", label = \"窗户数量：\", value = 1, min = 1),\n    textInput(inputId = \"time\", label = \"服务时间（小时）：\", value = \"1\"),\n    dateInput(inputId = \"date\", label = \"服务日期：\", \n              value = Sys.Date()),\n    actionButton(inputId = \"add_gst_button\", label = \"添加 GST（15%）\"),\n    actionButton(inputId = \"remove_gst_button\", label = \"取消 GST（15%）\"),\n    actionButton(inputId = \"add\", label = \"添加服务记录\"),\n    actionButton(inputId = \"plot_button\", label = \"生成图表\")\n  ),\n  mainPanel(\n    h3(\"计算结果：\"),\n    textOutput(outputId = \"total\"),\n    downloadButton(outputId = \"download\", label = \"下载服务记录\"),\n    tags$head(tags$style(HTML(custom_css))),\n    fluidRow(\n      column(12,\n             plotOutput(outputId = \"plot\")\n      ),\n      column(12,\n             div(class = \"record-table\",\n                 tableOutput(outputId = \"records\")\n             )\n      )\n    )\n  ),\n)\n  \n\n# 定义 server 组件\nserver &lt;- function(input, output, session) {\n  gst_active &lt;- reactiveVal(FALSE)\n  \n  observeEvent(input$add_gst_button, {\n    gst_active(TRUE)\n  })\n  \n  observeEvent(input$remove_gst_button, {\n    gst_active(FALSE)\n  })\n  \n  \n  service_records &lt;- reactiveValues(data = data.frame(Date = character(),\n                                                      Name = character(),\n                                                      Service = character(),\n                                                      Time = numeric(),\n                                                      Cost = numeric(),\n                                                      Deleted = logical(),\n                                                      stringsAsFactors = FALSE))\n  \n  \n  # 计算总费用\n  total_cost &lt;- reactive({\n    if(input$service == \"日常清洁\") {\n      cost_per_hour_service &lt;- 40\n    } else if(input$service == \"深层清洁\") {\n      cost_per_hour_service &lt;- 100\n    } else {\n      cost_per_hour_service &lt;- 200\n    }\n    \n    # 初始化 cost_per_hour_addone 变量\n    cost_per_hour_addone &lt;- 0\n    \n    if(\"烤箱\" %in% input$addone) {\n      cost_per_hour_addone &lt;- cost_per_hour_addone + (60 * input$oven_num)\n    }\n    if(\"窗户\" %in% input$addone) {\n      cost_per_hour_addone &lt;- cost_per_hour_addone + (30 * input$window_num)\n    }\n    if(\"墙和天花板\" %in% input$addone) {\n      cost_per_hour_addone &lt;- cost_per_hour_addone + 120\n    }\n    \n    total &lt;- (cost_per_hour_service) * as.numeric(input$time) + cost_per_hour_addone\n    \n    # 应用 GST\n    if (gst_active()) {\n      total &lt;- total * 1.15\n    }\n    \n    return(total)\n  })\n  \n  \n  # 添加服务记录\n  observeEvent(input$add, {\n    if(input$name != \"\") {\n      record &lt;- data.frame(Date = format(input$date, \"%m/%d/%y\"),\n                           Name = input$name,\n                           Service = paste(input$service, \"和\", paste(input$addone, collapse = \"，\")),\n                           Time = as.numeric(input$time),\n                           Cost = total_cost(),\n                           stringsAsFactors = FALSE)\n      service_records$data &lt;- rbind(service_records$data, record)\n    }\n  })\n  \n  \n  # 显示计算结果\n  output$total &lt;- renderText({\n    if(input$name != \"\") {\n      cost &lt;- total_cost()\n      paste0(input$name, \" 需要支付 $\", round(cost, 2), \" 的服务费用。\")\n    } else {\n      \"请输入客户名字。\"\n    }\n  })\n  \n  # 绘制时间序列图\n  output$plot &lt;- renderPlot({\n    if(input$plot_button &gt; 0) {\n      plot_data &lt;- service_records$data %&gt;%\n        mutate(Date = as.Date(Date, \"%m/%d/%y\")) %&gt;%\n        group_by(Date) %&gt;%\n        summarize(TotalCost = sum(Cost))\n      \n      ggplot(plot_data, aes(x = Date, y = TotalCost)) +\n        geom_line() +\n        geom_text(aes(label = round(TotalCost, 2)), vjust = -0.5, size = 4) +\n        labs(title = \"服务费用时间序列图\", x = \"日期\", y = \"服务费用\") +\n        theme_minimal()\n    }\n  })\n  \n  \n  # 下载服务记录\n  output$download &lt;- downloadHandler(\n    filename = function() {\n      paste(\"service_records_\", Sys.Date(), \".csv\", sep = \"\")\n    },\n    content = function(file) {\n      req(service_records$data)\n      write.csv(service_records$data, file, row.names = FALSE)\n    }\n  )\n  \n  # 显示服务记录\n  output$records &lt;- renderTable({\n    service_records$data %&gt;%\n      arrange(desc(Date))\n  })\n  \n}\n\n# 运行应用程序\nshinyApp(ui, server)\n\n👉 Run Cost Calculator App\n\n\n\n\n\n    \nSocial share button\n\n\n\n        \n        \n\n        \n        \n\n        \n        \n\n        \n        \n\n        \n        \n\n        \n        \n\n        \n        \n    \n\n    \n\n Back to top"
  },
  {
    "objectID": "resources/plots/chart_suggestions.html",
    "href": "resources/plots/chart_suggestions.html",
    "title": "Data Lab Zone",
    "section": "",
    "text": "Figure 1: Chart Suggestions"
  },
  {
    "objectID": "resources/plots/chart_suggestions.html#choose-the-right-visualization-for-your-data",
    "href": "resources/plots/chart_suggestions.html#choose-the-right-visualization-for-your-data",
    "title": "Data Lab Zone",
    "section": "",
    "text": "Figure 1: Chart Suggestions"
  },
  {
    "objectID": "resources/plots/chart_suggestions.html#data-visualization-books",
    "href": "resources/plots/chart_suggestions.html#data-visualization-books",
    "title": "Data Lab Zone",
    "section": "Data visualization Books:",
    "text": "Data visualization Books:"
  },
  {
    "objectID": "talks/presentations/2023/04/07/shinyapp.html",
    "href": "talks/presentations/2023/04/07/shinyapp.html",
    "title": "A talk about Shiny App",
    "section": "",
    "text": "Good morning/afternoon/evening everyone.\nThank you for joining me today. I’m excited to share insights on a powerful tool that has revolutionized the way we build and interact with web applications using R programming language - Shiny.\nWhether you’re a data scientist looking to share your insights in an interactive manner, a teacher hoping to make learning more engaging, or a developer wanting to harness the power of R in web application development, Shiny can be a game-changer.\nIn this presentation, we will cover what Shiny is, its architecture, and how to create a simple Shiny app. We’ll also explore some of the advanced features that make Shiny a versatile tool for creating interactive web applications.\nWithout further ado, let’s delve into the fascinating world of Shiny!\n\nFor more Shiny practical projects, you can see Projects page: Cost Calculator.\n\n\n\n    \n    Social share button\n    \n    \n\n\n\n    \n        \n        \n\n        \n        \n\n        \n        \n\n        \n        \n\n        \n        \n\n        \n        \n\n        \n        \n    \n\n    \n\n\n\n\n\n\n Back to topReusehttps://creativecommons.org/licenses/by-nc/4.0/"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "NING LI",
    "section": "",
    "text": "NING's Profile Page\n    \n    \n\n\n\n    \n\n\n\n\n\n\n\nNING LI\n  \nAccountant, Data Science Enthusiast, Founder of Data Lab Zone\n\n\n\n\n\nHello there! My name is Ning Li, and I am a fervent admirer of Data Science hailing from China 🇨🇳.\n\nIn the year 2022, I founded Data Lab Zone, a platform specifically designed to disseminated the wealth of Knowledge and deep insights I've gathered in the domain of data science.\n\nAt this moment, my primary focus lies in vital areas such as data wrangling, data visualization, and statistical modeling.\nIn addition, I find the practical applications of the R language in tackling real-world challenges truly fascinating.\n\nI heartily invite those who share a similar enthusiasm for these subjects, or those who are keen to offer their innovative ideas, to get in touch with me. Please feel comfortable to reach out.\n\n\n\n\n\n\n\n\n\nEducation and Certification\n\nMassey University, Auckland | Master in Accountancy\nAchieved certification Data Science: R Basics in 2022\nAchieved certification Data Science: Visualization in 2022\nAchieved certification Data Science: Probability in 2022\nAchieved certification Data Science: Productivity Tools in 2022\n\nInterests\n\nData Wrangling\nData Visualization\nStatistical Modeling\nPolitical Risk\nReading, Hiking and Listen to Music\n\n\n\n\n\n\n    \n    Contact\n\n    \n        Please leave your valuable comments\n        \n            \n                \n                    First Name:\n                    \n                \n                \n                    Last Name:\n                    \n                \n            \n            \n                Email Address:\n                \n            \n            \n                Message:\n                \n            \n            \n                Submit\n                Reset"
  },
  {
    "objectID": "success.html",
    "href": "success.html",
    "title": "Thank You!",
    "section": "",
    "text": "Thank You!\n    \n      Your form has been submitted successfully.\n      I will be in touch with you soon.\n      Back to Home"
  }
]